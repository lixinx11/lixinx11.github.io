<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>10大最高效的Java库盘点</title>
    <url>/2020/09/29/10%E5%A4%A7%E6%9C%80%E9%AB%98%E6%95%88%E7%9A%84Java%E5%BA%93%E7%9B%98%E7%82%B9/</url>
    <content><![CDATA[<p>代码库是开源生态系统的重要组成部分，一个开源库背后通常拥有一个优秀的开源社区，毕竟没有社区的努力和支持，这个开源库很难生存下去。</p>
<p>有了开源库，我们不需要每次编码都重复造轮子，这样你可以节省很多时间去做其他事情，比如陪伴家人和朋友。所以，在数十万的库中寻找一个最好的，最受欢迎的，而且用起来最简单高效的就显得尤为重要</p>
<p>下面，我将推荐给你们10个最高效的Java库，并且他们都是开源的</p>
<h2 id="1-Java-标准库"><a href="#1-Java-标准库" class="headerlink" title="1. Java 标准库"></a>1. Java 标准库</h2><p>不用怀疑，我说的就是Java标准库，很多人都低估了或者没有完全了解Java标准库，并且不知道如何在编程的时候使用它，有些人甚至都不用它，下面说一些Java标准库的简要说明</p>
<p> java.lang：总是默认被导入，因为它基本包含开发中需要的Java 类型：String，Double，Enum，Math，等</p>
<p> java.util：包含Java中可用的所有集合和数据结构</p>
<p> java.io：I/O流</p>
<p> java.nio：它实际上是java.io的替代品，代表非阻塞I / O。</p>
<p> java.math：提供了使用任意精度decimal（BigDecimal）和integer（BigInteger）值的功能</p>
<p> java.net：被用于处理套接字，创建连接，或者创建网络应用程序</p>
<p>在Java中，我们也会用到GUI库，我们甚至可以用java.sound播放音乐和创建MIDI文件</p>
<h2 id="2-JHipster"><a href="#2-JHipster" class="headerlink" title="2. JHipster"></a>2. JHipster</h2><p>JHipster是一个开发平台，用来开发和部署 Maven + Spring + AngularJS 的项目，提供完全热加载的 Java 和 JavaScript 代码。从前端到后端生成整个应用程序，你唯一需要添加的是架构背后的业务逻辑。最后生成的项目中包含两个最重要的库：</p>
<p>Spring Boot - 帮助您加速和促进应用程序开发</p>
<p>Angular / AngularJS - JavaScript框架</p>
<h2 id="3-Maven"><a href="#3-Maven" class="headerlink" title="3. Maven"></a>3. Maven</h2><p>Maven 是一个 Java 项目构建系统。老实说，Maven真的很好用，如果你以前从未使用过Maven，那真是太可惜了。Maven可以通过在一个pom.xml文件中指定它们来管理所有项目依赖项的jar包，配置和构建配置，甚至可以管理文档。</p>
<h2 id="4-Apache-Commons"><a href="#4-Apache-Commons" class="headerlink" title="4. Apache Commons"></a>4. Apache Commons</h2><p>Apache Commons实际上是一个专注于创建Java库的整个项目。以下是该库中最好和最常用的类库：</p>
<p> Commons Math：顾名思义，该库包含许多数学和统计组件</p>
<p> Commons CLI：提供用于解析命令行参数的API。</p>
<p> Commons CSV ：用于读写CSV文件的工具包,由两大核心对象组成 CSVParser（解析），CSVPrinter（写csv）。、</p>
<p> Commons IO：它用于更容易执行输入/输出操作，是针对开发IO流功能的工具类库</p>
<h2 id="5-Guava"><a href="#5-Guava" class="headerlink" title="5. Guava"></a>5. Guava</h2><p>Guava是Google的Java核心库。包含许多 Google 核心的 Java 常用库，这个库超级实用，里面我最喜欢的组件之一的就是：ComparisonChain用于为集合实现高级和复杂的比较排序。</p>
<h2 id="6-google-gson"><a href="#6-google-gson" class="headerlink" title="6. google-gson"></a>6. google-gson</h2><p>gson 是 Google 提供的用来在 Java 对象和 JSON 数据之间进行映射的 Java 类库。此库在开发移动应用程序和创建/使用REST API时非常有用。</p>
<h2 id="7-Hibernate-ORM"><a href="#7-Hibernate-ORM" class="headerlink" title="7. Hibernate-ORM"></a>7. Hibernate-ORM</h2><p>Hibernate是一种Java语言下的对象关系映射解决方案。它用于在关系数据库中保存数据，对JDBC进行了非常轻量级的对象封装，Hibernate也是JPA规范的一个实现。</p>
<h2 id="8-Mockito"><a href="#8-Mockito" class="headerlink" title="8. Mockito"></a>8. Mockito</h2><p>Mockito不是无酒精混合饮料，而是一个针对Java的mocking框架，Mockito使你可以使用更简单，更简洁的代码创建模拟和编写测试。总而言之，Mockito可以极大地简化单元测试的书写过程</p>
<h2 id="9-JUnit"><a href="#9-JUnit" class="headerlink" title="9. JUnit"></a>9. JUnit</h2><p>JUnit是一个Java语言的单元测试框架， JUnit有它自己的JUnit扩展生态圈，不过，不能单纯拿代码覆盖率来评估测试的好坏，有时候覆盖率越大并不代表你的软件质量越好。</p>
<h2 id="10-Log4j-和-Slf4j"><a href="#10-Log4j-和-Slf4j" class="headerlink" title="10. Log4j 和 Slf4j"></a>10. Log4j 和 Slf4j</h2><p>这两个都是日志框架。Slf4j为各种loging APIs提供一个简单统一的接口。Log4j只是一个简单的日志框架，控制日志的生成过程。</p>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>10大最高效的Java库盘点</tag>
      </tags>
  </entry>
  <entry>
    <title>AI思考</title>
    <url>/2020/08/25/AI%E6%80%9D%E8%80%83/</url>
    <content><![CDATA[<p>图灵测试（The Turing test）由艾伦·麦席森·图灵发明，指测试者与被测试者（一个人和一台机器）隔开的情况下，<br>通过一些装置（如键盘）向被测试者随意提问。<br>进行多次测试后，如果有超过30%的测试者不能确定出被测试者是人还是机器，<br>那么这台机器就通过了测试，并被认为具有人类智能。</p>
<p>图灵测试一词来源于计算机科学和密码学的先驱阿兰·麦席森·图灵写于1950年的一篇论文《计算机器与智能》，<br>其中30%是图灵对2000年时的机器思考能力的一个预测，目前我们已远远落后于这个预测</p>
<h2 id="图灵还对人工智能的发展给出了非常有益的建议："><a href="#图灵还对人工智能的发展给出了非常有益的建议：" class="headerlink" title="图灵还对人工智能的发展给出了非常有益的建议："></a>图灵还对人工智能的发展给出了非常有益的建议：</h2><p>与其去研制模拟成人思维的计算机，不如去试着制造更简单，也许只相当于一个小孩智慧的人工智能系统，<br>然后再让这个系统不断去学习——这种思路正是我们今天用机器学习来解决人工智能问题的核心指导思想。</p>
<p>AI is a fascinating area and I personally feel it will not do justice to explain it without looking at it from multiple dimensions. I have provided my point of view on AI in the following dimensions,</p>
<p>Guardrails for AI (starting with, “just because you can doesn’t mean you should”)<br>Core &amp; essential building blocks<br>Types of data AI systems work on<br>Primary characteristics of an AI system<br>Different types of AI (yawn!)<br>Types of approaches to train / teach AI systems<br>Top Algorithms<br>Most common AI workloads/tasks<br>Common examples of AI systems at work<br>Dev Ops for AI — how are AI systems built?<br>Popular Platform, API’s, Libraries &amp; Frameworks<br>Some of the absolute concepts and topics you need to take time in knowing<br>What’s next for AI?</p>
<p>人工智能是一个引人入胜的领域，我个人认为，如果不从多个角度审视人工智能，就无法公正地对其进行解释。我从以下几个方面对AI提出了自己的看法，</p>
<p>AI的Guardrails （从这里开始，只是因为您可以做到并不意味着您应该这样做”）<br>核心和必要的构建基块<br>数据AI系统的工作类型<br>人工智能系统的主要特征<br>不同类型的AI（打哈欠！）<br>训练/教导AI系统的方法类型<br>热门算法<br>最常见的AI工作负载/任务<br>工作中的AI系统的常见示例<br>面向AI的Dev Ops-如何构建AI系统？<br>流行平台，API，库和框架<br>您需要花一些时间来了解的一些绝对概念和主题<br>人工智能的下一步是什么？</p>
]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title>卷积神经网络(CNN)反向传播算法</title>
    <url>/2019/05/23/CNN/</url>
    <content><![CDATA[<pre><code>   ##  卷积神经网络(CNN)反向传播算法</code></pre>
<p>在卷积神经网络(CNN)前向传播算法中，我们对CNN的前向传播算法做了总结，基于CNN前向传播算法的基础，我们下面就对CNN的反向传播算法做一个总结。在阅读本文前，建议先研究DNN的反向传播算法：深度神经网络（DNN）反向传播算法(BP)</p>
<h3 id="1-回顾DNN的反向传播算法"><a href="#1-回顾DNN的反向传播算法" class="headerlink" title="1. 回顾DNN的反向传播算法"></a>1. 回顾DNN的反向传播算法</h3><p>我们首先回顾DNN的反向传播算法。在DNN中，我们是首先计算出输出层的\deltaL:\deltaL=∂J(W,b)∂zL=∂J(W,b)∂aL⊙σ′(zL)<br>\deltaL:\deltaL=∂J(W,b)∂zL=∂J(W,b)∂aL⊙σ′(zL)<br>利用数学归纳法，用δl+1<br>δl+1<br>的值一步步的向前求出第l层的\deltal<br>\deltal<br>，表达式为：δl=δl+1∂zl+1∂zl=(Wl+1)Tδl+1⊙σ′(zl)<br>δl=δl+1∂zl+1∂zl=(Wl+1)Tδl+1⊙σ′(zl)<br>有了δl<br>δl<br>的表达式，从而求出W,b的梯度表达式：</p>
<p>∂J(W,b)∂Wl=∂J(W,b,x,y)∂zl∂zl∂Wl=δl(al−1)T<br>∂J(W,b)∂Wl=∂J(W,b,x,y)∂zl∂zl∂Wl=δl(al−1)T<br>∂J(W,b,x,y)∂bl=∂J(W,b)∂zl∂zl∂bl=δl<br>∂J(W,b,x,y)∂bl=∂J(W,b)∂zl∂zl∂bl=δl<br>有了W,b梯度表达式，就可以用梯度下降法来优化W,b,求出最终的所有W,b的值。</p>
<p>现在我们想把同样的思想用到CNN中，很明显，CNN有些不同的地方，不能直接去套用DNN的反向传播算法的公式。</p>
<h3 id="2-CNN的反向传播算法思想"><a href="#2-CNN的反向传播算法思想" class="headerlink" title="2. CNN的反向传播算法思想"></a>2. CNN的反向传播算法思想</h3><p>要套用DNN的反向传播算法到CNN，有几个问题需要解决：</p>
<p>1）池化层没有激活函数，这个问题倒比较好解决，我们可以令池化层的激活函数为σ(z)<br>σ(z)<br>= z，即激活后就是自己本身。这样池化层激活函数的导数为1.</p>
<p>2）池化层在前向传播的时候，对输入进行了压缩，那么我们现在需要向前反向推导δl−1<br>δl−1<br>，这个推导方法和DNN完全不同。</p>
<ol start="3">
<li>卷积层是通过张量卷积，或者说若干个矩阵卷积求和而得的当前层的输出，这和DNN很不相同，DNN的全连接层是直接进行矩阵乘法得到当前层的输出。这样在卷积层反向传播的时候，上一层的δl−1<br>δl−1<br>递推计算方法肯定有所不同。</li>
</ol>
<p>4）对于卷积层，由于W使用的运算是卷积，那么从δl<br>δl<br>推导出该层的所有卷积核的W,b的方式也不同。</p>
<p>从上面可以看出，问题1比较好解决，但是问题2,3,4就需要好好的动一番脑筋了，而问题2,3,4也是解决CNN反向传播算法的关键所在。另外大家要注意到的是，DNN中的al,zl<br>al,zl<br>都只是一个向量，而我们CNN中的al,zl<br>al,zl<br>都是一个张量，这个张量是三维的，即由若干个输入的子矩阵组成。</p>
<p>下面我们就针对问题2,3,4来一步步研究CNN的反向传播算法。</p>
<p>在研究过程中，需要注意的是，由于卷积层可以有多个卷积核，各个卷积核的处理方法是完全相同且独立的，为了简化算法公式的复杂度，我们下面提到卷积核都是卷积层中若干卷积核中的一个。</p>
<h3 id="3-已知池化层的-deltal"><a href="#3-已知池化层的-deltal" class="headerlink" title="3. 已知池化层的\deltal"></a>3. 已知池化层的\deltal</h3><p>\deltal<br>，推导上一隐藏层的δl−1<br>δl−1<br>我们首先解决上面的问题2，如果已知池化层的\deltal<br>\deltal<br>，推导出上一隐藏层的δl−1<br>δl−1<br>。</p>
<p>在前向传播算法时，池化层一般我们会用MAX或者Average对输入进行池化，池化的区域大小已知。现在我们反过来，要从缩小后的误差δl<br>δl<br>，还原前一次较大区域对应的误差。</p>
<p>在反向传播时，我们首先会把\deltal<br>\deltal<br>的所有子矩阵大小还原成池化之前的大小，然后如果是MAX，则把\deltal<br>\deltal<br>的所有子矩阵的各个池化局域的值放在之前做前向传播算法得到最大值的位置。如果是Average，则把δl<br>δl<br>的所有子矩阵的各个池化局域的值取平均后放在还原后的子矩阵位置。这个过程一般叫做upsample。</p>
<p>用一个例子可以很方便的表示：假设我们的池化区域大小是2x2。\deltal<br>\deltal<br>的第k个子矩阵为:δkl=(28 46)<br>δkl=(28 46)<br>由于池化区域为2x2，我们先讲δlk<br>δkl<br>做还原，即变成：(0000 0280 0460 0000)<br>(0000 0280 0460 0000)<br>如果是MAX，假设我们之前在前向传播时记录的最大值位置分别是左上，右下，右上，左下，则转换后的矩阵为：(2000 0008 0400 0060)<br>(2000 0008 0400 0060)<br>如果是Average，则进行平均：转换后的矩阵为：(0.50.522 0.50.522 111.51.5 111.51.5)<br>(0.50.522 0.50.522 111.51.5 111.51.5)<br>这样我们就得到了上一层 ∂J(W,b)∂akl−1<br>∂J(W,b)∂akl−1<br>的值，要得到δkl−1<br>δkl−1<br>：δkl−1=∂J(W,b)∂akl−1∂akl−1∂zkl−1=upsample(δkl)⊙σ′(zl−1k)<br>δkl−1=∂J(W,b)∂akl−1∂akl−1∂zkl−1=upsample(δkl)⊙σ′(zkl−1)<br>其中，upsample函数完成了池化误差矩阵放大与误差重新分配的逻辑。</p>
<p>我们概括下，对于张量δl−1<br>δl−1<br>，我们有：δl−1=upsample(\deltal)⊙σ′(zl−1)<br>δl−1=upsample(\deltal)⊙σ′(zl−1)</p>
<h3 id="4-已知卷积层的-deltal"><a href="#4-已知卷积层的-deltal" class="headerlink" title="4. 已知卷积层的\deltal"></a>4. 已知卷积层的\deltal</h3><p>\deltal<br>，推导上一隐藏层的δl−1<br>δl−1<br>对于卷积层的反向传播，我们首先回忆下卷积层的前向传播公式：al=σ(zl)=σ(al−1∗Wl+bl)<br>al=σ(zl)=σ(al−1∗Wl+bl)<br>其中nin<br>nin<br>为上一隐藏层的输入子矩阵个数。</p>
<p>在DNN中，我们知道δl−1<br>δl−1<br>和δl<br>δl<br>的递推关系为：δl=∂J(W,b)∂zl=∂J(W,b)∂zl+1∂zl+1∂zl=δl+1∂zl+1∂zl<br>δl=∂J(W,b)∂zl=∂J(W,b)∂zl+1∂zl+1∂zl=δl+1∂zl+1∂zl<br>因此要推导出δl−1<br>δl−1<br>和δl<br>δl<br>的递推关系，必须计算∂zl∂zl−1<br>∂zl∂zl−1<br>的梯度表达式。</p>
<p>注意到zl<br>zl<br>和zl−1<br>zl−1<br>的关系为：zl=al−1∗Wl+bl=σ(zl−1)∗Wl+bl<br>zl=al−1∗Wl+bl=σ(zl−1)∗Wl+bl<br>因此我们有：δl−1=δl∂zl∂zl−1=δl∗rot180(Wl)⊙σ′(zl−1)<br>δl−1=δl∂zl∂zl−1=δl∗rot180(Wl)⊙σ′(zl−1)<br>这里的式子其实和DNN的类似，区别在于对于含有卷积的式子求导时，卷积核被旋转了180度。即式子中的rot180()<br>rot180()<br>，翻转180度的意思是上下翻转一次，接着左右翻转一次。在DNN中这里只是矩阵的转置。那么为什么呢？由于这里都是张量，直接推演参数太多了。我们以一个简单的例子说明为啥这里求导后卷积核要翻转。</p>
<p>假设我们l-1层的输出al−1<br>al−1<br>是一个3x3矩阵，第l层的卷积核Wl<br>Wl<br>是一个2x2矩阵，采用1像素的步幅，则输出zl<br>zl<br>是一个2x2的矩阵。我们简化bl<br>bl<br>都是0,则有al−1∗Wl=zl<br>al−1∗Wl=zl<br>我们列出a,W,z的矩阵表达式如下：(a11a12a13 a21a22a23 a31a32a33)∗(w11w12 w21w22)=(z11z12 z21z22)<br>(a11a12a13 a21a22a23 a31a32a33)∗(w11w12 w21w22)=(z11z12 z21z22)<br>利用卷积的定义，很容易得出：</p>
<p>z11=a11w11+a12w12+a21w21+a22w22<br>z11=a11w11+a12w12+a21w21+a22w22<br>z12=a12w11+a13w12+a22w21+a23w22<br>z12=a12w11+a13w12+a22w21+a23w22<br>z21=a21w11+a22w12+a31w21+a32w22<br>z21=a21w11+a22w12+a31w21+a32w22<br>z22=a22w11+a23w12+a32w21+a33w22<br>z22=a22w11+a23w12+a32w21+a33w22<br>接着我们模拟反向求导：∇al−1=∂J(W,b)∂al−1=∂J(W,b)∂zl∂zl∂al−1=δl∂zl∂al−1<br>∇al−1=∂J(W,b)∂al−1=∂J(W,b)∂zl∂zl∂al−1=δl∂zl∂al−1<br>从上式可以看出，对于al−1<br>al−1<br>的梯度误差∇al−1<br>∇al−1<br>，等于第l层的梯度误差乘以∂zl∂al−1<br>∂zl∂al−1<br>，而∂zl∂al−1<br>∂zl∂al−1<br>对应上面的例子中相关联的w的值。假设我们的z矩阵对应的反向传播误差是δ11,δ12,δ21,δ22<br>δ11,δ12,δ21,δ22<br>组成的2x2矩阵，则利用上面梯度的式子和4个等式，我们可以分别写出∇al−1<br>∇al−1<br>的9个标量的梯度。</p>
<p>比如对于a11<br>a11<br>的梯度，由于在4个等式中a11<br>a11<br>只和z11<br>z11<br>有乘积关系，从而我们有：∇a11=δ11w11<br>∇a11=δ11w11<br>对于a12<br>a12<br>的梯度，由于在4个等式中a12<br>a12<br>和z12,z11<br>z12,z11<br>有乘积关系，从而我们有：∇a12=δ11w12+δ12w11<br>∇a12=δ11w12+δ12w11<br>同样的道理我们得到：</p>
<p>∇a13=δ12w12<br>∇a13=δ12w12<br>∇a21=δ11w21+δ21w11<br>∇a21=δ11w21+δ21w11<br>∇a22=δ11w22+δ12w21+δ21w12+δ22w11<br>∇a22=δ11w22+δ12w21+δ21w12+δ22w11<br>∇a23=δ12w22+δ22w12<br>∇a23=δ12w22+δ22w12<br>∇a31=δ21w21<br>∇a31=δ21w21<br>∇a32=δ21w22+δ22w21<br>∇a32=δ21w22+δ22w21<br>∇a33=δ22w22<br>∇a33=δ22w22<br>这上面9个式子其实可以用一个矩阵卷积的形式表示，即：</p>
<p>(0000 0δ11δ120 0δ21δ220 0000)∗(w22w21 w12w11)=(∇a11∇a12∇a13 ∇a21∇a22∇a23 ∇a31∇a32∇a33)<br>(0000 0δ11δ120 0δ21δ220 0000)∗(w22w21 w12w11)=(∇a11∇a12∇a13 ∇a21∇a22∇a23 ∇a31∇a32∇a33)<br>为了符合梯度计算，我们在误差矩阵周围填充了一圈0，此时我们将卷积核翻转后和反向传播的梯度误差进行卷积，就得到了前一次的梯度误差。这个例子直观的介绍了为什么对含有卷积的式子求导时，卷积核要翻转180度的原因。</p>
<p>以上就是卷积层的误差反向传播过程。</p>
<h3 id="5-已知卷积层的δl"><a href="#5-已知卷积层的δl" class="headerlink" title="5. 已知卷积层的δl"></a>5. 已知卷积层的δl</h3><p>δl<br>，推导该层的W,b的梯度<br>好了，我们现在已经可以递推出每一层的梯度误差δl<br>δl<br>了，对于全连接层，可以按DNN的反向传播算法求该层W,b的梯度，而池化层并没有W,b,也不用求W,b的梯度。只有卷积层的W,b需要求出。</p>
<p>注意到卷积层z和W,b的关系为：zl=al−1∗Wl+b<br>zl=al−1∗Wl+b<br>因此我们有：∂J(W,b)∂Wl=∂J(W,b)∂zl∂zl∂Wl=\deltal∗rot180(al−1)<br>∂J(W,b)∂Wl=∂J(W,b)∂zl∂zl∂Wl=\deltal∗rot180(al−1)<br>由于我们有上一节的基础，大家应该清楚为什么这里求导后al−1<br>al−1<br>要旋转180度了。</p>
<p>而对于b,则稍微有些特殊，因为\deltal<br>\deltal<br>是三维张量，而b只是一个向量，不能像DNN那样直接和\deltal<br>\deltal<br>相等。通常的做法是将\deltal<br>\deltal<br>的各个子矩阵的项分别求和，得到一个误差向量，即为b的梯度：∂J(W,b)∂bl=∑u,v(δl)u,v<br>∂J(W,b)∂bl=∑u,v(δl)u,v</p>
<h3 id="6-CNN反向传播算法总结"><a href="#6-CNN反向传播算法总结" class="headerlink" title="6. CNN反向传播算法总结"></a>6. CNN反向传播算法总结</h3><p>现在我们总结下CNN的反向传播算法，以最基本的批量梯度下降法为例来描述反向传播算法。</p>
<p>输入：m个图片样本，CNN模型的层数L和所有隐藏层的类型，对于卷积层，要定义卷积核的大小K，卷积核子矩阵的维度F，填充大小P，步幅S。对于池化层，要定义池化区域大小k和池化标准（MAX或Average），对于全连接层，要定义全连接层的激活函数（输出层除外）和各层的神经元个数。梯度迭代参数迭代步长α<br>α<br>,最大迭代次数MAX与停止迭代阈值ϵ<br>ϵ<br>输出：CNN模型各隐藏层与输出层的W,b</p>
<ol>
<li>初始化各隐藏层与输出层的各W,b的值为一个随机值。</li>
</ol>
<p>2）for iter from 1 to MAX：</p>
<p>2-1) for i =1 to m：</p>
<p>a) 将CNN输入a1<br>a1<br>设置为xi<br>xi<br>对应的张量</p>
<p>b) for l=2 to L-1，根据下面3种情况进行前向传播算法计算：</p>
<p>b-1) 如果当前是全连接层：则有ai,l=σ(zi,l)=σ(Wlai,l−1+bi,l)<br>ai,l=σ(zi,l)=σ(Wlai,l−1+bi,l)<br>b-2) 如果当前是卷积层：则有ai,l=σ(zi,l)=σ(Wl∗ai,l−1+bi,l)<br>ai,l=σ(zi,l)=σ(Wl∗ai,l−1+bi,l)<br>b-3) 如果当前是池化层：则有ai,l=pool(ai,l−1)<br>ai,l=pool(ai,l−1)<br>, 这里的pool指按照池化区域大小k和池化标准将输入张量缩小的过程。</p>
<p>c) 对于输出层第L层:ai,L=softmax(zi,L)=softmax(Wi,Lai,L−1+bi,L)<br>ai,L=softmax(zi,L)=softmax(Wi,Lai,L−1+bi,L)<br>c) 通过损失函数计算输出层的δi,L<br>δi,L<br>d) for l= L to 2, 根据下面3种情况进行进行反向传播算法计算:</p>
<p>d-1) 如果当前是全连接层：δi,l=(Wl+1)Tδi,l+1⊙σ′(zi,l)<br>δi,l=(Wl+1)Tδi,l+1⊙σ′(zi,l)<br>d-2) 如果当前是卷积层：δi,l=δi,l+1∗rot180(Wl+1)⊙σ′(zi,l)<br>δi,l=δi,l+1∗rot180(Wl+1)⊙σ′(zi,l)<br>d-3) 如果当前是池化层：δi,l=upsample(δi,l+1)⊙σ′(zi,l)<br>δi,l=upsample(δi,l+1)⊙σ′(zi,l)<br>2-2) for l = 2 to L，根据下面2种情况更新第l层的Wl,bl<br>Wl,bl<br>:</p>
<p>2-2-1) 如果当前是全连接层：Wl=Wl−α∑i=1mδi,l(ai,l−1)T<br>Wl=Wl−α∑i=1mδi,l(ai,l−1)T<br> bl=bl−α∑i=1mδi,l<br>bl=bl−α∑i=1mδi,l<br>2-2-2) 如果当前是卷积层，对于每一个卷积核有：Wl=Wl−α∑i=1mδi,l∗rot180(ai,l−1),bl=bl−α∑i=1m∑u,v(δi,l)u,v<br>Wl=Wl−α∑i=1mδi,l∗rot180(ai,l−1),bl=bl−α∑i=1m∑u,v(δi,l)u,v<br>2-3) 如果所有W，b的变化值都小于停止迭代阈值ϵ<br>ϵ<br>，则跳出迭代循环到步骤3。</p>
<p>3） 输出各隐藏层与输出层的线性关系系数矩阵W和偏倚向量b。</p>
]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>卷积神经网络(CNN)反向传播算法</tag>
      </tags>
  </entry>
  <entry>
    <title>GUI</title>
    <url>/2020/09/03/FUI/</url>
    <content><![CDATA[<pre><code>   GUI开发,JavaFX/Swing/Qt等任意一种界面框架</code></pre>
]]></content>
      <categories>
        <category>GUI</category>
      </categories>
      <tags>
        <tag>GUI开发</tag>
      </tags>
  </entry>
  <entry>
    <title>DNN的反向传播算法</title>
    <url>/2019/07/21/DNN/</url>
    <content><![CDATA[<p>　我们首先回顾DNN的反向传播算法。在DNN中，我们是首先计算出输出层的δLδL:<br>δL=∂J(W,b)∂zL=∂J(W,b)∂aL⊙σ′(zL)<br>δL=∂J(W,b)∂zL=∂J(W,b)∂aL⊙σ′(zL)<br>　　　　利用数学归纳法，用δl+1δl+1的值一步步的向前求出第l层的δlδl，表达式为：<br>δl=(∂zl+1∂zl)Tδl+1=(Wl+1)Tδl+1⊙σ′(zl)<br>δl=(∂zl+1∂zl)Tδl+1=(Wl+1)Tδl+1⊙σ′(zl)<br>　　　　有了δlδl的表达式，从而求出W,bW,b的梯度表达式：<br>∂J(W,b)∂Wl=δl(al−1)T<br>∂J(W,b)∂Wl=δl(al−1)T<br>∂J(W,b,x,y)∂bl==δl<br>∂J(W,b,x,y)∂bl==δl<br>　　　　有了W,bW,b梯度表达式，就可以用梯度下降法来优化W,bW,b,求出最终的所有W,bW,b的值。</p>
<p>　　　　现在我们想把同样的思想用到CNN中，很明显，CNN有些不同的地方，不能直接去套用DNN的反向传播算法的公式。</p>
]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>DNN的反向传播算法</tag>
      </tags>
  </entry>
  <entry>
    <title>LSTM</title>
    <url>/2020/08/23/LSTM/</url>
    <content><![CDATA[<p>长短期记忆（Long short-term memory, LSTM）是一种特殊的RNN，主要是为了解决长序列训练过程中的梯度消失和梯度爆炸问题。简单来说，就是相比普通的RNN，LSTM能够在更长的序列中有更好的表现。</p>
<p> <img src="https://lixinx11.github.io/medias/bigdata/21.png" alt="LSTM"></p>
]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>LSTM</tag>
      </tags>
  </entry>
  <entry>
    <title>RPA</title>
    <url>/2020/08/22/NLP/</url>
    <content><![CDATA[<h2 id="什麼是-RPA？"><a href="#什麼是-RPA？" class="headerlink" title="什麼是 RPA？"></a>什麼是 RPA？</h2><pre><code>2019年至今（2020年初），国产RPA企业已经陆续拿到融资，其中有三起集中发生在6月份，其中一起追加融资发生在8月份，保守估计，
5个国产RPA企业融资总金额在8亿人民币上下，但市场估值已高达54.2亿人民币，资本如此青睐的RPA是何方神圣呢？它是什么样的一个技术呢？


RPA 是既簡單又強大的業務流程自動化軟體。機器人流程自動化讓您能夠使用工具建置自己專屬的軟體機器人，以便將任何業務流程</code></pre>
<p>   自動化。您的「機器人」是可設定的軟體，用於執行您所指派和控制的任務。<br>   RPA 機器人具備學習能力，也可以被複製。了解機器人如何運作，並且依照您的需求進行調整及擴展。不需要使用程式碼、不會中斷作業、非侵入式，而且使用簡易。</p>
<h2 id="揭開流程機器人-RPA-的神秘面紗"><a href="#揭開流程機器人-RPA-的神秘面紗" class="headerlink" title="揭開流程機器人(RPA)的神秘面紗"></a>揭開流程機器人(RPA)的神秘面紗</h2><p>在企業日常營運中，有許多流程往往是仰賴所多的人工在電腦桌面與資訊系統之間的重複作業。流程機器人(RPA)是一種新興的程式軟體工具，它會模擬使用者坐在辦公桌時經常做的事情，將這些重複且枯燥的電腦桌面作業程序自動化，不需經由特殊的硬體設備，能在任何資訊系統(IT)環境中發揮良好的表現，甚至能在電腦後台背景虛擬化的執行工作，這就是流程機器人(RPA)可以做的工作-將重複性高但有邏輯性的作業，以流程機器人(RPA)取代人力的投入。</p>
<p>流程機器人就像是在工廠內的巨型黃色機械手臂，透過它將勞力密集且重複性高的的作業流程自動化，進而改變企業決策的速度。</p>
<p>流程機器人帶給企業的效益</p>
<p>企業內部一般事務性的工作，根據調查，一個“滿載”的流程機器人僅約耗費一般員工三分之一的成本。在財務會計的作業流程自動化應用方面，從日記帳分錄記錄到調整總帳科目，以及轉為各項報表等這些流程都適用流程自動化，目前已經出現非常多的實際應用，流程機器人效率是間接作業人員的15倍，同時趨近於零失誤率的作業執行品質，提供15％至90％的降低成本的機會。</p>
<p>流程機器人不僅可以減少間接人員的人力需求，還提供了其他優勢；因其24X7全天候運行，流程機器人能製作對時間敏感度高的報告，以趕上截止日期。透過流程機器人的執行結果將會更準確，避免數據重複輸入和輸入錯誤所衍生一連串的彌補措施。</p>
<p>讓流程機器人自動化成真</p>
<h3 id="基本上導入流程機器人時，企業通常分成處於兩種狀態："><a href="#基本上導入流程機器人時，企業通常分成處於兩種狀態：" class="headerlink" title="基本上導入流程機器人時，企業通常分成處於兩種狀態："></a>基本上導入流程機器人時，企業通常分成處於兩種狀態：</h3><p>第一種是已經進行過前期試作的企業，正在試圖擴大這項技術；第二種則是正在探索流程機器人可能性的初步評估階段。如果您的組織屬於後者，我們建議的方式就是從一個前期試行專案(Pilot/Prototype)著手，讓企業先熟悉流程機器人的能力。</p>
<p>為了避免資源過度的投入，建議前期試行專案可從選擇三到五個流程開始，藉由試行專案所投入的時間與資源，進而評估效益以及侷限性，確保流程機器人適合業務端的程度。</p>
<p>   <img src="https://lixinx11.github.io/medias/bigdata/12.png" alt="流程自动化"></p>
]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>RPA</tag>
      </tags>
  </entry>
  <entry>
    <title>R语言学习</title>
    <url>/2020/09/23/R/</url>
    <content><![CDATA[<hr>
<pre><code>        ##  R &amp; Python: A Love Story</code></pre>
<p><a href="https://rstudio.com/products/rstudio/download/#download">https://rstudio.com/products/rstudio/download/#download</a></p>
]]></content>
      <categories>
        <category>R</category>
      </categories>
      <tags>
        <tag>R</tag>
      </tags>
  </entry>
  <entry>
    <title>RNN</title>
    <url>/2020/08/23/RNN/</url>
    <content><![CDATA[<p>循環神經網絡（Recurrent neural network：RNN）是神經網絡的一種</p>
<p> <img src="https://lixinx11.github.io/medias/bigdata/22.png" alt="RNN"></p>
]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>RNN</tag>
      </tags>
  </entry>
  <entry>
    <title>Tensorflow</title>
    <url>/2020/07/23/Tensorflow/</url>
    <content><![CDATA[<p> Tensorflow 技术官网  <a href="https://www.tensorflow.org/">https://www.tensorflow.org/</a></p>
<pre><code>TensorFlow是一個強大的機器學習框架、AlphaGo和Google Cloud Vision更建立在TensorFlow之上

深度学习框架TensorFlow入门，带你了解tensorflow实现</code></pre>
<p>tensorflow</p>
<h2 id="先来认识一下TF的价值："><a href="#先来认识一下TF的价值：" class="headerlink" title="先来认识一下TF的价值："></a>先来认识一下TF的价值：</h2><p>TensorFlow，是Google在15年年底发布的机器学习平台，发布以后由于其速度快，扩展性好，推广速度也很快。<br>Google的大战略：Android占领了移动端；TF占领神经网络提供AI服务。未来的趋势恰好是语音图像以及AI的时代。<br>TF的特点之一就是可以支持很多种设备，大到GPU、CPU，小到手机平板，五花八门的设备都可以跑起来TF。不得不说这一点很有前瞻性，可以预见的是，mobile-end的用户将会享受到越来越多的AI服务。<br>系统概述<br>tensorflow技术架构<br> <img src="https://lixinx11.github.io/medias/bigdata/13.png" alt="tensorflow 系统概述"></p>
<h2 id="整个系统从底层到上层可分为七层："><a href="#整个系统从底层到上层可分为七层：" class="headerlink" title="整个系统从底层到上层可分为七层："></a>整个系统从底层到上层可分为七层：</h2><p>最底层是硬件计算资源，支持CPU、GPU；<br>支持两种通信协议；<br>数值计算层提供最基础的计算，有线性计算、卷积计算；<br>数据的计算都是以数组的形式参与计算；<br>计算图层用来设计神经网络的结构；<br>工作流层提供轻量级的框架调用<br>最后构造的深度学习网络可以通过TensorBoard服务端可视化</p>
<h2 id="技术架构"><a href="#技术架构" class="headerlink" title="技术架构"></a>技术架构</h2><p> tensorflow 系统概述<br> <img src="https://lixinx11.github.io/medias/bigdata/14.png" alt="tensorflow 技术架构"></p>
<h2 id="整体技术栈分为两部分："><a href="#整体技术栈分为两部分：" class="headerlink" title="整体技术栈分为两部分："></a>整体技术栈分为两部分：</h2><p>前端系统：提供编程模型，负责构造计算图；<br>后端系统：提供运行时环境，负责执行计算图。</p>
<h2 id="组件交互"><a href="#组件交互" class="headerlink" title="组件交互"></a>组件交互</h2><p>tensorflow组件交互<br> <img src="https://lixinx11.github.io/medias/bigdata/15.png" alt="tensorflow 组件交互"></p>
<h2 id="master节点给两种类型的节点分发任务："><a href="#master节点给两种类型的节点分发任务：" class="headerlink" title="master节点给两种类型的节点分发任务："></a>master节点给两种类型的节点分发任务：</h2><p>/job:ps/task:0: 负责模型参数的存储和更新<br>/job:worker/task:0: 负责模型的训练或推理</p>
<h2 id="会话-Session"><a href="#会话-Session" class="headerlink" title="会话(Session)"></a>会话(Session)</h2><p>tensorflow 会话<br> <img src="https://lixinx11.github.io/medias/bigdata/16.png" alt="tensorflow 会话"><br>客户端使用会话来和TF系统交互，一般的模式是，建立会话，此时会生成一张空图；在会话中添加节点和边，形成一张图，然后执行。</p>
<h2 id="实现（Implementation）"><a href="#实现（Implementation）" class="headerlink" title="实现（Implementation）"></a>实现（Implementation）</h2><p>tensorflow 分布式<br> <img src="https://lixinx11.github.io/medias/bigdata/17.png" alt="tensorflow 实现"><br>TF中最重要的Tensor被支持的非常全面，8bit到64bit， signed和unsigned，IEEE float/double，complex number等等。使用引用计数来保存tensor，当计数到0时，tensor被回收。<br>客户端，用户会使用；与master和一些worker process交流<br>master，用来与客户端交互，同时调度任务；<br>worker process，工作节点，每个worker process可以访问一到多个device。<br>device，TF的计算核心，通过将device的类型、job名称、在worker process中的索引将device命名。可以通过注册机制来添加新的device实现，每个device实现需要负责内存分配和管理调度TF系统所下达的核运算需求。<br>跨设备通信</p>
<p>当两个需要通信的op在不同的机器上时，就需要跨设备通信，当它们需要通信时，TF会在它们之间的联系中添加Send和Recv节点，通过Send和Recv之间进行通信来达到op之间通信的效果。如上所示。<br>梯度计算（ Gradient Computation ）</p>
<h2 id="tensorflow-梯度计算"><a href="#tensorflow-梯度计算" class="headerlink" title="tensorflow 梯度计算"></a>tensorflow 梯度计算</h2><p>连接式的机器学习算法往往需要使用梯度下降法来求取参数，TF通过扩展图的方式实现了自动求导，TF做法如下：<br>对于每张计算图，得到从输入I到输出C的路径，并从C到I回溯，回溯过程中对于路径上的每个节点A，添加另一个节点来计算A’来计算偏导，在计算偏导的过程中，A’不仅仅将上一层传下来的反向导数作为输入，还可能将A的输入和输出也作为其输入。<br>数据并行计算（ Data Parallel Training）<br> <img src="https://lixinx11.github.io/medias/bigdata/18.png" alt="tensorflow 梯度计算"></p>
<h2 id="tensorflow-数据并行计算"><a href="#tensorflow-数据并行计算" class="headerlink" title="tensorflow 数据并行计算"></a>tensorflow 数据并行计算</h2><p>通过数据并行的方式来提升模型的效率，比如，假如每次模型的mini-batch是1000个样本，那么，切成10份，每份100个，然后将模型复制10份，每份都将梯度传到参数服务器上。<br>数据切分也分为同步和异步两种方式，同步的切分是等待每个独立的model传上来的梯度都到齐后再进行更新，这样和一个大的batch没有区别。异步的切分则是不用等待，每个独立的模型的参数更新直接更新。<br>模型并行训练（ Model Parallel Training）<br> <img src="https://lixinx11.github.io/medias/bigdata/19.png" alt="tensorflow 数据并行计算"></p>
<h2 id="tensorflow-模型并行训练"><a href="#tensorflow-模型并行训练" class="headerlink" title="tensorflow 模型并行训练"></a>tensorflow 模型并行训练</h2><p> <img src="https://lixinx11.github.io/medias/bigdata/20.png" alt="tensorflow 模型并行训练"><br>还可以对模型进行切分，让模型的不同部分执行在不同的设备上，这样可以一个迭代的样本可以在不同的设备上同时执行。如上图所示的LSTM模型</p>
]]></content>
      <categories>
        <category>Tensorflow</category>
      </categories>
      <tags>
        <tag>Tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title>ThreadLocal</title>
    <url>/2019/09/21/ThreadLocal/</url>
    <content><![CDATA[<h2 id="彻底理解ThreadLocal"><a href="#彻底理解ThreadLocal" class="headerlink" title="彻底理解ThreadLocal"></a>彻底理解ThreadLocal</h2><p>深挖过threadLocal之后，一句话概括：Synchronized用于线程间的数据共享，而ThreadLocal则用于线程间的数据隔离。所以ThreadLocal的应用场合，最适合的是按线程多实例（每个线程对应一个实例）的对象的访问，并且这个对象很多地方都要用到。</p>
<p>数据隔离的秘诀其实是这样的，Thread有个TheadLocalMap类型的属性，叫做threadLocals，该属性用来保存该线程本地变量。这样每个线程都有自己的数据，就做到了不同线程间数据的隔离，保证了数据安全。</p>
<p>接下来采用jdk1.8源码进行深挖一下TheadLocal和TheadLocalMap。</p>
<h2 id="ThreadLocal是什么"><a href="#ThreadLocal是什么" class="headerlink" title="ThreadLocal是什么"></a>ThreadLocal是什么</h2><p>早在JDK 1.2的版本中就提供java.lang.ThreadLocal，ThreadLocal为解决多线程程序的并发问题提供了一种新的思路。使用这个工具类可以很简洁地编写出优美的多线程程序。</p>
<p>当使用ThreadLocal维护变量时，ThreadLocal为每个使用该变量的线程提供独立的变量副本，所以每一个线程都可以独立地改变自己的副本，而不会影响其它线程所对应的副本。</p>
<p>从线程的角度看，目标变量就象是线程的本地变量，这也是类名中“Local”所要表达的意思。</p>
<p>所以，在Java中编写线程局部变量的代码相对来说要笨拙一些，因此造成线程局部变量没有在Java开发者中得到很好的普及。</p>
<h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>ThreadLocal，连接ThreadLocalMap和Thread。来处理Thread的TheadLocalMap属性，包括init初始化属性赋值、get对应的变量，set设置变量等。通过当前线程，获取线程上的ThreadLocalMap属性，对数据进行get、set等操作。</p>
<p>ThreadLocalMap，用来存储数据，采用类似hashmap机制，存储了以threadLocal为key，需要隔离的数据为value的Entry键值对数组结构。</p>
<p>ThreadLocal，有个ThreadLocalMap类型的属性，存储的数据就放在这儿。</p>
<h2 id="ThreadLocal、ThreadLocal、Thread之间的关系"><a href="#ThreadLocal、ThreadLocal、Thread之间的关系" class="headerlink" title="ThreadLocal、ThreadLocal、Thread之间的关系"></a>ThreadLocal、ThreadLocal、Thread之间的关系</h2><p>ThreadLocalMap是ThreadLocal内部类，由ThreadLocal创建，Thread有ThreadLocal.ThreadLocalMap类型的属性</p>
<h2 id="ThreadLocalMap简介"><a href="#ThreadLocalMap简介" class="headerlink" title="ThreadLocalMap简介"></a>ThreadLocalMap简介</h2><p>看名字就知道是个map，没错，这就是个hashMap机制实现的map，用Entry数组来存储键值对，key是ThreadLocal对象，value则是具体的值。值得一提的是，为了方便GC，Entry继承了WeakReference，也就是弱引用。里面有一些具体关于如何清理过期的数据、扩容等机制，思路基本和hashmap差不多，有兴趣的可以自行阅读了解，这边只需知道大概的数据存储结构即可。</p>
<h2 id="Thread同步机制的比较"><a href="#Thread同步机制的比较" class="headerlink" title="Thread同步机制的比较"></a>Thread同步机制的比较</h2><p>ThreadLocal和线程同步机制相比有什么优势呢？</p>
<p>Synchronized用于线程间的数据共享，而ThreadLocal则用于线程间的数据隔离。</p>
<p>在同步机制中，通过对象的锁机制保证同一时间只有一个线程访问变量。这时该变量是多个线程共享的，使用同步机制要求程序慎密地分析什么时候对变量进行读写，什么时候需要锁定某个对象，什么时候释放对象锁等繁杂的问题，程序设计和编写难度相对较大。</p>
<p>而ThreadLocal则从另一个角度来解决多线程的并发访问。ThreadLocal会为每一个线程提供一个独立的变量副本，从而隔离了多个线程对数据的访问冲突。因为每一个线程都拥有自己的变量副本，从而也就没有必要对该变量进行同步了。ThreadLocal提供了线程安全的共享对象，在编写多线程代码时，可以把不安全的变量封装进ThreadLocal。</p>
<p>概括起来说，对于多线程资源共享的问题，同步机制采用了“以时间换空间”的方式，而ThreadLocal采用了“以空间换时间”的方式。前者仅提供一份变量，让不同的线程排队访问，而后者为每一个线程都提供了一份变量，因此可以同时访问而互不影响。</p>
<p>Spring使用ThreadLocal解决线程安全问题我们知道在一般情况下，只有无状态的Bean才可以在多线程环境下共享，在Spring中，绝大部分Bean都可以声明为singleton作用域。就是因为Spring对一些Bean（如RequestContextHolder、TransactionSynchronizationManager、LocaleContextHolder等）中非线程安全状态采用ThreadLocal进行处理，让它们也成为线程安全的状态，因为有状态的Bean就可以在多线程中共享了。</p>
<p>一般的Web应用划分为展现层、服务层和持久层三个层次，在不同的层中编写对应的逻辑，下层通过接口向上层开放功能调用。在一般情况下，从接收请求到返回响应所经过的所有程序调用都同属于一个线程。</p>
<p>同一线程贯通三层这样你就可以根据需要，将一些非线程安全的变量以ThreadLocal存放，在同一次请求响应的调用线程中，所有关联的对象引用到的都是同一个变量。</p>
<p>下面的实例能够体现Spring对有状态Bean的改造思路：</p>
<p>TestDao：非线程安全</p>
<p>public class TestDao {<br>    private Connection conn;// ①一个非线程安全的变量</p>
<pre><code>public void addTopic() throws SQLException &#123;
    Statement stat = conn.createStatement();// ②引用非线程安全变量
    // …
&#125;</code></pre>
<p>由于conn是成员变量，因为addTopic()方法是非线程安全的，必须在使用时创建一个新TopicDao实例（非singleton）。下面使用ThreadLocal对conn这个非线程安全的“状态”进行改造：</p>
<p>TestDao：线程安全</p>
<p>public class TestDaoNew {// ①使用ThreadLocal保存Connection变量<br>  private static ThreadLocal<Connection> connThreadLocal = ThreadLocal.withInitial(Test::createConnection);</p>
<p>  // 具体创建数据库连接的方法<br>  private static Connection createConnection() {<br>    Connection result = null;<br>    /**<br>     * create a real connection…<br>     * such as :<br>     * result = DriverManager.getConnection(dbUrl, dbUser, dbPwd);<br>     */<br>    return result;<br>  }</p>
<p>  // ③直接返回线程本地变量<br>  public static Connection getConnection() {<br>    return connThreadLocal.get();<br>  }</p>
<p>  // 具体操作<br>  public void addTopic() throws SQLException {<br>    // ④从ThreadLocal中获取线程对应的Connection<br>    Statement stat = getConnection().createStatement();<br>    //….any other operation<br>  }<br>}</p>
<p>不同的线程在使用TopicDao时，根据之前的深挖get具体操作，判断connThreadLocal.get()会去判断是有map，没有则根据initivalValue创建一个Connection对象并添加到本地线程变量中，initivalValue对应的值也就是上述的lamba表达式对应的创建connection的方法返回的结果，下次get则由于已经有了，则会直接获取已经创建好的Connection，这样，就保证了不同的线程使用线程相关的Connection，而不会使用其它线程的Connection。因此，这个TopicDao就可以做到singleton共享了。</p>
<p>当然，这个例子本身很粗糙，将Connection的ThreadLocal直接放在DAO只能做到本DAO的多个方法共享Connection时不发生线程安全问题，但无法和其它DAO共用同一个Connection，要做到同一事务多DAO共享同一Connection，必须在一个共同的外部类使用ThreadLocal保存Connection。</p>
<p>ConnectionManager.java</p>
<p>public class ConnectionManager {</p>
<pre><code>private static ThreadLocal&lt;Connection&gt; connectionHolder = ThreadLocal.withInitial(() -&gt; &#123;
    Connection conn = null;
    try &#123;
        conn = DriverManager.getConnection(
                &quot;jdbc:mysql://localhost:3306/test&quot;, &quot;username&quot;,
                &quot;password&quot;);
    &#125; catch (SQLException e) &#123;
        e.printStackTrace();
    &#125;
    return conn;
&#125;);

public static Connection getConnection() &#123;
    return connectionHolder.get();
&#125;</code></pre>
<p>}</p>
<h2 id="线程隔离的秘密"><a href="#线程隔离的秘密" class="headerlink" title="线程隔离的秘密"></a>线程隔离的秘密</h2><p>秘密就就在于上述叙述的ThreadLocalMap这个类。ThreadLocalMap是ThreadLocal类的一个静态内部类，它实现了键值对的设置和获取（对比Map对象来理解），每个线程中都有一个独立的ThreadLocalMap副本，它所存储的值，只能被当前线程读取和修改。ThreadLocal类通过操作每一个线程特有的ThreadLocalMap副本，从而实现了变量访问在不同线程中的隔离。因为每个线程的变量都是自己特有的，完全不会有并发错误。还有一点就是，ThreadLocalMap存储的键值对中的键是this对象指向的ThreadLocal对象，而值就是你所设置的对象了。</p>
<p>为了加深理解，我们接着看上面代码中出现的getMap和createMap方法的实现：</p>
<pre><code>/**
 * Get the map associated with a ThreadLocal. Overridden in
 * InheritableThreadLocal.
 *
 * @param  t the current thread
 * @return the map
 */
ThreadLocalMap getMap(Thread t) &#123;
    return t.threadLocals;
&#125;

/**
 * Create the map associated with a ThreadLocal. Overridden in
 * InheritableThreadLocal.
 *
 * @param t the current thread
 * @param firstValue value for the initial entry of the map
 * @param map the map to store.
 */
void createMap(Thread t, T firstValue) &#123;
    t.threadLocals = new ThreadLocalMap(this, firstValue);
&#125;</code></pre>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>ThreadLocal是解决线程安全问题一个很好的思路，它通过为每个线程提供一个独立的变量副本解决了变量并发访问的冲突问题。在很多情况下，ThreadLocal比直接使用synchronized同步机制解决线程安全问题更简单，更方便，且结果程序拥有更高的并发性。</p>
]]></content>
      <categories>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>彻底理解ThreadLocal</tag>
      </tags>
  </entry>
  <entry>
    <title>时光角落</title>
    <url>/2020/09/03/book/</url>
    <content><![CDATA[<pre><code>思考是人类最大的乐趣之一 --布莱希特</code></pre>
<h1 id="休闲时读的一本书："><a href="#休闲时读的一本书：" class="headerlink" title="休闲时读的一本书："></a>休闲时读的一本书：</h1><p>  软件创新之路：冲破高技术营造的牢笼</p>
]]></content>
      <categories>
        <category>book</category>
      </categories>
      <tags>
        <tag>时光角落</tag>
      </tags>
  </entry>
  <entry>
    <title>Dockerfile 定制镜像</title>
    <url>/2018/08/21/dockerfile/</url>
    <content><![CDATA[<p>从前面一节的docker commit的学习中，我们可以了解到，镜像的定制实际上就是定制每一层所添加的配置、文件等信息，但是命令毕竟只是命令，每次定制都得去重复执行这个命令，而且还不够直观，如果我们可以把每一层修改、安装、构建、操作的命令都写入一个脚本，用这个脚本来构建、定制镜像，那么这些问题不就都可以解决了吗？对的，这个脚本就是我们说的Dockerfile。</p>
<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>Dockerfile 是一个文本文件，其内包含了一条条的指令(Instruction)，每一条指令构建一层，因此每一条指令的内容，就是描述该层应当如何构建。</p>
<p>还以之前定制 nginx 镜像为例，这次我们使用 Dockerfile 来定制。在一个空白目录中，建立一个文本文件，并命名为 Dockerfile：</p>
<p>$ mkdir mynginx<br>$ cd mynginx<br>$ touch Dockerfile<br>其内容为：</p>
<p>FROM nginx<br>RUN echo ‘<h1>Hello, Docker!</h1>‘ &gt; /usr/share/nginx/html/index.html<br>这个 Dockerfile 很简单，一共就两行。涉及到了两条指令，FROM 和 RUN。</p>
<h2 id="FROM-指定基础镜像"><a href="#FROM-指定基础镜像" class="headerlink" title="FROM 指定基础镜像"></a>FROM 指定基础镜像</h2><p>所谓定制镜像，那一定是以一个镜像为基础，在其上进行定制。就像我们之前运行了一个 nginx 镜像的容器，再进行修改一样，基础镜像是必须指定的。而FROM就是指定基础镜像，因此一个 Dockerfile 中 FROM 是必备的指令，并且必须是第一条指令。</p>
<p>在Docker Store上有非常多的高质量的官方镜像，有可以直接拿来使用的服务类的镜像，如 nginx、redis、mongo、mysql、httpd、php、tomcat 等；也有一些方便开发、构建、运行各种语言应用的镜像，如 node、openjdk、python、ruby、golang 等。可以在其中寻找一个最符合我们最终目标的镜像为基础镜像进行定制。</p>
<p>如果没有找到对应服务的镜像，官方镜像中还提供了一些更为基础的操作系统镜像，如 ubuntu、debian、centos、fedora、alpine 等，这些操作系统的软件库为我们提供了更广阔的扩展空间。</p>
<p>除了选择现有镜像为基础镜像外，Docker 还存在一个特殊的镜像，名为scratch。这个镜像是虚拟的概念，并不实际存在，它表示一个空白的镜像。</p>
<p>FROM scratch<br>…<br>如果你以scratch为基础镜像的话，意味着你不以任何镜像为基础，接下来所写的指令将作为镜像第一层开始存在。有的同学可能感觉很奇怪，没有任何基础镜像，我怎么去执行我的程序呢，其实对于 Linux 下静态编译的程序来说，并不需要有操作系统提供运行时支持，所需的一切库都已经在可执行文件里了，因此直接FROM scratch会让镜像体积更加小巧。使用 Go 语言 开发的应用很多会使用这种方式来制作镜像，这也是为什么有人认为 Go 是特别适合容器微服务架构的语言的原因之一。</p>
<h2 id="RUN-执行命令"><a href="#RUN-执行命令" class="headerlink" title="RUN 执行命令"></a>RUN 执行命令</h2><p>RUN指令是用来执行命令行命令的。由于命令行的强大能力，RUN指令在定制镜像时是最常用的指令之一。其格式有两种：</p>
<p>shell 格式：RUN &lt;命令&gt;，就像直接在命令行中输入的命令一样。刚才写的 Dockerfile 中的 RUN 指令就是这种格式。<br>RUN echo ‘<h1>Hello, Docker!</h1>‘ &gt; /usr/share/nginx/html/index.html<br>exec 格式：RUN [“可执行文件”, “参数1”, “参数2”]，这更像是函数调用中的格式。 既然 RUN 就像 Shell 脚本一样可以执行命令，那么我们是否就可以像 Shell 脚本一样把每个命令对应一个 RUN 呢？比如这样：<br>FROM debian:jessie<br>RUN apt-get update<br>RUN apt-get install -y gcc libc6-dev make<br>RUN wget -O redis.tar.gz “<a href="http://download.redis.io/releases/redis-3.2.5.tar.gz&quot;">http://download.redis.io/releases/redis-3.2.5.tar.gz&quot;</a><br>RUN mkdir -p /usr/src/redis<br>RUN tar -xzf redis.tar.gz -C /usr/src/redis –strip-components=1<br>RUN make -C /usr/src/redis<br>RUN make -C /usr/src/redis install<br>之前说过，Dockerfile 中每一个指令都会建立一层，RUN 也不例外。每一个 RUN 的行为，就和刚才我们手工建立镜像的过程一样：新建立一层，在其上执行这些命令，执行结束后，commit 这一层的修改，构成新的镜像。</p>
<p>而上面的这种写法，创建了 7 层镜像。这是完全没有意义的，而且很多运行时不需要的东西，都被装进了镜像里，比如编译环境、更新的软件包等等。结果就是产生非常臃肿、非常多层的镜像，不仅仅增加了构建部署的时间，也很容易出错。 这是很多初学 Docker 的人常犯的一个错误。</p>
<p>Union FS 是有最大层数限制的，比如 AUFS，曾经是最大不得超过 42 层，现在是不得超过 127 层。</p>
<p>上面的 Dockerfile 正确的写法应该是这样：</p>
<p>FROM debian:jessie<br>RUN buildDeps=’gcc libc6-dev make’ <br>    &amp;&amp; apt-get update <br>    &amp;&amp; apt-get install -y $buildDeps <br>    &amp;&amp; wget -O redis.tar.gz “<a href="http://download.redis.io/releases/redis-3.2.5.tar.gz&quot;">http://download.redis.io/releases/redis-3.2.5.tar.gz&quot;</a> <br>    &amp;&amp; mkdir -p /usr/src/redis <br>    &amp;&amp; tar -xzf redis.tar.gz -C /usr/src/redis –strip-components=1 <br>    &amp;&amp; make -C /usr/src/redis <br>    &amp;&amp; make -C /usr/src/redis install <br>    &amp;&amp; rm -rf /var/lib/apt/lists/* <br>    &amp;&amp; rm redis.tar.gz <br>    &amp;&amp; rm -r /usr/src/redis <br>    &amp;&amp; apt-get purge -y –auto-remove $buildDeps<br>首先，之前所有的命令只有一个目的，就是编译、安装 redis 可执行文件。因此没有必要建立很多层，这只是一层的事情。因此，这里没有使用很多个 RUN 对一一对应不同的命令，而是仅仅使用一个 RUN 指令，并使用&amp;&amp;将各个所需命令串联起来。将之前的 7 层，简化为了 1 层。在撰写 Dockerfile 的时候，要经常提醒自己，这并不是在写 Shell 脚本，而是在定义每一层该如何构建。</p>
<p>并且，这里为了格式化还进行了换行。Dockerfile 支持 Shell 类的行尾添加\的命令换行方式，以及行首#进行注释的格式。良好的格式，比如换行、缩进、注释等，会让维护、排障更为容易，这是一个比较好的习惯。</p>
<p>此外，还可以看到这一组命令的最后添加了清理工作的命令，删除了为了编译构建所需要的软件，清理了所有下载、展开的文件，并且还清理了 apt 缓存文件。这是很重要的一步，我们之前说过，镜像是多层存储，每一层的东西并不会在下一层被删除，会一直跟随着镜像。因此镜像构建时，一定要确保每一层只添加真正需要添加的东西，任何无关的东西都应该清理掉。 很多人初学 Docker 制作出了很臃肿的镜像的原因之一，就是忘记了每一层构建的最后一定要清理掉无关文件。</p>
<h2 id="构建镜像"><a href="#构建镜像" class="headerlink" title="构建镜像"></a>构建镜像</h2><p>好了，让我们再回到之前定制的 nginx 镜像的 Dockerfile 来。现在我们明白了这个 Dockerfile的内容，那么让我们来构建这个镜像吧。在 Dockerfile 文件所在目录执行：</p>
<p>$ docker build -t nginx:v3 .<br>Sending build context to Docker daemon 2.048 kB<br>Step 1 : FROM nginx<br> —&gt; e43d811ce2f4<br>Step 2 : RUN echo ‘<h1>Hello, Docker!</h1>‘ &gt; /usr/share/nginx/html/index.html<br> —&gt; Running in 9cdc27646c7b<br> —&gt; 44aa4490ce2c<br>Removing intermediate container 9cdc27646c7b<br>Successfully built 44aa4490ce2c<br>从命令的输出结果中，我们可以清晰的看到镜像的构建过程。在 Step 2 中，如同我们之前所说的那样，RUN 指令启动了一个容器 9cdc27646c7b，执行了所要求的命令，并最后提交了这一层 44aa4490ce2c，随后删除了所用到的这个容器 9cdc27646c7b。这里我们使用了 docker build命令进行镜像构建。其格式为：</p>
<p>$ docker build [选项] &lt;上下文路径/URL/-&gt;<br>在这里我们指定了最终镜像的名称 -t nginx:v3，构建成功后，我们可以像之前运行 nginx:v2 那样来运行这个镜像，其结果会和 nginx:v2 一样。</p>
<h2 id="镜像构建上下文（Context）"><a href="#镜像构建上下文（Context）" class="headerlink" title="镜像构建上下文（Context）"></a>镜像构建上下文（Context）</h2><p>如果注意，会看到 docker build 命令最后有一个.。.表示当前目录，而 Dockerfile 就在当前目录，因此不少初学者以为这个路径是在指定 Dockerfile 所在路径，这么理解其实是不准确的。如果对应上面的命令格式，你可能会发现，这是在指定上下文路径。那么什么是上下文呢？</p>
<p>首先我们要理解 docker build 的工作原理。Docker 在运行时分为 Docker 引擎（也就是服务端守护进程）和客户端工具。Docker 的引擎提供了一组 REST API，被称为 Docker Remote API，而如 docker 命令这样的客户端工具，则是通过这组 API 与 Docker 引擎交互，从而完成各种功能。因此，虽然表面上我们好像是在本机执行各种 docker 功能，但实际上，一切都是使用的远程调用形式在服务端（Docker 引擎）完成。也因为这种 C/S 设计，让我们操作远程服务器的 Docker 引擎变得轻而易举。</p>
<p>当我们进行镜像构建的时候，并非所有定制都会通过 RUN 指令完成，经常会需要将一些本地文件复制进镜像，比如通过 COPY 指令、ADD 指令等。而 docker build 命令构建镜像，其实并非在本地构建，而是在服务端，也就是 Docker 引擎中构建的。那么在这种客户端/服务端的架构中，如何才能让服务端获得本地文件呢？</p>
<p>这就引入了上下文的概念。当构建的时候，用户会指定构建镜像上下文的路径，docker build 命令得知这个路径后，会将路径下的所有内容打包，然后上传给 Docker 引擎。这样 Docker 引擎收到这个上下文包后，展开就会获得构建镜像所需的一切文件。如果在 Dockerfile 中这么写：</p>
<p>COPY ./package.json /app/<br>这并不是要复制执行 docker build 命令所在的目录下的 package.json，也不是复制 Dockerfile 所在目录下的 package.json，而是复制 上下文（context） 目录下的 package.json。</p>
<p>因此，COPY这类指令中的源文件的路径都是相对路径。这也是初学者经常会问的为什么 COPY ../package.json /app 或者 COPY /opt/xxxx /app 无法工作的原因，因为这些路径已经超出了上下文的范围，Docker 引擎无法获得这些位置的文件。如果真的需要那些文件，应该将它们复制到上下文目录中去。</p>
<p>现在就可以理解刚才的命令docker build -t nginx:v3 .中的这个.，实际上是在指定上下文的目录，docker build 命令会将该目录下的内容打包交给 Docker 引擎以帮助构建镜像。</p>
<p>如果观察 docker build 输出，我们其实已经看到了这个发送上下文的过程：</p>
<p>$ docker build -t nginx:v3 .<br>Sending build context to Docker daemon 2.048 kB<br>…<br>理解构建上下文对于镜像构建是很重要的，可以避免犯一些不应该的错误。比如有些初学者在发现 COPY /opt/xxxx /app 不工作后，于是干脆将 Dockerfile 放到了硬盘根目录去构建，结果发现 docker build 执行后，在发送一个几十 GB 的东西，极为缓慢而且很容易构建失败。那是因为这种做法是在让 docker build 打包整个硬盘，这显然是使用错误。</p>
<p>一般来说，应该会将 Dockerfile 置于一个空目录下，或者项目根目录下。如果该目录下没有所需文件，那么应该把所需文件复制一份过来。如果目录下有些东西确实不希望构建时传给 Docker 引擎，那么可以用 .gitignore 一样的语法写一个.dockerignore，该文件是用于剔除不需要作为上下文传递给 Docker 引擎的。</p>
<p>那么为什么会有人误以为 . 是指定 Dockerfile 所在目录呢？这是因为在默认情况下，如果不额外指定 Dockerfile 的话，会将上下文目录下的名为 Dockerfile 的文件作为 Dockerfile。</p>
<p>这只是默认行为，实际上 Dockerfile 的文件名并不要求必须为 Dockerfile，而且并不要求必须位于上下文目录中，比如可以用-f ../Dockerfile.php参数指定某个文件作为 Dockerfile。</p>
<p>当然，一般大家习惯性的会使用默认的文件名 Dockerfile，以及会将其置于镜像构建上下文目录中。</p>
<h2 id="迁移镜像"><a href="#迁移镜像" class="headerlink" title="迁移镜像"></a>迁移镜像</h2><p>Docker 还提供了docker load和docker save命令，用以将镜像保存为一个 tar 文件，然后传输到另一个位置上，再加载进来。这是在没有 Docker Registry 时的做法，现在已经不推荐，镜像迁移应该直接使用 Docker Registry，无论是直接使用 Docker Hub 还是使用内网私有 Registry 都可以。</p>
<p>使用docker save命令可以将镜像保存为归档文件。比如我们希望保存这个 alpine 镜像。</p>
<p>$ docker image ls alpine<br>REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE<br>alpine              latest              baa5d63471ea        5 weeks ago         4.803 MB<br>保存镜像的命令为：</p>
<p>$ docker save alpine | gzip &gt; alpine-latest.tar.gz<br>然后我们将 alpine-latest.tar.gz 文件复制到了到了另一个机器上，可以用下面这个命令加载镜像：</p>
<p>$ docker load -i alpine-latest.tar.gz<br>Loaded image: alpine:latest<br>如果我们结合这两个命令以及 ssh 甚至 pv 的话，利用 Linux 强大的管道，我们可以写一个命令完成从一个机器将镜像迁移到另一个机器，并且带进度条的功能：</p>
<p>docker save &lt;镜像名&gt; | bzip2 | pv | ssh &lt;用户名&gt;@&lt;主机名&gt; ‘cat | docker load’</p>
]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>Dockerfile</tag>
      </tags>
  </entry>
  <entry>
    <title>从嫦娥5号看第二宇宙速度</title>
    <url>/2020/11/26/chang6/</url>
    <content><![CDATA[<h2 id="1、第一宇宙速度"><a href="#1、第一宇宙速度" class="headerlink" title="1、第一宇宙速度"></a>1、第一宇宙速度</h2><pre><code>摆脱地球引力 就必须大于第一宇宙速度     按照力学理论可以计算出 v1=7.9 km/s
小于第二宇宙速度，否则会超出太阳的引力，冲出太阳系。 当航天器超过第一宇宙速度V1达到一定值时，它就会脱离地球的引力场而成为围绕太阳运行的人造行星，这个速度就叫做第二宇宙速度，亦称脱离速度。</code></pre>
<h2 id="2、-第二宇宙速度"><a href="#2、-第二宇宙速度" class="headerlink" title="2、 第二宇宙速度"></a>2、 第二宇宙速度</h2><p>按照力学理论可以计算出第二宇宙速度V2=11．2公里/秒</p>
<h2 id="3、-从月球采样返回"><a href="#3、-从月球采样返回" class="headerlink" title="3、 从月球采样返回"></a>3、 从月球采样返回</h2><p>返回器以接近第二宇宙速度(第二宇宙速度为11.2公里/秒)再入返回相关技术<br>第二宇宙速度也叫脱离速度,是脱离地球飞行所需的速度,嫦娥以脱离速度再入地球大气层,再弹跳出大气层进入太空、再入大气层、再弹出大气层.一跳就是上千公里,最后能以设计所需的速度精确降落地面.</p>
<h2 id="4、天问号-到达火星"><a href="#4、天问号-到达火星" class="headerlink" title="4、天问号 到达火星"></a>4、天问号 到达火星</h2><p> 到达火星 必须要 摆脱地球引力，达到甚至高于第二宇宙速度</p>
]]></content>
      <categories>
        <category>从嫦娥5号看第二宇宙速度</category>
      </categories>
      <tags>
        <tag>从嫦娥5号看第二宇宙速度</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello world</title>
    <url>/2010/04/12/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
      <tags>
        <tag>Hello world</tag>
      </tags>
  </entry>
  <entry>
    <title>java探针</title>
    <url>/2020/08/22/java%E6%8E%A2%E9%92%88/</url>
    <content><![CDATA[<h2 id="一、需求"><a href="#一、需求" class="headerlink" title="一、需求"></a>一、需求</h2><p>Tomcat：<br>（1）模块启动时间<br>（2）模块交互耗时</p>
<h2 id="二、现状"><a href="#二、现状" class="headerlink" title="二、现状"></a>二、现状</h2><p>现代APM体系，基本都是参考Google的Dapper（大规模分布式系统的跟踪系统）的体系来做的。通过跟踪请求的处理过程，来对应用系统在前后端处理、服务端调用的性能消耗进行跟踪，关于Dapper的介绍可以看这个链接：<a href="http://bigbully.github.io/Dapper-translation/">http://bigbully.github.io/Dapper-translation/</a><br>下面重点选5个比较有名的server端探针进行简单介绍：</p>
<h3 id="2-1-Pinpoint（开源）"><a href="#2-1-Pinpoint（开源）" class="headerlink" title="2.1 Pinpoint（开源）"></a>2.1 Pinpoint（开源）</h3><p>github地址：<a href="https://github.com/naver/pinpoint">https://github.com/naver/pinpoint</a><br>java领域的性能分析的开源项目，这个是一个韩国团队开源出来的，通过JavaAgent的机制来做字节码代码植入，实现加入traceid和抓取性能数据的目的。<br>NewRelic、Oneapm之类的工具在java平台上的性能分析也是类似的机制。</p>
<h3 id="2-2-Zipkin（开源）"><a href="#2-2-Zipkin（开源）" class="headerlink" title="2.2 Zipkin（开源）"></a>2.2 Zipkin（开源）</h3><p>官网：OpenZipkin · <a href="http://zipkin.io/">http://zipkin.io/</a><br>github地址：<a href="https://github.com/openzipkin/zipkin">https://github.com/openzipkin/zipkin</a><br>这个是twitter开源出来的，也是参考Dapper的体系来做的。<br>Zipkin的java应用端是通过一个叫Brave的组件来实现对应用内部的性能分析数据采集。<br>Brave的github地址：<a href="https://github.com/openzipkin/brave">https://github.com/openzipkin/brave</a><br>这个组件通过实现一系列的java拦截器，来做到对http/servlet请求、数据库访问的调用过程跟踪。<br>然后通过在spring之类的配置文件里加入这些拦截器，完成对java应用的性能数据采集。</p>
<h3 id="2-3-CAT（开源）"><a href="#2-3-CAT（开源）" class="headerlink" title="2.3 CAT（开源）"></a>2.3 CAT（开源）</h3><p>github地址：<a href="https://github.com/dianping/cat">https://github.com/dianping/cat</a><br>这个是大众点评开源出来的，实现的功能也还是蛮丰富的，国内也有一些公司在用了。<br>不过他实现跟踪的手段，是要在代码里硬编码写一些“埋点”，也就是侵入式的。<br>这样做有利有弊，好处是可以在自己需要的地方加埋点，比较有针对性；坏处是必须改动现有系统，很多开发团队不愿意。</p>
<h3 id="2-4-NewRelic（闭源，代码不混淆）"><a href="#2-4-NewRelic（闭源，代码不混淆）" class="headerlink" title="2.4 NewRelic（闭源，代码不混淆）"></a>2.4 NewRelic（闭源，代码不混淆）</h3><p><a href="https://newrelic.com/java">https://newrelic.com/java</a></p>
<h3 id="2-5-听云（闭源，代码混淆）"><a href="#2-5-听云（闭源，代码混淆）" class="headerlink" title="2.5 听云（闭源，代码混淆）"></a>2.5 听云（闭源，代码混淆）</h3><p><a href="http://www.tingyun.com/tingyun_server.html">http://www.tingyun.com/tingyun_server.html</a><br>探针能力介绍：<a href="http://doc.tingyun.com/server/html/phpzhichiliebiao.html">http://doc.tingyun.com/server/html/phpzhichiliebiao.html</a></p>
<h2 id="三、探针能力汇总"><a href="#三、探针能力汇总" class="headerlink" title="三、探针能力汇总"></a>三、探针能力汇总</h2><h3 id="3-1-支持"><a href="#3-1-支持" class="headerlink" title="3.1 支持"></a>3.1 支持</h3><p>（1）应用运行环境：PHP, Java, .NET，Node.js, Python，Ruby等<br>（2）云：阿里云、腾讯云、AWS、金山云、青云、华为云等<br>（3）Database：MySQL, Oracle, MS SQL Server, PostgreSQL等<br>（4）Framework：Spring， Yii，Django，Tomcat，JBoss，WebLogic等<br>（5）NoSQL：Memcached，MongoDB，Redis等非关系型数据库服务<br>（6）API：监控HTTP、Dubbo、Thrift协议下当前应用调用的外部服务，如微博、微信第三方API接口等，并支持跨应用分析</p>
<h3 id="3-2-核心功能"><a href="#3-2-核心功能" class="headerlink" title="3.2 核心功能"></a>3.2 核心功能</h3><p>（1）web应用过程：分析url调用过程中性能消耗原因,抓取超过阈值url的详细数据<br>（2）数据库性能：支持多种数据库类型的监测，定位并追踪慢SQL语句问题<br>（3）错误分析：记录错误发生时的详细信息，统计应用错误率，定位问题具体至代码行<br>（4）外部API调用：可以监测所有服务端应用外部调用API的耗时，并进行汇总统计<br>（5）线程剖析：可以实现生产环境下实时在线的线程剖析,可在运行时了解代码性能<br>（6）NoSQL分析：实时监控Memcache, MongoDB，Redis等NoSQL数据库的性能问题<br>（7）JVM性能：实时监控 JVM 运行状态，通过图表展示 JVM 内存分配情况、内存使用情况、垃圾收集信息、类加载数量、JVM 线程信息以及会话信息。<br>（8）HTTP 会话：分析每个应用程序的 HTTP 会话数，包括：活跃、过期、拒绝的会话。</p>
<h3 id="3-3-基于javaAgent和Java字节码注入技术的java探针"><a href="#3-3-基于javaAgent和Java字节码注入技术的java探针" class="headerlink" title="3.3 基于javaAgent和Java字节码注入技术的java探针"></a>3.3 基于javaAgent和Java字节码注入技术的java探针</h3><p>（1）springCloud自带了这些功能<br>（2）asm、javassist之类的<br>（3）springboot的Actuator扩展下也可以</p>
]]></content>
      <categories>
        <category>java探针</category>
      </categories>
      <tags>
        <tag>java探针</tag>
      </tags>
  </entry>
  <entry>
    <title>markdown</title>
    <url>/2020/08/18/markdown/</url>
    <content><![CDATA[<h2 id="pandoc的安装"><a href="#pandoc的安装" class="headerlink" title="pandoc的安装"></a>pandoc的安装</h2><p>pandoc的作用主要是将我们的markdown文件转换成html，<br>这样就可以在浏览器中实时预览我们的文件渲染效果。<br>当然，pandoc还有许多其他的功能，比如它也支持将markdown文件输出成pdf等，给出他的下载链接</p>
<h3 id="网址：http-pandoc-org-installing-html"><a href="#网址：http-pandoc-org-installing-html" class="headerlink" title="网址：http://pandoc.org/installing.html"></a>网址：<a href="http://pandoc.org/installing.html">http://pandoc.org/installing.html</a></h3>]]></content>
      <categories>
        <category>markdown</category>
      </categories>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title>maven打包docker</title>
    <url>/2020/08/27/maven%E6%89%93%E5%8C%85docker/</url>
    <content><![CDATA[<pre><code>     ##    maven打包docker  
 ###   1、使用maven打包。
 mvn package docker:build
 这里你将会生成一个项目名:项目版本号，例如：project:0.0.1;
 ###  使用docker run运行镜像。
 ①首先使用docker image ls，查看xxx.tar包的镜像名字</code></pre>
<p>   ②使用docker run -p 8080:8080 imageName 就运行了。</p>
<pre><code> ### 如何将docker镜像保存至指定地址，使用docker save命令。

     ####保存到用户目录下
docker save -o ~/xxx.tar project:0.0.1
 #### 或者可以使用这条
docker save project:0.0.1&gt;~/xxx.tar
 ####  使用docker load加载tar包：

 docker load -i xxx.tar   或者
 docker load&lt;xxx.tar</code></pre>
]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>mysql5.7安装使用指南</title>
    <url>/2020/08/15/mysql%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97-1/</url>
    <content><![CDATA[<h2 id="1、加压mysql文件包，并在D-mysql5-7-28-目录下创建my-ini"><a href="#1、加压mysql文件包，并在D-mysql5-7-28-目录下创建my-ini" class="headerlink" title="1、加压mysql文件包，并在D:\mysql5.7.28 目录下创建my.ini"></a>1、加压mysql文件包，并在D:\mysql5.7.28 目录下创建my.ini</h2><p>内容：</p>
<p>[client]</p>
<h1 id="设置mysql客户端默认字符集"><a href="#设置mysql客户端默认字符集" class="headerlink" title="设置mysql客户端默认字符集"></a>设置mysql客户端默认字符集</h1><p>default-character-set=utf8</p>
<p>[mysqld]</p>
<h1 id="设置3306端口"><a href="#设置3306端口" class="headerlink" title="设置3306端口"></a>设置3306端口</h1><p>port = 3306<br>character-set-server=utf8</p>
<h1 id="设置mysql的安装目录"><a href="#设置mysql的安装目录" class="headerlink" title="设置mysql的安装目录"></a>设置mysql的安装目录</h1><p>basedir=D:\mysql5.7.28</p>
<h1 id="设置-mysql数据库的数据的存放目录，MySQL-8-不需要以下配置，系统自己生成即可，否则有可能报错"><a href="#设置-mysql数据库的数据的存放目录，MySQL-8-不需要以下配置，系统自己生成即可，否则有可能报错" class="headerlink" title="设置 mysql数据库的数据的存放目录，MySQL 8+ 不需要以下配置，系统自己生成即可，否则有可能报错"></a>设置 mysql数据库的数据的存放目录，MySQL 8+ 不需要以下配置，系统自己生成即可，否则有可能报错</h1><p>#datadir=D:\mysql5.7.28\data</p>
<h1 id="允许最大连接数"><a href="#允许最大连接数" class="headerlink" title="允许最大连接数"></a>允许最大连接数</h1><p>max_connections=200</p>
<h1 id="服务端使用的字符集默认为8比特编码的latin1字符集"><a href="#服务端使用的字符集默认为8比特编码的latin1字符集" class="headerlink" title="服务端使用的字符集默认为8比特编码的latin1字符集"></a>服务端使用的字符集默认为8比特编码的latin1字符集</h1><p>character-set-server=utf8</p>
<h1 id="创建新表时将使用的默认存储引擎"><a href="#创建新表时将使用的默认存储引擎" class="headerlink" title="创建新表时将使用的默认存储引擎"></a>创建新表时将使用的默认存储引擎</h1><p>default-storage-engine=INNODB<br>sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES</p>
<h2 id="2、以管理员身份安装并且启动-cmd"><a href="#2、以管理员身份安装并且启动-cmd" class="headerlink" title="2、以管理员身份安装并且启动 cmd"></a>2、以管理员身份安装并且启动 cmd</h2><p>mysqld  –initialize    – 此步骤会自动生成data文件包</p>
<p>初始化成功后会在my.ini配置文件的datadir的目录下生成一些文件，其中xxx.err(xxx是你电脑用户的名称)文件里说明了root账户的临时密码。例子：&lt;r8j<em>Qrh)jdp就是root账户的临时密码<br> A temporary password is generated for root@localhost: &lt;r8j</em>Qrh)jdp  eqncDQIUl8/P</p>
<h2 id="3、注册mysql服务"><a href="#3、注册mysql服务" class="headerlink" title="3、注册mysql服务"></a>3、注册mysql服务</h2><p>mysqld -install MySQL </p>
<h2 id="4、启动mysql服务"><a href="#4、启动mysql服务" class="headerlink" title="4、启动mysql服务"></a>4、启动mysql服务</h2><p>net start MySQL  </p>
<p>使用root账号登录</p>
<p>mysql -u root -p eqncDQIUl8/P</p>
<p>修改root密码</p>
<p>ALTER USER ‘root’@’localhost’ IDENTIFIED BY ‘root’;  </p>
<p>完整操作步骤<br>以非管理员身份安装数据库提示拒绝安装<br>以管理员身份安装并且启动<br>配置环境变量，便于以后不需进入安装路径才能调用sql.exe</p>
<p>· 添加一个名叫 MYSQL_HOME 的变量</p>
<p>· 修改Path变量，在末尾添加 %MYSQL_HOME%\bin</p>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>我的技术博客</tag>
      </tags>
  </entry>
  <entry>
    <title>我的第一篇博客</title>
    <url>/2012/03/15/mysql%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/</url>
    <content><![CDATA[<p>   第一章</p>
<p>内容</p>
<hr>
<p> 第二章</p>
<p>内容</p>
<hr>
<p>   参考文献</p>
<p><a href="http://www.baidu.com/">www.baidu.com</a></p>
]]></content>
  </entry>
  <entry>
    <title>npm</title>
    <url>/2020/08/29/npm/</url>
    <content><![CDATA[<h1 id="install-dependencies"><a href="#install-dependencies" class="headerlink" title="install dependencies"></a>install dependencies</h1><p>npm install</p>
<h1 id="serve-with-hot-reload-at-localhost-8080"><a href="#serve-with-hot-reload-at-localhost-8080" class="headerlink" title="serve with hot reload at localhost:8080"></a>serve with hot reload at localhost:8080</h1><p>npm run dev</p>
<h1 id="build-for-production-with-minification"><a href="#build-for-production-with-minification" class="headerlink" title="build for production with minification"></a>build for production with minification</h1><p>npm run build</p>
<h1 id="build-for-production-and-view-the-bundle-analyzer-report"><a href="#build-for-production-and-view-the-bundle-analyzer-report" class="headerlink" title="build for production and view the bundle analyzer report"></a>build for production and view the bundle analyzer report</h1><p>npm run build –report</p>
]]></content>
      <categories>
        <category>npm</category>
      </categories>
      <tags>
        <tag>npm</tag>
      </tags>
  </entry>
  <entry>
    <title>oracle迁移到mysql</title>
    <url>/2019/06/18/oracle%E8%BF%81%E7%A7%BB%E5%88%B0mysql/</url>
    <content><![CDATA[<h2 id="oracle迁移到mysql"><a href="#oracle迁移到mysql" class="headerlink" title="oracle迁移到mysql"></a>oracle迁移到mysql</h2><p>  相比较 navicat更为精确<br>  备注：免费版只能导出25条数据转换、建议转换表结构后数据，通过同步抽取处理。<br>  官网地址：<a href="https://intelligent-converters.com/oracle-to-mysql.htm">https://intelligent-converters.com/oracle-to-mysql.htm</a></p>
]]></content>
      <categories>
        <category>数据迁移</category>
      </categories>
      <tags>
        <tag>数据迁移</tag>
      </tags>
  </entry>
  <entry>
    <title>pandas 函数</title>
    <url>/2020/09/09/python1/</url>
    <content><![CDATA[<p>df2= pd.DataFrame([[1,2,3],[4,5,6]],index=[‘r1’,’r2’],columns=[‘c1’,’c2’,’c3’])<br>dates=pd.date_range(‘2020-12-12’,periods=7)<br>df3 =pd.DataFrame(np.random.randn(7,4),index=dates,columns=list(‘abcd’))</p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>pandas 函数</tag>
      </tags>
  </entry>
  <entry>
    <title>python绘制科赫雪花</title>
    <url>/2020/09/26/python%E7%BB%98%E5%9B%BE/</url>
    <content><![CDATA[<pre><code>##      python绘制科赫雪花</code></pre>
<h3 id="脚本如下："><a href="#脚本如下：" class="headerlink" title="脚本如下："></a>脚本如下：</h3><p>import turtle<br>def koch(size,n):<br>  if n==1:<br>    turtle.fd(size)<br>  else:<br>    for i in [0,60,-120,60]:<br>      turtle.left(i)<br>      koch(size/3,n-1)<br>def main():<br>  turtle.setup(600,600)<br>  turtle.penup()<br>  turtle.speed(10)<br>  turtle.hideturtle()<br>  turtle.pensize(2)<br>  turtle.goto(-200,100)<br>  turtle.pendown()<br>  level=4<br>  koch(400,level)<br>  turtle.right(120)<br>  koch(400, level)<br>  turtle.right(120)<br>  koch(400, level)<br>  turtle.penup()<br>  turtle.done()<br>main()</p>
<h3 id="演示结果如图："><a href="#演示结果如图：" class="headerlink" title="演示结果如图："></a>演示结果如图：</h3><p>  <img src="https://lixinx11.github.io/medias/bigdata/23.png" alt="科赫雪花"></p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python绘制科赫雪花</tag>
      </tags>
  </entry>
  <entry>
    <title>redis使用指南</title>
    <url>/2018/06/13/redis%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/</url>
    <content><![CDATA[<p>redis与redis部署服务的安装<br>下载文件redis-3.0.0.tar.gz</p>
<h2 id="一，redis服务的安装"><a href="#一，redis服务的安装" class="headerlink" title="一，redis服务的安装"></a>一，redis服务的安装</h2><h3 id="1-环境配置"><a href="#1-环境配置" class="headerlink" title="1.环境配置"></a>1.环境配置</h3><p>Redis是c开发的，因此安装redis需要c语言的编译环境，即需要安装gcc</p>
<p>查看是否安装gcc</p>
<p>gcc -v<br>如果没有gcc，则需要在线安装。命令如下</p>
<p>yum install gcc-c++</p>
<h3 id="2-redis安装"><a href="#2-redis安装" class="headerlink" title="2.redis安装"></a>2.redis安装</h3><p>1）上传redis压缩包到服务器</p>
<p>本文是通过MobaXterm进行操作的，如图</p>
<p>1.png 2）解压redis压缩包</p>
<p>tar zxf redis-3.0.0.tar.gz<br>3）进入redis-3.0.0目录并查看该目录下文件</p>
<p>2.png</p>
<p>4）制作编译redis源码</p>
<p>3.png</p>
<p>如下则编译成功</p>
<p>4.png</p>
<p>5）安装编译后的redis代码到指定目录，一般存放于/ usr / local下的redis目录，指令如下</p>
<p>make install PREFIX=/usr/local/redis<br>如下图则说明安装成功，此时查看/ user / local目录，可以发现多了一个redis文件夹</p>
<p>5.png</p>
<p>6）此时可以启动redis了，交替启动模式为前端启动，指令如下</p>
<p>./redis-server<br>6.png</p>
<p>7）前端启动的话，如果客户端关闭，redis服务也会停掉，所以需要改成后台启动redis</p>
<p>a）将redis解压文件里面的redis.conf文件复制到当前目录</p>
<p>cp ~/redis-3.0.0/redis.conf .<br>b）修改redis.conf文件，将守护进程否-&gt;将守护进程守护进程，这样便将启动方式修改为后台启动了</p>
<p>vim redis.conf<br>7.png</p>
<p>然后保存修改并退出，指令如下（四步操作）</p>
<p>Esc -&gt; : -&gt; wq -&gt; Enter(回车)</p>
<h3 id="3-启动redis（后台启动）"><a href="#3-启动redis（后台启动）" class="headerlink" title="3.启动redis（后台启动）"></a>3.启动redis（后台启动）</h3><p>./redis-server redis.conf<br>8.png</p>
<p>4.测试<br>1）查看redis是否在运行</p>
<p>ps aux|grep redis<br>2）打开redis连接</p>
<p>./redis-cli   或redis-cli -c -p 6379<br>连接成功，如图所示</p>
<p>9.png</p>
<h2 id="二，redis实施服务安装"><a href="#二，redis实施服务安装" class="headerlink" title="二，redis实施服务安装"></a>二，redis实施服务安装</h2><h3 id="1-创建重新分配目录"><a href="#1-创建重新分配目录" class="headerlink" title="1.创建重新分配目录"></a>1.创建重新分配目录</h3><p>1）在usr / local目录下新建的redis-cluster目录，用于存放重新分配</p>
<p>10.png</p>
<p>2）复制/ usr / local / redis / bin目录下所有文件</p>
<p>把redis目录下的bin目录下的所有文件复制到/ usr / local / redis-cluster / redis01目录下，不用担心这里没有redis01目录，会自动创建的。</p>
<p>cp -r redis/bin/ redis-cluster/redis01<br>11.png</p>
<p>3）删除redis01目录下快照文件dump.rdb。</p>
<p>rm -rf dump.rdb<br>12.png</p>
<p>4）修改redis01目录下redis.conf配置文件</p>
<p>a）修改端口号为6380</p>
<p>13.png</p>
<p>b）将启用群集功能是的注释打开（大概632行）</p>
<p>c）将群集配置文件节点6379.conf的注释打开，并同时将群集配置文件节点6380.conf（大概640行）</p>
<p>14.png</p>
<p>d）打开bind注释，并修改为bind 192.168.0.40（这一步很重要，每个例程都要修改为对应的服务器的ip，下面127.0.0.1的地方都要替换192.168.0.40）</p>
<p>5）创建6个redis实例</p>
<p>a）将redis-cluster / redis01文件复制5份到redis-cluster目录下（redis02-redis06），创建6个redis实例，模拟Redis替换的6个实例。如下所示：</p>
<p>15.png</p>
<p>b）分别修改redis.conf文件端口号为6381-6385</p>
<h3 id="2-启动所有redis例程"><a href="#2-启动所有redis例程" class="headerlink" title="2.启动所有redis例程"></a>2.启动所有redis例程</h3><p>1）由于一个启动太麻烦，所以在这里创建一个批量启动redis中断的脚本文件startall.sh，文件内容如下：</p>
<p>cd redis01<br>./redis-server redis.conf<br>cd ..<br>cd redis02<br>./redis-server redis.conf<br>cd ..<br>cd redis03<br>./redis-server redis.conf<br>cd ..<br>cd redis04<br>./redis-server redis.conf<br>cd ..<br>cd redis05<br>./redis-server redis.conf<br>cd ..<br>cd redis06<br>./redis-server redis.conf<br>cd ..<br>16.png</p>
<p>2）创建好启动脚本文件之后，需要修改该脚本的权限，使之能够执行，指令如下：</p>
<p>chmod +x startall.sh<br>3）执行startall.sh脚本，启动6个redis例程</p>
<p>注意：如果出现报“没有那个文件或目录行”的错误，有可能是因为文件格式错误。输入如下命令将文件dos格式转换成unix再启动</p>
<p>dos2unix startall.sh<br>17.png</p>
<p>4）查看redis是否启动</p>
<p>ps -ef|grep redis<br>18.png</p>
<h3 id="3-安装Ruby环境"><a href="#3-安装Ruby环境" class="headerlink" title="3.安装Ruby环境"></a>3.安装Ruby环境</h3><p>注意：redis需要Ruby版本大于2.2.2</p>
<p>下载文件ruby-2.3.0.tar.gz</p>
<p>1）若存在Ruby，则清除旧版Ruby</p>
<p>yum remove ruby<br>2）安装依赖</p>
<p>yum -y install zlib-devel curl-devel openssl-devel httpd-devel apr-devel apr-util-devel mysql-devel<br>3）上传ruby-2.3.0到服务器，并解压</p>
<p>tar zxvf ruby-2.3.0.tar.gz<br>19.png</p>
<p>4）进入ruby-2.3.0目录下，执行以下命令</p>
<p>./configure –disable-install-rdoc<br>20.png</p>
<p>5）在ruby-2.3.0目录下，执行以下命令</p>
<p> make<br> make install<br>6）查看Ruby信息</p>
<p>ruby -v<br>21.png</p>
<p>7）要支持redis通信，需要下载redis相关包</p>
<p>gem install redis<br>22.png</p>
<h3 id="4-完善实力"><a href="#4-完善实力" class="headerlink" title="4.完善实力"></a>4.完善实力</h3><p>1）切换到redis解压的原始包src目录下</p>
<p>cd /root/redis-3.0.0/src/<br>2）执行以下命令</p>
<p>./redis-trib.rb create –replicas 1 192.168.0.40:6380 192.168.0.40:6381 192.168.0.40:6382 192.168.0.40:6383 192.168.0.40:6384 192.168.0.40:6385<br>–replicas 1 表示每个主数据库拥有从数据库个数为1。master节点不能少于3个，所以我们用了6个redis<br>23.png</p>
<p>3）遇到以下提示信息，手动输入是</p>
<p>24.png</p>
<h3 id="5-测试"><a href="#5-测试" class="headerlink" title="5.测试"></a>5.测试</h3><p>1）测试连接</p>
<p>./redis-cli -c -p 6380<br>25.png</p>
<p>2）查看所需信息</p>
<p>a.查看当前集群信息<br>cluster info<br>b.查看集群里有多少个节点<br>cluster nodes<br>26.png</p>
<h3 id="6-至此linux下redis部署安装完毕"><a href="#6-至此linux下redis部署安装完毕" class="headerlink" title="6.至此linux下redis部署安装完毕"></a>6.至此linux下redis部署安装完毕</h3><h3 id="7-建造多台遇到的问题"><a href="#7-建造多台遇到的问题" class="headerlink" title="7.建造多台遇到的问题"></a>7.建造多台遇到的问题</h3><p>配置文件<br>redis.conf<br>bind 127.0.0.1 机器ip<br>将绑定方式修改为:<br>bind 机器ip<br>开启集群的配置<br>#cluster-config-file nodes-6496.conf 将注释打开并将端口号修改，区别自动生成的文件<br>b问题<br>Redis集群端口为6491-6496 就需要打开6491-6496的端口号以及16491-16496的端口<br>c重启服务<br>重启服务需要将各个端口生成的rdb、nodes.conf 、aof文件删除<br>d验证<br>#./redis-cli -c -h 10.10.200.199 -p 6491<br>10.10.200.199:6491&gt;cluster nodes<br>10.10.200.199:6491&gt;cluster info<br>e查询键<br>查看key对应的slot<br>cluster keyslot key<br>查看slot和节点的对应关系<br>cluster slots<br>f关闭redis端口<br>./redis-cli -p 6379 shutdown<br>用kill -9 进程号，直接杀进程的方法会造成数据丢失<br>##后续### 1.redis-4.0.11默认会开启绑定127.0.0.1和写保护protected-mode是，配置的时候需要将bind 127.0.0.1注掉，改成protected-mode否</p>
]]></content>
      <categories>
        <category>NOSQL数据库</category>
      </categories>
      <tags>
        <tag>我的技术博客</tag>
      </tags>
  </entry>
  <entry>
    <title>redis</title>
    <url>/2020/09/05/redis/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>sklearn函数汇总</title>
    <url>/2020/09/06/sklearn%E5%87%BD%E6%95%B0%E6%B1%87%E6%80%BB/</url>
    <content><![CDATA[<p><strong>sklearn函数汇总</strong><br>9/6/2020 11:45:01 AM </p>
<ol>
<li>拆分数据集为训练集和测试集：</li>
</ol>
<p>from sklearn.model_selection import train_test_split<br>x_train, x_test, y_train, y_test =<br>train_test_split(x, y, test_size = 0.2,random_state=3,shuffle=False)</p>
<h1 id="test-size代表测试集的大小，train-size代表训练集的大小，两者只能存在一个"><a href="#test-size代表测试集的大小，train-size代表训练集的大小，两者只能存在一个" class="headerlink" title="test_size代表测试集的大小，train_size代表训练集的大小，两者只能存在一个"></a>test_size代表测试集的大小，train_size代表训练集的大小，两者只能存在一个</h1><p>  random_state代表随即种子编号，默认为None<br>  shuffle代表是否进行有放回抽样</p>
<h2 id="2-数据预处理"><a href="#2-数据预处理" class="headerlink" title="2. 数据预处理"></a>2. 数据预处理</h2><h3 id="2-1-标准化："><a href="#2-1-标准化：" class="headerlink" title="2.1 标准化："></a>2.1 标准化：</h3><p>from sklearn.preprocessing import StandardScaler<br>scaler = StandardScaler().fit(x_train) # fit生成规则<br>x_trainScaler = scaler.transform(x_train) # 将规则应用于训练集<br>x_testScaler = scaler.transform(x_test)  # 将规则应用于测试集</p>
<h3 id="2-2-区间缩放："><a href="#2-2-区间缩放：" class="headerlink" title="2.2 区间缩放："></a>2.2 区间缩放：</h3><p>from sklearn.preprocessing import MinMaxScaler<br>scaler = MinMaxScaler().fit(x_train) # fit生成规则<br>x_trainScaler = scaler.transform(x_train) # 将规则应用于训练集<br>x_testScaler = scaler.transform(x_test)  # 将规则应用于测试集</p>
<h3 id="2-3-归一化："><a href="#2-3-归一化：" class="headerlink" title="2.3 归一化："></a>2.3 归一化：</h3><p>from sklearn.preprocessing import Normalizer<br>scaler = Normalizer().fit(x_train) # fit生成规则<br>x_trainScaler = scaler.transform(x_train) # 将规则应用于训练集<br>x_testScaler = scaler.transform(x_test)  # 将规则应用于测试集</p>
<h3 id="2-4-二值化：设定一个阈值，大于阈值的赋值为1，小于等于阈值的赋值为0"><a href="#2-4-二值化：设定一个阈值，大于阈值的赋值为1，小于等于阈值的赋值为0" class="headerlink" title="2.4 二值化：设定一个阈值，大于阈值的赋值为1，小于等于阈值的赋值为0"></a>2.4 二值化：设定一个阈值，大于阈值的赋值为1，小于等于阈值的赋值为0</h3><p>from sklearn.preprocessing import Binarizer<br>scaler = Binarizer(threshold=3).fit(x_train) # threshold为设定的阀值<br>x_trainScaler = scaler.transform(x_train) # 将规则应用于训练集<br>x_testScaler = scaler.transform(x_test)  # 将规则应用于测试集</p>
<h3 id="2-5-哑编码处理："><a href="#2-5-哑编码处理：" class="headerlink" title="2.5 哑编码处理："></a>2.5 哑编码处理：</h3><p>from sklearn.preprocessing import OneHotEncoder<br>scaler = OneHotEncoder().fit(x_train.reshape((-1,1)))<br>x_trainScaler = scaler.transform(x_train) # 将规则应用于训练集<br>x_testScaler = scaler.transform(x_test)  # 将规则应用于测试集</p>
<h3 id="2-6-自定义函数变换"><a href="#2-6-自定义函数变换" class="headerlink" title="2.6 自定义函数变换"></a>2.6 自定义函数变换</h3><p>from numpy import log1p  # 使用对数函数转换<br>from sklearn.preprocessing import FunctionTransformer<br>scaler = FunctionTransformer(log1p).fit(x_train)<br>x_trainScaler = scaler.transform(x_train) # 将规则应用于训练集<br>x_testScaler = scaler.transform(x_test)  # 将规则应用于测试集</p>
<h3 id="2-7-PCA降维："><a href="#2-7-PCA降维：" class="headerlink" title="2.7 PCA降维："></a>2.7 PCA降维：</h3><p>from sklearn.decomposition import PCA<br>pca = PCA(n_components=3).fit(x_train)  # n_components设置降维到n维度<br>x_trainPca = pca.transform(x_train) # 将规则应用于训练集<br>x_testPca = pca.transform(x_test)  # 将规则应用于测试集</p>
<h3 id="2-8-LDA降维："><a href="#2-8-LDA降维：" class="headerlink" title="2.8 LDA降维："></a>2.8 LDA降维：</h3><p>from sklearn.lda import LDA<br>lda = LDA(n_components=3).fit(x_train)  # n_components设置降维到n维度<br>x_trainLda = lda.transform(x_train) # 将规则应用于训练集<br>x_testLda = lda.transform(x_test)  # 将规则应用于测试集</p>
<h2 id="3-特征筛选"><a href="#3-特征筛选" class="headerlink" title="3. 特征筛选"></a>3. 特征筛选</h2><h3 id="3-1-Filter法："><a href="#3-1-Filter法：" class="headerlink" title="3.1 Filter法："></a>3.1 Filter法：</h3><p>from sklearn.feature_selection import SelectKBest, f_classif<br>selector = SelectKBest(f_classif, k=4) – 用f_classif方法，设定数目为4<br>a=selector.fit(x,y)<br>print(np.array(a.scores_),’\n’,a.get_support())  –  输出得分及选择的结果</p>
<h3 id="3-2-Wrapper法（递归法）："><a href="#3-2-Wrapper法（递归法）：" class="headerlink" title="3.2 Wrapper法（递归法）："></a>3.2 Wrapper法（递归法）：</h3><p>from sklearn.linear_model import LinearRegression –导入基模型<br>from sklearn.feature_selection import RFE  – 导入RFE模块<br>model1 = LinearRegression()   – 建立一个线性模型<br>rfe = RFE(model1,4)           – 进行多轮训练，设置筛选特征数目为4个<br>rfe = rfe.fit(x,y)            – 模型的拟合训练<br>print(rfe.support_)           – 输出特征的选择结果<br>print(rfe.ranking_)           – 特征的选择排名</p>
<h2 id="4-构建模型"><a href="#4-构建模型" class="headerlink" title="4.构建模型"></a>4.构建模型</h2><h3 id="4-1决策树模型"><a href="#4-1决策树模型" class="headerlink" title="4.1决策树模型"></a>4.1决策树模型</h3><p>决策树优点：</p>
<p>便于理解和解释。树的结构可以可视化出来。<br>训练需要的数据少，对异常值和缺失值不敏感。<br>能够处理数值型数据和分类数据。<br>决策树缺点：</p>
<p>容易产生一个过于复杂的模型，使模型产生过拟合的问题。<br>决策树可能是不稳定的，因为数据中的微小变化可能会导致完全不同的树生成。<br>from sklearn.tree import DecisionTreeClassifier<br>clf = DecisionTreeClassifier(criterion=’gini’, –设置衡量的系数,有entropy和gini，默认gini<br>                               splitter=’best’, –选择分类的策略，best和random，默认best<br>                               max_depth=5, –设置树的最大深度<br>                               min_samples_split=10,– 区分一个内部节点需要的最少的样本数<br>                               min_samples_leaf=5 – 一个叶节点所需要的最小样本数<br>                               max_features=5 –最大特征数<br>                               max_leaf_nodes=3–最大样本节点个数<br>                               min_impurity_split –指定信息增益的阀值<br>                               )<br>clf= clf.fit(x_train,y_train)  – 拟合训练</p>
<h3 id="4-2-逻辑回归模型"><a href="#4-2-逻辑回归模型" class="headerlink" title="4.2 逻辑回归模型"></a>4.2 逻辑回归模型</h3><p>优点：实现简单，易于理解和实现；计算代价不高，速度很快，存储资源低。</p>
<p>缺点：容易欠拟合，分类精度可能不高。对异常值和缺失值敏感</p>
<p>from sklearn.linear_model import LogisticRegression<br>clf = LogisticRegression(penalty=’l2’, –惩罚项（l1与l2），默认l2<br>                         dual=False, –对偶或原始方法，默认False，样本数量&gt;样本特征的时候，dual通常设置为False<br>                         tol=0.0001, –停止求解的标准，float类型，默认为1e-4。就是求解到多少的时候，停止，认为已经求出最优解<br>                         C=1.0, –正则化系数λ的倒数，float类型，默认为1.0，越小的数值表示越强的正则化。<br>                         fit_intercept=True, –是否存在截距或偏差，bool类型，默认为True。<br>                         intercept_scaling=1, –仅在正则化项为”liblinear”，且fit_intercept设置为True时有用。float类型，默认为1<br>                         class_weight=None, –用于标示分类模型中各种类型的权重，默认为不输入，也就是不考虑权重，即为None<br>                         random_state=None, –随机数种子，int类型，可选参数，默认为无<br>                         solver=’liblinear’, –优化算法选择参数，只有五个可选参数，即newton-cg,lbfgs,liblinear,sag,saga。默认为liblinear<br>                         max_iter=10, –算法收敛最大迭代次数，int类型，默认为10。<br>                         multi_class=’ovr’–分类方式选择参数，str类型，可选参数为ovr和multinomial，默认为ovr。<br>                                          如果是二元逻辑回归，ovr和multinomial并没有任何区别，区别主要在多元逻辑回归上。<br>                         verbose=0, –日志冗长度，int类型。默认为0。就是不输出训练过程<br>                         warm_start=False, –热启动参数，bool类型。默认为False。<br>                         n_jobs=1–并行数。int类型，默认为1。1的时候，用CPU的一个内核运行程序，2的时候，用CPU的2个内核运行程序。<br>                        )<br>clf= clf.fit(x_train,y_train)  – 拟合训练</p>
<h3 id="4-3-线性回归模型"><a href="#4-3-线性回归模型" class="headerlink" title="4.3 线性回归模型"></a>4.3 线性回归模型</h3><p>优点：实现简单，可解释性强。</p>
<p>缺点：容易出现欠拟合，对异常值和缺失值比较敏感。</p>
<p>from sklearn.linear_model import LinearRegression()<br>clf = LinearRegression(copy_X=True,<br>                       fit_intercept=True,<br>                       n_jobs=1,<br>                       normalize=False)<br>clf= clf.fit(x_train,y_train)  – 拟合训练</p>
<h3 id="4-4-K-means聚类"><a href="#4-4-K-means聚类" class="headerlink" title="4.4 K-means聚类"></a>4.4 K-means聚类</h3><p>from sklearn.cluster import KMeans<br>clf = KMeans(n_clusters=4, –给定的类别数<br>             max_iter=100,–为迭代的次数，这里设置最大迭代次数为300<br>             n_init=10,–设为10意味着进行10次随机初始化，选择效果最好的一种来作为模型<br>             copy_x=True–布尔型，默认值=True,如果把此参数值设为True，则原始数据不会被改变。如果是False，则会直接在原始数据<br>                        上做修改并在函数返回值时将其还原。<br>             )<br>clf= clf.fit(x)  – 拟合训练</p>
]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>sklearn函数汇总</tag>
      </tags>
  </entry>
  <entry>
    <title>spi --探秘</title>
    <url>/2020/09/29/spi/</url>
    <content><![CDATA[<p>本文通过探析JDK提供的，在开源项目中比较常用的Java SPI机制，希望给大家在实际开发实践、学习开源项目提供参考。</p>
<h2 id="1-SPI是什么"><a href="#1-SPI是什么" class="headerlink" title="1 SPI是什么"></a>1 SPI是什么</h2><p>SPI全称Service Provider Interface，是Java提供的一套用来被第三方实现或者扩展的API，它可以用来启用框架扩展和替换组件。</p>
<p>image.jpg</p>
<p>Java SPI 实际上是“基于接口的编程＋策略模式＋配置文件”组合实现的动态加载机制。</p>
<p>系统设计的各个抽象，往往有很多不同的实现方案，在面向的对象的设计里，一般推荐模块之间基于接口编程，模块之间不对实现类进行硬编码。一旦代码里涉及具体的实现类，就违反了可拔插的原则，如果需要替换一种实现，就需要修改代码。为了实现在模块装配的时候能不在程序里动态指明，这就需要一种服务发现机制。<br>Java SPI就是提供这样的一个机制：为某个接口寻找服务实现的机制。有点类似IOC的思想，就是将装配的控制权移到程序之外，在模块化设计中这个机制尤其重要。所以SPI的核心思想就是解耦。</p>
<h2 id="2-使用场景"><a href="#2-使用场景" class="headerlink" title="2 使用场景"></a>2 使用场景</h2><p>概括地说，适用于：调用者根据实际使用需要，启用、扩展、或者替换框架的实现策略</p>
<p>比较常见的例子：</p>
<p>数据库驱动加载接口实现类的加载<br>JDBC加载不同类型数据库的驱动</p>
<p>日志门面接口实现类加载<br>SLF4J加载不同提供商的日志实现类</p>
<p>Spring<br>Spring中大量使用了SPI,比如：对servlet3.0规范对ServletContainerInitializer的实现、自动类型转换Type Conversion SPI(Converter SPI、Formatter SPI)等</p>
<p>Dubbo<br>Dubbo中也大量使用SPI的方式实现框架的扩展, 不过它对Java提供的原生SPI做了封装，允许用户扩展实现Filter接口</p>
<h2 id="3-使用介绍"><a href="#3-使用介绍" class="headerlink" title="3 使用介绍"></a>3 使用介绍</h2><p>要使用Java SPI，需要遵循如下约定：</p>
<p>1、当服务提供者提供了接口的一种具体实现后，在jar包的META-INF/services目录下创建一个以“接口全限定名”为命名的文件，内容为实现类的全限定名；</p>
<p>2、接口实现类所在的jar包放在主程序的classpath中；</p>
<p>3、主程序通过java.util.ServiceLoder动态装载实现模块，它通过扫描META-INF/services目录下的配置文件找到实现类的全限定名，把类加载到JVM；</p>
<p>4、SPI的实现类必须携带一个不带参数的构造方法；</p>
<p>示例代码<br>步骤1、定义一组接口 (假设是org.foo.demo.IShout)，并写出接口的一个或多个实现，(假设是org.foo.demo.animal.Dog、org.foo.demo.animal.Cat)。</p>
<p>public interface IShout {<br>    void shout();<br>}<br>public class Cat implements IShout {<br>    @Override<br>    public void shout() {<br>        System.out.println(“miao miao”);<br>    }<br>}<br>public class Dog implements IShout {<br>    @Override<br>    public void shout() {<br>        System.out.println(“wang wang”);<br>    }<br>}<br>步骤2、在 src/main/resources/ 下建立 /META-INF/services 目录， 新增一个以接口命名的文件 (org.foo.demo.IShout文件)，内容是要应用的实现类（这里是org.foo.demo.animal.Dog和org.foo.demo.animal.Cat，每行一个类）。</p>
<p>文件位置</p>
<ul>
<li>src<br>  -main        <pre><code>  -resources            
      - META-INF                
          - services                    
              - org.foo.demo.IShout</code></pre>
文件内容</li>
</ul>
<p>org.foo.demo.animal.Dogorg.foo.demo.animal.Cat<br>步骤3、使用 ServiceLoader 来加载配置文件中指定的实现。</p>
<p>public class SPI Main {<br>    public static void main(String[] args) {<br>        ServiceLoader<IShout> shouts = ServiceLoader.load(IShout.class);<br>        for (IShout s : shouts) {<br>            s.shout();<br>        }<br>    }<br>}<br>代码输出：</p>
<p>wang wang<br>miao miao</p>
<h2 id="4-原理解析"><a href="#4-原理解析" class="headerlink" title="4 原理解析"></a>4 原理解析</h2><p>首先看ServiceLoader类的签名类的成员变量：</p>
<p>public final class ServiceLoader<S> implements Iterable<S>{<br>    private static final String PREFIX = “META-INF/services/“;</p>
<pre><code>// 代表被加载的类或者接口
private final Class&lt;S&gt; service;

// 用于定位，加载和实例化providers的类加载器
private final ClassLoader loader;

// 创建ServiceLoader时采用的访问控制上下文
private final AccessControlContext acc;

// 缓存providers，按实例化的顺序排列
private LinkedHashMap&lt;String,S&gt; providers = new LinkedHashMap&lt;&gt;();

// 懒查找迭代器
private LazyIterator lookupIterator;

......</code></pre>
<p>}<br>参考具体ServiceLoader具体源码，代码量不多，加上注释一共587行，梳理了一下，实现的流程如下：</p>
<h3 id="1-应用程序调用ServiceLoader-load方法"><a href="#1-应用程序调用ServiceLoader-load方法" class="headerlink" title="1 应用程序调用ServiceLoader.load方法"></a>1 应用程序调用ServiceLoader.load方法</h3><p>ServiceLoader.load方法内先创建一个新的ServiceLoader，并实例化该类中的成员变量，包括：</p>
<p>loader(ClassLoader类型，类加载器)</p>
<p>acc(AccessControlContext类型，访问控制器)</p>
<p>providers(LinkedHashMap&lt;String,S&gt;类型，用于缓存加载成功的类)</p>
<p>lookupIterator(实现迭代器功能)</p>
<h3 id="2-应用程序通过迭代器接口获取对象实例"><a href="#2-应用程序通过迭代器接口获取对象实例" class="headerlink" title="2 应用程序通过迭代器接口获取对象实例"></a>2 应用程序通过迭代器接口获取对象实例</h3><p>ServiceLoader先判断成员变量providers对象中(LinkedHashMap&lt;String,S&gt;类型)是否有缓存实例对象，如果有缓存，直接返回。<br>如果没有缓存，执行类的装载，实现如下：</p>
<p>(1) 读取META-INF/services/下的配置文件，获得所有能被实例化的类的名称，值得注意的是，ServiceLoader可以跨越jar包获取META-INF下的配置文件，具体加载配置的实现代码如下：</p>
<pre><code>    try &#123;
        String fullName = PREFIX + service.getName();
        if (loader == null)
            configs = ClassLoader.getSystemResources(fullName);
        else
            configs = loader.getResources(fullName);
    &#125; catch (IOException x) &#123;
        fail(service, &quot;Error locating configuration files&quot;, x);
    &#125;</code></pre>
<p>(2) 通过反射方法Class.forName()加载类对象，并用instance()方法将类实例化。</p>
<p>(3) 把实例化后的类缓存到providers对象中，(LinkedHashMap&lt;String,S&gt;类型）<br>然后返回实例对象。</p>
<h2 id="5-总结"><a href="#5-总结" class="headerlink" title="5 总结"></a>5 总结</h2><h3 id="优点："><a href="#优点：" class="headerlink" title="优点："></a>优点：</h3><p>使用Java SPI机制的优势是实现解耦，使得第三方服务模块的装配控制的逻辑与调用者的业务代码分离，而不是耦合在一起。应用程序可以根据实际业务情况启用框架扩展或替换框架组件。</p>
<h3 id="缺点："><a href="#缺点：" class="headerlink" title="缺点："></a>缺点：</h3><p>虽然ServiceLoader也算是使用的延迟加载，但是基本只能通过遍历全部获取，也就是接口的实现类全部加载并实例化一遍。如果你并不想用某些实现类，它也被加载并实例化了，这就造成了浪费。获取某个实现类的方式不够灵活，只能通过Iterator形式获取，不能根据某个参数来获取对应的实现类。</p>
<p>多个并发多线程使用ServiceLoader类的实例是不安全的。</p>
]]></content>
      <categories>
        <category>spi</category>
      </categories>
      <tags>
        <tag>spi</tag>
      </tags>
  </entry>
  <entry>
    <title>tidb</title>
    <url>/2020/11/03/tidb/</url>
    <content><![CDATA[<h1 id="TiDB-4-0"><a href="#TiDB-4-0" class="headerlink" title="TiDB 4.0"></a>TiDB 4.0</h1><p>TiDB 4.0 兼容mysql5.7版本</p>
]]></content>
      <categories>
        <category>tidb</category>
      </categories>
      <tags>
        <tag>tidb</tag>
      </tags>
  </entry>
  <entry>
    <title>多路复用技术 epoll 分析</title>
    <url>/2020/08/20/%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<pre><code> ## 多路复用技术 epoll 分析  </code></pre>
<p> epoll并没有使用共享内存 文中大部分人认为，epoll并没有使用mmap或共享内存</p>
<h2 id="Linux下的I-O复用与epoll详解"><a href="#Linux下的I-O复用与epoll详解" class="headerlink" title="Linux下的I/O复用与epoll详解"></a>Linux下的I/O复用与epoll详解</h2><p>epoll原理详解及epoll反应堆模型<br>epoll的操作<br>int epoll_create(int size);<br>int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);<br>int epoll_wait(int epfd, struct epoll_event *events,int maxevents, int timeout);<br>epoll_create: 建立一个epoll对象(在epoll文件系统中给这个句柄分配资源).<br>调用epoll_ctl向epoll对象中添加socket. 包含该socket的节点会被加入到一个红黑树上.<br>调用epoll_wait收集发生事件的连接. 触发了事件的链接会被放入一个双向链表.<br>epoll的结构与工作原理<br>红黑树. 用红黑树存储需要监听事件的socket.<br>epoll_ctl在向epoll对象中添加、修改、删除事件时，从rbr红黑树中查找事件也非常快<br>双向链表. 触发了监听事件的socket会被拷贝至此，等待用户处理。<br> 所有添加到epoll中的事件都会与设备(如网卡)驱动程序建立回调关系，也就是说相应事件的发生时会调用这里的回调方法。这个回调方法在内核中叫做ep_poll_callback，它会把这样的事件放到上面的rdllist双向链表中。</p>
<p> <img src="https://lixinx11.github.io/medias/bigdata/5.png" alt=" epoll 分析"></p>
<h2 id="epoll的两种触发模式"><a href="#epoll的两种触发模式" class="headerlink" title="epoll的两种触发模式"></a>epoll的两种触发模式</h2><p>epoll有EPOLLLT和EPOLLET两种触发模式，水平触发和边缘触发. 此处略</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>java nio是利用Selector多路复用来实现的.<br>linux2.x版本后，Selector是用epoll实现的.<br>通过建立一个Selector, 可以在其上监听socket. 通过建立一个epoll对象，可以在其上为socket注册监听事件.<br>linux epoll的常用函数是epoll_ctl, epoll_wait. 利用epoll_ctl可以为socket注册监听事件，并调用epoll_wait返回触发事件的socket.<br>epoll_ctl监听socket时，会将该socket放入红黑树<br>epoll_wait返回一个双向链表，其中包含了触发事件的socket.<br>所有添加到epoll中的事件都会与设备(如网卡)驱动程序建立回调关系，相应事件的发生时会调用回调方法ep_poll_callback.把socket放到rdllist双向链表中.<br>epoll与select poll的比较<br>select poll是采用轮询方式, epoll采用回调的方式<br>select poll每次等待socket事件，都需要把所有socket从用户态拷贝至内核态，epoll则只需将socket添加一次到红黑树上即可.<br>select用数组来存放socket, 因此受到数量限制. poll用链表存放, epoll用红黑树存放, 因此不受数量限制.<br>select、poll、epoll虽然都会返回就绪的文件描述符数量。但是select和poll并不会明确指出是哪些文件描述符就绪，而epoll会。造成的区别就是，系统调用返回后，调用select和poll的程序需要遍历监听的整个文件描述符找到是谁处于就绪，而epoll则直接处理即可。</p>
]]></content>
      <categories>
        <category>epoll</category>
      </categories>
      <tags>
        <tag>epoll</tag>
      </tags>
  </entry>
  <entry>
    <title>低代码开发</title>
    <url>/2020/09/15/%E4%BD%8E%E4%BB%A3%E7%A0%81%E5%BC%80%E5%8F%91/</url>
    <content><![CDATA[<pre><code>                                #   低代码开发未来的趋势？</code></pre>
<p>低代码开发平台是现在很火的话题，市场上的低代码开发平台，主要有两类。</p>
<h2 id="第一类，"><a href="#第一类，" class="headerlink" title="第一类，"></a>第一类，</h2><p>通过拖拽方式开发App界面，数据来源于现有系统。这个领域有很多新的创业公司，比如被西门子收购的Mendix，获得大笔融资的Outsystems，<br>还有微软开发了很多年的PowerApps。这些可以帮助企业基于现有系统开发新的应用界面，尤其是延伸到手机端。</p>
<h2 id="第二类，"><a href="#第二类，" class="headerlink" title="第二类，"></a>第二类，</h2><p>从零开始，创建业务系统，或是构建企业数据中台。这个领域需要很多年的技术积累，<br>需要通过成百上千个项目沉淀客户需求，才能做出好的开发工具。如何把基础功能标准化，如何把差异化的部分提炼出来做成可配置，这是一个非常难的课题。<br>在这方面比较领先的有以开发CRM并逐步进化的Salesforce， 开发ERP起家的Odoo 、BPM厂商华炎魔方。</p>
<h2 id="总之"><a href="#总之" class="headerlink" title="总之"></a>总之</h2><pre><code>随着人工智能的发展，初级的程序员未来竟被机器替代。企业的技能要求向设计，算法等高级技能发展。</code></pre>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>低代码开发</tag>
      </tags>
  </entry>
  <entry>
    <title>十个面向对象设计原则</title>
    <url>/2020/08/24/%E5%8D%81%E4%B8%AA%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99/</url>
    <content><![CDATA[<h2 id="十个面向对象设计原则"><a href="#十个面向对象设计原则" class="headerlink" title="十个面向对象设计原则"></a>十个面向对象设计原则</h2><p>  　 追求高内聚highly cohesive 和松耦合 loosely couple 的解决方案是面向对象设计基本核心原则。这里列出OO设计中十大原则：</p>
<h3 id="1-DRY-不要重复你自己"><a href="#1-DRY-不要重复你自己" class="headerlink" title="1. DRY (不要重复你自己)"></a>1. DRY (不要重复你自己)</h3><p>这是指不写重复的代码，取而代之是使用抽象共性的东西。如果超过一次使用硬编码，那么就要考虑将其公开为final修饰的不变量；如果你在两个以上地方有相同的代码块，那么就要考虑使其成为一个单独的方法。SOLID设计原理的好处是在维护。值得注意的是重复的不是指代码，而是对于功能而言的。</p>
<h3 id="2-封装变化"><a href="#2-封装变化" class="headerlink" title="2.封装变化"></a>2.封装变化</h3><p>在软件领域唯一不变的就是“变”，所以封装那些你估计在未来可能被改变的代码。这种设计的好处是容易测试和易于维护。如果你是进行Java编码，那么就要使变量和方法变成私有。有几个Java设计模式采用封装，工厂设计模式封装的是对象创建代码，并提供了在不改变现有的代码情况下推出新产品的灵活性。</p>
<h3 id="3-开闭原则"><a href="#3-开闭原则" class="headerlink" title="3.开闭原则"></a>3.开闭原则</h3><p>类，方法或函数应该对扩展开放（新功能）和对修改关闭。这又是一个漂亮的面向对象的设计原则，防止对已经测试过的代码尝试修改。</p>
<h3 id="4-单一职责"><a href="#4-单一职责" class="headerlink" title="4.单一职责"></a>4.单一职责</h3><p>不应该有超过一个理由去修改类，因为一个类只能有一个职责功能，如果你将多于一个功能增加到一个类中，相当于在两个功能之间引入了紧耦合。</p>
<h3 id="5-依赖注入或反转控制"><a href="#5-依赖注入或反转控制" class="headerlink" title="5.依赖注入或反转控制"></a>5.依赖注入或反转控制</h3><p>不要主动要求依赖，因为它已经由框架提供给你。比如Spring框架等，这样的设计原则妙处在于，它是由DI注入框架的注入匹配需要的类，这样更容易进行测试维护，因为创建对象的代码都集中在框架，而客户端代码是不参与的。</p>
<h3 id="6-组合胜过于继承"><a href="#6-组合胜过于继承" class="headerlink" title="6. 组合胜过于继承"></a>6. 组合胜过于继承</h3><p>如果可能的话组合composition总是胜过继承。组合比继承拥有更多的灵活性。组合允许在运行时设置属性，并通过使用接口来实现，我们可以使用多态在类运行时改变类的行为，从而提供更好的接口实现。</p>
<h3 id="7-LSP原则"><a href="#7-LSP原则" class="headerlink" title="7. LSP原则"></a>7. LSP原则</h3><p>根据里氏替换原则，子类型必须是可替代超类型，即方法或函数，它使用超类的类型必须能够与子类的对象时一样没有任何问题，如果一个类比子类有更多的功能，而子类可能不支持某些功能，这没有违反LSP。为了遵循LSP的设计原理，派生类或子类必须是增强功能不是减少它。</p>
<h3 id="8-接口分离原则ISP"><a href="#8-接口分离原则ISP" class="headerlink" title="8.接口分离原则ISP"></a>8.接口分离原则ISP</h3><p>接口隔离原则要求：客户端不应该实现它不使用的接口，。当一个接口包含一个以上的功能而客户端只需要一个功能时容易出现这种情况，因为一旦你释放你的接口，你就不能改变它。</p>
<h3 id="9-面向接口而不是实现编程"><a href="#9-面向接口而不是实现编程" class="headerlink" title="9. 面向接口而不是实现编程"></a>9. 面向接口而不是实现编程</h3><p>面向接口编程而不是面向实现子类，这有灵活性的好处，特别是同样接口有不同实现子类时。</p>
<h3 id="10-委托原则"><a href="#10-委托原则" class="headerlink" title="10.委托原则"></a>10.委托原则</h3><p>不要自己做所有的事情，可以委托给相应的类去完成。</p>
]]></content>
      <categories>
        <category>面向对象</category>
      </categories>
      <tags>
        <tag>面向对象</tag>
      </tags>
  </entry>
  <entry>
    <title>大数据技术栈</title>
    <url>/2020/05/12/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E6%A0%88/</url>
    <content><![CDATA[<p><img src="https://lixinx11.github.io/medias/bigdata/1.png" alt="大数据架构"></p>
]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>我的技术博客</tag>
      </tags>
  </entry>
  <entry>
    <title>大数据框架设计</title>
    <url>/2020/08/18/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E8%AE%BE%E8%AE%A1/</url>
    <content><![CDATA[<h2 id="大数据技术栈"><a href="#大数据技术栈" class="headerlink" title="大数据技术栈"></a>大数据技术栈</h2><p><img src="https://lixinx11.github.io/medias/bigdata/3.png" alt="大数据技术栈"></p>
]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>常见开源产品epoll网络事件模型汇总</title>
    <url>/2020/08/21/%E5%B8%B8%E8%A7%81%E5%BC%80%E6%BA%90%E4%BA%A7%E5%93%81epoll%E7%BD%91%E7%BB%9C%E4%BA%8B%E4%BB%B6%E6%A8%A1%E5%9E%8B%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<h2 id="常用模型总结："><a href="#常用模型总结：" class="headerlink" title="常用模型总结："></a>常用模型总结：</h2><p>1）epoll 1线程(listen+accept+epoll_wait+处理) 模型 …………………………………….代表产品redis<br>2）epoll 1线程(listen+accept+epoll_wait) + 1队列通知 + n线程(处理) 模型…………代表产品thrift-nonblocking-server<br>2）epoll 1线程(listen+accept+epoll_wait) + n队列通知 + n线程(处理) 模型…………代表产品memcached<br>4）epoll 1进程(listen) + n进程(accept+epoll_wait+处理) 模型………………………….代表产品nginx<br>5）epoll 1线程(listen) + n线程(accept+epoll_wait+处理) 模型<br>6)  epoll 1线程(listen+accept) + n线程(epoll_wait+处理) 模型</p>
<h2 id="常用模型汇总："><a href="#常用模型汇总：" class="headerlink" title="常用模型汇总："></a>常用模型汇总：</h2><p><img src="https://lixinx11.github.io/medias/bigdata/10.png" alt="常用模型汇总"></p>
<h2 id="常用模型对比："><a href="#常用模型对比：" class="headerlink" title="常用模型对比："></a>常用模型对比：</h2><p>  <img src="https://lixinx11.github.io/medias/bigdata/11.png" alt="常用模型对比"></p>
]]></content>
      <categories>
        <category>epoll</category>
      </categories>
      <tags>
        <tag>epoll网络事件模型分析</tag>
      </tags>
  </entry>
  <entry>
    <title>微服务架构</title>
    <url>/2014/02/10/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>微服务-不是免费的午餐！</title>
    <url>/2019/03/18/%E5%BE%AE%E6%9C%8D%E5%8A%A1-%E4%B8%8D%E6%98%AF%E5%85%8D%E8%B4%B9%E7%9A%84%E5%8D%88%E9%A4%90%EF%BC%81/</url>
    <content><![CDATA[<pre><code> ## 微服务-不是免费的午餐</code></pre>
<p>这是Contino的 CTO Benjamin Wootton的来宾帖子，Contino是一家总部位于伦敦的咨询公司，致力于将DevOps和Continuous Delivery应用于软件交付项目。 </p>
<p>微服务是一种软件体系结构，涉及将系统作为一组非常小的，颗粒状的，独立的协作服务进行交付。</p>
<p>尽管它们并不是一个新主意，但微服务在今年似乎已经爆炸式增长，文章，会议曲目和Twitter流都在抒情地表达了以这种方式构建软件系统的好处。</p>
<p>这种受欢迎程度部分是由于Cloud，DevOps和Continuous Delivery等趋势共同推动了这种方法的实现，部分是由于Netflix等公司的出色工作而来，这些公司非常明显地应用了这种模式以产生巨大效果。</p>
<p>首先让我说我是这种方法的粉丝。微服务架构具有许多非常实际和重大的好处：</p>
<p>服务本身非常简单，专注于做好一件事情。<br>可以使用最合适的最佳工具来构建每种服务；<br>以这种方式构建的系统本质上是松散耦合的。<br>在这种模式下，多个开发人员和团队可以彼此相对独立地交付；<br>它们是持续交付的重要推动力，可以频繁发布，同时保持系统的其余部分可用并稳定。<br>这就是说，微服务不是免费的午餐！</p>
<p>我目前正在参与设计基于微服务的系统，尽管各个服务非常简单，但是在管理这些服务和协调整个服务的业务流程方面，存在更高层次的复杂性。</p>
<p>微服务是在实践中很好的想法之一，但是当遇到现实时就会出现各种复杂性。出于这个原因，我想写这篇文章来捕捉其中的一些并纠正这种平衡。</p>
<h3 id="重大运营开销"><a href="#重大运营开销" class="headerlink" title="重大运营开销"></a>重大运营开销</h3><p>微服务架构带来了大量的操作开销。</p>
<p>在可能将整体应用程序部署到小型应用程序服务器群集的地方，您现在可以使用多种语言和环境使用数十个单独的服务来构建，测试，部署和运行。</p>
<p>所有这些服务都可能需要群集以实现故障转移和弹性，在您添加弹性后，您的单个整体系统将变成由40-60个进程组成的20个服务。</p>
<p>与提供相同业务功能的单个整体应用程序相比，用于在服务和资产之间进行连接的负载平衡器和消息传递层开始变得相当大！</p>
<p>生产所有这些需要高质量的监视和操作基础结构。保持应用程序服务器运行可能是一项全职工作，但是现在我们必须确保数十个甚至数百个进程保持正常运行，不要用完磁盘空间，不要死锁，保持高性能。这是一项艰巨的任务。</p>
<p>通过您的管道将大量的微服务以物理方式运送到生产中，还需要非常高度的鲁棒性以及发布和部署自动化。</p>
<p>当前，从操作的角度来看，没有太多的框架和开源工具来支持这一点。因此，推出微服务的团队可能需要在自定义脚本或开发上进行大量投资，以管理这些流程，然后再编写可提供业务价值的代码行。</p>
<p>对于模型，操作是最明显且最普遍的反对意见，尽管它很容易被该体系结构的支持者遗忘。</p>
<h3 id="要求具备实质性的DevOps技能"><a href="#要求具备实质性的DevOps技能" class="headerlink" title="要求具备实质性的DevOps技能"></a>要求具备实质性的DevOps技能</h3><p>在开发团队可能能够启动Tomcat群集并使之保持可用的地方，保持Microservices处于可用状态的操作挑战意味着您确实需要高质量的DevOps并释放嵌入在开发团队中的自动化技能。</p>
<p>您根本无法将以这种样式构建的应用程序扔给运营团队。由于基于微服务的应用程序非常紧密地集成到其环境中，因此开发团队需要非常专注于操作和生产意识。</p>
<p>惯用此体系结构还意味着许多服务也将需要自己的数据存储。当然，这些也可以是多语言的（最适合该工作的工具！），这意味着现在必须由对如何部署，运行，优化和支持少量NoSQL了如指掌的开发人员替换古老的DBA。产品。</p>
<p>拥有如此强大的DevOps配置文件的开发人员很难找到，因此如果您走这条路，您的招聘挑战就会变得更加困难。</p>
<h3 id="隐式接口"><a href="#隐式接口" class="headerlink" title="隐式接口"></a>隐式接口</h3><p>一旦将系统分解为协作组件，就会在它们之间引入接口。接口充当合同，双方需要交换相同的消息格式并对这些消息具有相同的语义理解。</p>
<p>更改合同一侧的语法或语义，所有其他服务都需要了解该更改。在微服务环境中，这可能意味着简单的跨领域变更最终需要对许多不同的组件进行更改，所有这些组件都需要以协调的方式发布。</p>
<p>当然，我们可以使用向后兼容方法来避免其中的某些更改，但是您经常会发现，业务驱动的需求无论如何都禁止分阶段发布。例如，发布新产品线或外部强制性法规变更可能会迫使我们一起释放大量服务。由于集成点，与替代的整体应用程序相比，这代表了额外的发布风险。</p>
<p>如果我们让协作服务前进并变得不同步（也许以金丝雀的发布风格），则更改消息格式的效果将变得非常难以可视化。</p>
<p>再次，贝克特兼容性在这里并不是微服务传播者声称的万能药。</p>
<h3 id="重复努力"><a href="#重复努力" class="headerlink" title="重复努力"></a>重复努力</h3><p>想象一下，存在一项新的业务需求，即针对某个产品线以不同方式计算税额。我们有几种选择来实现这一目标。</p>
<p>我们可以引入一项新服务，并允许其他服务在需要时调用此服务。但是，这确实将更多潜在的同步耦合引入到系统中，因此我们不会轻易做出决定。</p>
<p>我们可以复制工作量，将税额计算添加到需要它的所有服务中。除了重复的开发工作之外，以这种方式重复执行通常被认为是一个坏主意，因为每个代码实例都需要进行测试和维护。</p>
<p>最后的选择是在服务之间共享资源，例如税收计算库。这可能很有用，但是它并不总是在多语言环境中起作用，并且引入了耦合，这可能意味着必须并行释放服务以维护它们之间的隐式接口。这种耦合实质上减轻了微服务方法的许多好处。</p>
<p>在我看来，这三个选项都是次优的，而不是一次编写代码并使之在整个应用程序中可用。我见过的以这种方式工作的团队倾向于选择2，复制业务逻辑，这违反了良好软件工程的许多原则。是的，这甚至发生在经过良好分解和设计良好的系统中-并不总是表明服务边界不好。</p>
<h3 id="分布式系统复杂度"><a href="#分布式系统复杂度" class="headerlink" title="分布式系统复杂度"></a>分布式系统复杂度</h3><p>微服务意味着分布式系统。在以前可能有一个方法调用充当子系统边界的地方，现在我们引入了许多远程过程调用，REST API或消息传递，以将不同进程和服务器之间的组件粘合在一起。</p>
<p>分发完系统后，我们必须考虑很多以前从未考虑过的问题。网络延迟，容错，消息序列化，不可靠的网络，异步性，版本控制，我们的应用程序层中的不同负载等。</p>
<p>为其中一些编码是一件好事。向后兼容性和正常降级是我们可能无法在整体式替代方案中实现的良好属性，有助于保持系统正常运行，并且比整体式应用程序具有更高的可用性。</p>
<p>但是，这样做的代价是应用程序开发人员必须考虑所有以前不需要的所有事情。分布式系统更难以开发和测试一个数量级，因此与构建那种不性感的整体应用程序相比，门槛再次提高。</p>
<h3 id="异步困难！"><a href="#异步困难！" class="headerlink" title="异步困难！"></a>异步困难！</h3><p>与上述观点有关，以微服务样式构建的系统可能比单片应用程序异步得多，它们依靠消息传递和并行性来提供其功能。</p>
<p>当我们将工作分解成真正独立的独立任务时，异步系统非常有用，这些任务可能在不同时间发生混乱。</p>
<p>但是，当事情必须在固有的异步体系结构中同步或事务发生时，事情变得复杂了，我们需要管理关联ID和分布式事务以将各种操作绑定在一起。</p>
<h3 id="可测性挑战"><a href="#可测性挑战" class="headerlink" title="可测性挑战"></a>可测性挑战</h3><p>如此众多的服务都以不同的步伐发展，并且不同的服务在内部推出了canary版本，因此很难以一致的方式重新创建环境以进行手动或自动测试。当我们添加异步性和动态消息负载时，测试以这种方式构建的系统变得更加困难，并且对将要发布到生产环境中的服务集充满信心。</p>
<p>我们可以测试单个服务，但是在这种动态环境中，服务的交互会出现非常细微的行为，很难对其进行可视化和推测，更不用说对其进行全面测试了。</p>
<p>惯用微服务需要减少对测试的重视，而将更多的精力放在监视上，因此我们可以发现生产中的异常并迅速回滚或采取适当的措施。我坚信这种方法-降低释放壁垒并倾向于连续交付以加快瘦肉交付。但是，由于花了数年时间应用测试自动化以在发布之前获得信心的人，降低此功能的任何事情都感觉要付出高昂的代价，尤其是在错误规避风险的环境中，错误可能会产生重大影响。</p>
<h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>这些是在构建和运行基于微服务的系统的早期阶段遇到的一些困难。</p>
<p>我仍然是这种方法的忠实拥护者，并相信在具有适当团队的适当项目下，采用这种架构是一种很棒的架构，在这种架构中，收益大于成本。</p>
<p>但是，在考虑像微服务这样的体系结构时，重要的是不要被这一类的炒作吸引，因为挑战和成本与收益一样真实。</p>
]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>微服务</tag>
      </tags>
  </entry>
  <entry>
    <title>技术趋势</title>
    <url>/2020/09/04/%E6%8A%80%E6%9C%AF%E8%B6%8B%E5%8A%BF/</url>
    <content><![CDATA[<pre><code>                           #  新冠肺炎后五大技术争夺战</code></pre>
<p>   技术正在以惊人的速度发展，为现代企业、竞争对手和整个行业定义下一个前沿领域。普华永道(PWC)最近进行的一项题为“驾驭不确定性浪潮——第23届全球CEO年度调查”的调查显示，69%的CEO对科技变革的速度感到担忧，难以跟上科技变革的步伐。只有27%的受访者承认他们对2020年的收入增长前景非常有信心，这是自2009年经济衰退以来的最低水平。<br>　　技术将发挥决定性的作用，因为各国制定了在COVID-19之后的复苏计划。突破性的技术研发将形成创新的中坚力量。展望未来，以下是前5大技术，它们将争夺后COVID-19的霸主地位，并创造潜在的投资机会和快速的商业利益。</p>
<h2 id="人工智能"><a href="#人工智能" class="headerlink" title="人工智能"></a>人工智能</h2><p>　　多年来，人工智能一直是最受争议和最受欢迎的技术，被吹捧为下一个重大技术。由COVID-19病毒引起的技术变革可能意味着人工智能的骄傲时刻终于到来了。<br>　　在寻求业务连续性规划的过程中，企业需要将更多数据集中在云上，从而推动人工智能的发展。从更精确的预测算法到RPA——人工智能的能力是不可思议的。人工智能优势的另一个机会来自远程工作的增加。在组织机构艰难应对招回员工的挑战之际，它们可能更愿意接受基于人工智能的过程自动化软件来处理日常和基于规则的任务。<br>##　　物联网<br>　　物联网(IoT)以及其他颠覆性技术，如云和人工智能，可能会在COVID-19恢复后成为游戏规则的改变者。根据麻省理工学院研究人员的一项研究，物联网技术及其连接的传感器有助于监测高危患者，从而减轻感染性传播的关键来源。<br>　　连接的传感器还可以帮助自动化某些过程，并将人类执行每项活动的需要降到最低，用例包括监视、监视和预测性维护。<br>##　　云计算<br>　　云计算是一项不容忽视的技术。随着企业数字化和员工在家工作，云服务器呈现服务器，与合作伙伴和客户协作。<br>　　许多企业正在借助云技术迅速扭转颓势，以极快的速度调整和改造其运营。想想基督教青年会(YMCA)、星球健身中心(PlanetFitness)和耐克(Nike)，它们提供的服务包括在线健身课程。学校和大学正在提供在线学习，而OTT内容的需求已经急剧上升，这要归功于云。在线杂货零售商也看到了新的业务增长，这一切都要归功于云基础设施。<br>　　每一个企业都在寻找云——公共的、私有的和混合的云——来重新设想其运营，并使协作达到前所未有的规模。<br>##　　区块链<br>　　COVID-19危机使全球供应链陷入混乱，制造业的未来也面临严重问题。区块链和透明账本对经济复苏和经济活动恢复至关重要。这种大范围的挑战为区块链的整合提供了机会，区块链有能力改变供应链的未来。<br>　　为了重建被破坏的网络，信任和验证信息的能力将是必不可少的。区块链技术提供了构建块，可为贸易合作伙伴和消费者提供受信任和受保护数据的透明性，并通过共同商定的规则集同步流程。对于那些因大流行而导致供应链中断的企业而言，这种潜力特别具有吸引力。<br>##　　机器人学<br>　　在COVID-19之后，机器人将成为企业的面孔，主要是为了减轻员工的危险任务;并实现快速的生产时间表和低成本。为了应对当前的危机，这些“机器助手”将加入执行董事会。<br>　　如果企业领袖积极投资于正确的技术，那么从宏观层面来看，这可能是他们产品和经济增长的关键时刻。<br>　　COVID-19对世界经济的影响虽然是暂时的，但稳定和长期改善的基本面受到了冲击和挑战。技术带来的机遇是巨大的，只有采取灵活和开放的方法，企业才能取得成功，而这样做的人从长远来看肯定会得到好处。</p>
]]></content>
      <categories>
        <category>技术趋势</category>
      </categories>
      <tags>
        <tag>技术趋势</tag>
      </tags>
  </entry>
  <entry>
    <title>技术选型</title>
    <url>/2020/09/01/%E6%8A%80%E6%9C%AF%E9%80%89%E5%9E%8B/</url>
    <content><![CDATA[<p>categories:  #分类<br>    -  技术选型</p>
<pre><code>命令行工具：iTerm2
浏览器：Chrome
虚拟机：VirtualBox
MySQL 数据库查询工具：Sequel-Ace
Redis 管理工具：RDM
MongoDB 管理工具：MongoDB
设计工具：Sketch 3
视频播放：MPlayerX
@todo zsh 的配置信息统一，Alias 等信息。</code></pre>
]]></content>
      <tags>
        <tag>技术选型</tag>
      </tags>
  </entry>
  <entry>
    <title>拼多多的晋升之道</title>
    <url>/2019/11/22/%E6%8B%BC%E5%A4%9A%E5%A4%9A%E7%9A%84%E6%99%8B%E5%8D%87%E4%B9%8B%E9%81%93/</url>
    <content><![CDATA[<p>成立于2015年的拼多多，在一切人都以为电商的格局曾经尘埃落定的时候，再次证实了增加的机遇首先来自看待增加的视角。那么它迸发性增加的势能在哪儿呢？它是如何完成为了迸发增加？<br>拼多多迸发式增加的三个势能</p>
<h2 id="势能1：错位竞争，弯道超车"><a href="#势能1：错位竞争，弯道超车" class="headerlink" title="势能1：错位竞争，弯道超车"></a>势能1：错位竞争，弯道超车</h2><p>拼多多的第一个势能是捉住了三四线乃至五六线都会迸发增加的触网用户，并胜利引入了这些流量。</p>
<p>近几年中国市场一直在提“花费进级”这一观点，原有互联网巨擘都在结构花费进级后的佳构电商，例如网易严选、盒马鲜生、天猫小店、生活选集等。花费进级的提出、佳构电商的结构，与拼多多成立和疾速发展的时间段高度重合。拼多多反其道行之，锁定了三线到六线都会，锁定了价钱敏感用户，它的电商价值定位就和阿里巴巴、京东形成为了巨大差异，进入当时的“战略无人区”。</p>
<p>拼多多经由过程接手降级市场，错位竞争，完成为了弯道超车。</p>
<h2 id="势能2：交际与电商的交融"><a href="#势能2：交际与电商的交融" class="headerlink" title="势能2：交际与电商的交融"></a>势能2：交际与电商的交融</h2><p>拼多多的第二个势能就在于交融了“交际”与“电商”的功能。这是阿里巴巴和腾讯两家超等巨擘都没有完成的交融。</p>
<p>拼多多经由过程低价产物刺激用户在上分享和流传，想要超等优惠的价钱，用户就要主动发起拼团，只要激活一个用户，用户周边尤其是上的朋友、家人、邻居都有可能被覆盖。最终，成为拼多多的流量入口，拼多多将电子商务胜利融入交际平台。</p>
<p>咱们能够看到，拼多多的增加迸发线是树立在用户干系的指数性激活和购买裂变上。传统期间的营业基本上是B2C营业，即企业面临花费者，进行推广流传、渠道构建与销售活动，而数字期间最大的特点是花费者自身便是互联体，假如能充分激活用户干系资产，这个算法模型就从B2C变成为了B2C2C，也便是企业到花费者到花费者，这样一个n次方形式，C的n次方便是用户的指数裂变。</p>
<p>有了用户和定单，使得拼多多对上游具备更强的议价能力，拼多多直接与制造商、品牌商合作，为花费者带来低成本的商品，形成增加的良性循环。</p>
<h2 id="势能3：告白轰炸"><a href="#势能3：告白轰炸" class="headerlink" title="势能3：告白轰炸"></a>势能3：告白轰炸</h2><p>第三个势能是利用告白的集中轰炸，敏捷晋升拼多多在目标市场上的知名度和被信任度。</p>
<p>为巩固其流量优势和品牌知名度，拼多多自 2016年10月起在一线和二线都会推出了大批线下告白。经由过程赞助综艺节目，拼多多敏捷拓展了在三线到六线都会的知名度和被信任度，吸引了大批精准花费人群。</p>
]]></content>
      <categories>
        <category>产品</category>
      </categories>
      <tags>
        <tag>拼多多的晋升之道</tag>
      </tags>
  </entry>
  <entry>
    <title>整合测试</title>
    <url>/2019/04/16/%E6%95%B4%E5%90%88%E6%B5%8B%E8%AF%95/</url>
    <content><![CDATA[<h2 id="整合测试"><a href="#整合测试" class="headerlink" title="整合测试"></a>整合测试</h2><h3 id="如何在微服务架构中编写集成测试？"><a href="#如何在微服务架构中编写集成测试？" class="headerlink" title="如何在微服务架构中编写集成测试？"></a>如何在微服务架构中编写集成测试？</h3><p>编写集成测试需要大量的精力。与编写单元测试相比，它花费更多，并且要打开的锁数量要多得多。虽然我们仅通过单元测试保证服务的功能，但我们需要集成测试来保证与其他服务的通信。</p>
<p>当涉及集成时，难度级别会进一步增加，并且还涉及微服务架构。如果您之前编写过Moliolith应用程序的集成测试，则可以更清楚地看到它们之间的区别。</p>
<p>在本节中，我们将研究基于Microservis体系结构和消费者驱动的合同测试方法的系统中集成测试的重要性，这通过为主题带来不同的视角，使我们免于编写集成测试的成本。  </p>
<h3 id="为什么我们需要集成测试？"><a href="#为什么我们需要集成测试？" class="headerlink" title="为什么我们需要集成测试？"></a>为什么我们需要集成测试？</h3><p>随着微服务架构中服务数量的增加，服务之间的通信和集成数量将成正比例增加。包含10个服务的系统和100个或更多服务相互交谈的系统的复杂性和维护成本无疑将是相同的。</p>
<p>让我们考虑一个由数十个微服务组成的大型企业应用程序。我们有一个名为CustomerService的服务。该服务提供了与我们客户有关的其他服务可能需要的所有服务。因此，应使用该服务将对此服务进行的更改通知其他服务。否则，如果幸运的话，相关服务或不知道此更改的服务将在测试环境中失败。在最坏的情况下，如果正在进行的测试过程未涵盖该服务，则当您在实时环境中失败时，系统会通知您，这是我们想要的最后一件事。</p>
<p>同样，如果为CustomerService还需要其他服务的数据，该服务所做的更改应该也可以用已知的CustomerService。 </p>
<p>那么我们如何管理这些变更通知？我们可以用人工手动处理吗？此外，我们是否知道哪些服务会影响我们更改的服务？我们是否需要最新的文档？</p>
<p>如果我们的应用程序包含少量微服务，则该团队中的团队可能很小，您也许可以以某种方式手动进行升级。在这里，我们所说的手动是指将对团队内服务所做的更改直接通知给受更改影响的服务的负责任服务。但是，不幸的是，如果我们谈论的是数十种甚至数百种服务，则无法手动管理它。</p>
<p>补救措施：消费者驱动的合同测试（CDC测试）<br>我们有一个问题要知道您对微服务所做的最细微的更改如何影响使用该服务的消费者，而CDC测试可能是解决此问题的好方法。</p>
<p>我们可以将CDC方法定义为最简单的形式，因为这两个服务就它们彼此发送的数据格式达成一致。此方法基于即时共享服务提供商或服务使用者所做的每个更改的原理。</p>
<p>实施CDC时最重要的问题之一是管理消费者和提供者服务的团队之间的沟通。通信越断开线，实施CDC就会越困难。因此，最佳方案是所有服务均由同一团队负责。</p>
<p>我们聊了很多，好吧，好吧，猜想您开始考虑如何实现此CDC，我想向您介绍Pact框架。由于Pact的详细实施时间可能会长一些，因此我认为在此处提供有关哪种伤口是软膏，其基本结构和用法的入门级信息是合适的。 </p>
<h3 id="契约CDC测试框架"><a href="#契约CDC测试框架" class="headerlink" title="契约CDC测试框架"></a>契约CDC测试框架</h3><p>让我们先看一下Pact的官方资料。</p>
<p>Pact是一个由消费者驱动的合同测试框架。Pact诞生于微服务的繁荣时期，旨在解决大型分布式系统的集成测试问题。</p>
<p>Pact 是由Pact Foundation使用Ruby语言开发的开源CDC测试框架。它支持多种语言，例如Php，Go，C＃以及Ruby。如果查看Pact Fodundation的github页面，您会看到它在每种语言的单独存储库中进行。 </p>
<p>现在，让我们看一下如何逐步实现而又不涉及太多技术细节和代码部分。 </p>
<p>情境<br>我们有一个名为CustomerService的服务，以及另一个使用此服务的ProductService的服务。在这里，他们扮演CustomerService Provider和ProductService作为Consumer的角色。换句话说，CustomerService的更改是否影响ProductService至关重要。</p>
<h4 id="1-在消费者服务端创建合同"><a href="#1-在消费者服务端创建合同" class="headerlink" title="1-在消费者服务端创建合同"></a>1-在消费者服务端创建合同</h4><p>如果我们正在创建测试项目，则无法担任服务的productervi角色的使用者。通过确定我们要编写测试场景，我们写我们的单元测试按照格式被确定PactNet和我们提供的服务模拟。在这里，单元测试语句应该引起您的注意。我们从一开始就说集成测试，您可能想知道，它来自哪里？ </p>
<p>使用CDC，我们脱离了经典的Integration Test编写格式。如您所知，通常Integration Test方法实际上执行与Unit Tests不同的Web服务或数据库访问。因此，不涉及任何嘲笑。CDC yi Pact由作者在单元测试，提供程序服务中实施，而我们却无法接受，因为我们不再与重要的合同是我们之间的提供程序协议。</p>
<p>消费者，提供者 ‘将被X请求相应的Y接受使用FLUENT提供的方法在Pact所指类型的测试类单元中的响应。</p>
<h4 id="2-创建协议合同（合同）并与提供者共享"><a href="#2-创建协议合同（合同）并与提供者共享" class="headerlink" title="2-创建协议合同（合同）并与提供者共享"></a>2-创建协议合同（合同）并与提供者共享</h4><p>消费者测试在文章侧的所有测试方法之后运行。运行测试后，需要创建json格式的Contract。该json文件将在配置Pact时指定的目录中创建。该json文件将随着测试方法中的每一次更改而自动更新，并且始终会在指定目录中进行更新。换句话说，Pact处理合同的不断更新，这是一个非常重要的问题。</p>
<p>生成的文件为json格式且可读性很强的事实使我们甚至可以将CDC应用于结构非常不同的服务。随着供应商编写的围棋语言，一个PHP的消费者可以动摇对他们的契约合同手中。 </p>
<p>以下是合同契约示例。在“ 交互”列表下具有两个交互意味着要编写两种测试方法。请求部分消费者然后要求而作出响应。如果对请求消费者的供应商 “，是指从响应的期望。如您所见，它实际上是一种清晰的格式，不需要解释。资料来源：https : //github.com/tdshipley/pact-workshop-dotnet-core-v1</p>
<p>{<br>  “消费者”：{<br>    “名称”：“消费者”<br>  }，<br>  “提供者”：{<br>    “名称”：“提供者”<br>  }，<br>  “互动”：[<br>    {<br>      “ description”：“具有无效日期参数的日期验证的无效GET请求”，<br>      “ providerState”：“有数据”，<br>      “请求”：{<br>        “ method”：“ get”，<br>        “ path”：“ / api / provider”，<br>        “ query”：“ validDateTime =哈哈兹”<br>      }，<br>      “响应”：{<br>        “状态”：400，<br>        “标题”：{<br>          “ Content-Type”：“应用程序/ json; charset = utf-8”<br>        }，<br>        “身体”： {<br>          “ message”：“ validDateTime不是日期或时间”<br>        }<br>      }<br>    }，<br>    {<br>      “ description”：“用于日期验证的有效GET请求”，<br>      “ providerState”：“没有数据”，<br>      “请求”：{<br>        “ method”：“ get”，<br>        “ path”：“ / api / provider”，<br>        “ query”：“ validDateTime = 04/04/2018”<br>      }，<br>      “响应”：{<br>        “状态”：404，<br>        “标题”：{<br>        }<br>      }<br>    }<br>  ]<br>  “元数据”：{<br>    “ pactSpecification”：{<br>      “ version”：“ 2.0.0”<br>    }<br>  }<br>}</p>
<h4 id="3-通知提供商合同"><a href="#3-通知提供商合同" class="headerlink" title="3-通知提供商合同"></a>3-通知提供商合同</h4><p>在最后阶段，我们需要告知我们的提供商希望与他签订合同的消费者，并提供有关协议保留位置的信息，以便我们的提供商知道哪个消费者在他进行的任何更改中都会受到影响。</p>
<p>我们可以使用Pact提供的流利方法轻松地做到这一点。我们可以为提供者定义任意数量的消费者和契约网址。在讨论代码细节之前，让我们在总结主题之前最后讨论一下Pact Broker概念。 </p>
<h3 id="什么是契约经纪人？"><a href="#什么是契约经纪人？" class="headerlink" title="什么是契约经纪人？"></a>什么是契约经纪人？</h3><p>我们将在与提供者共享的部分中配置 “ 契约 ”时确定的目录中创建 json格式的合同。’我们说。在使用者和提供者处于同一环境中的情况下，将合同存储在目录中将很有用，但是在现实生活中，您将必须在Internet上即服务器上共享此文件。公约为我们提供了两种可能性。我们要做的就是指定json文件的位置，而不是目录，写上Pact Broker的地址，以及凭据信息（如果有）。对使用者和提供者执行相同的过程。现在，我们的服务将能够与在互联网上公开或私有的合同握手。</p>
<p>如果您希望将Pact Broker服务作为SaaS获得，则还可以提供官方服务。您可以通过访问<a href="https://pactflow.io/%E6%9F%A5%E7%9C%8B%E5%AE%83%E3%80%82%E5%A6%82%E6%9E%9C%E6%82%A8%E6%89%93%E7%AE%97%E8%AE%A4%E7%9C%9F%E4%BD%BF%E7%94%A8Pact%EF%BC%8C%E5%BB%BA%E8%AE%AE%E6%82%A8%E4%BD%BF%E7%94%A8Pact">https://pactflow.io/查看它。如果您打算认真使用Pact，建议您使用Pact</a> Broker。</p>
<p>此外，Pact Broker的界面非常不错，可以查看合同和数据的最新状态，例如哪种服务取决于哪种服务。作为示例，我总结了我从Pact Broker的github页面获取的两个屏幕截图。</p>
<p><img src="https://lixinx11.github.io/medias/bigdata/4.png" alt="Pact Broker"></p>
<p>图片来自<a href="https://github.com/pact-foundation/pact_broker">https://github.com/pact-foundation/pact_broker</a><br>虽然您可以在上图中看到我们定义的服务之间的关系，但在下面我们可以看到合同的最新状态。合同验证的日期位于提供商的“ 上次验证”列的右边。红色表示交易失败。</p>
<p>在本节中，我们研究了消费者驱动的冲突方法，该方法为集成测试（微服务体系结构中最具挑战性的问题之一）以及用于实现此方法的Pact框架带来了不同的观点。</p>
<p>如果您要使用微服务体系结构开发产品，建议您将Pact或其他框架作为软件开发生命周期中必不可少的一部分。</p>
]]></content>
      <categories>
        <category>测试</category>
      </categories>
      <tags>
        <tag>测试</tag>
      </tags>
  </entry>
  <entry>
    <title>最好用的自动化测试工具</title>
    <url>/2019/07/23/%E6%9C%80%E5%A5%BD%E7%94%A8%E7%9A%84%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7/</url>
    <content><![CDATA[<h2 id="Selenium"><a href="#Selenium" class="headerlink" title="Selenium"></a>Selenium</h2><p>WebUI自动化测试</p>
<p>Selenium是网页应用中最流行的开源自动化测试框架。起源于2000年，10多年来不断地完善，Selenium成为许多Web自动化测试人员的选择，尤其是那些有高级编程和脚本技能的人。Selenium也成为了其他开源自动化测试工具比如Katalon Studio，Watir，Protractor和Robot Framework的核心框架。</p>
<p>Selenium 支持多系统环境（Windows，Mac，Linux）以及多种浏览器（Chrome，FireFox，IE以及无头浏览器（没有界面））。它的脚本可以由各种各样的编程语言编写，比如 Java，Groovy，Python，C#，PHP，Ruby 以及 Perl。</p>
<p>因为Selenium的灵活性，测试人员可以写各种复杂的、高级的测试脚本来应对各种复杂的问题，它需要高级的编程技能和付出来构建满足自己需求的自动化测试框架和库。</p>
<h2 id="Appium"><a href="#Appium" class="headerlink" title="Appium"></a>Appium</h2><p>AppUI自动化测试</p>
<p>Appium是一个移动端自动化测试开源工具，支持iOS和Android平台，支持Python、Java等语言，即同一套Java或Python脚本可以同时运行在iOS和Android平台，Appium 是一个C/S架构，核心是一个Web服务器，它提供了一套REST的接口。当收到客户端的连接后，就会监听到命令，然后在移动设备上执行这些命令，最后将执行结果放在HTTP响应中返还给客户端。</p>
<h2 id="Jmeter"><a href="#Jmeter" class="headerlink" title="Jmeter"></a>Jmeter</h2><p>接口测试，性能测试</p>
<p>Apache JMeter是一个开源的Java桌面应用程序，主要用于web应用程序的负载测试。它还支持单元测试和有限的功能测试。</p>
<p>它有很多好的特性，比如动态报告、可移植性、强大的测试IDE等，并且支持不同类型的应用程序、协议、shell脚本、Java对象和数据库。</p>
<h2 id="Postman"><a href="#Postman" class="headerlink" title="Postman"></a>Postman</h2><p>接口测试</p>
<p>Postman 提供功能强大的Web API和HTTP请求的调试，它能够发送任何类型的HTTP请求 (GET, POST, PUT, DELETE…)，并且能附带任何数量的参数和Headers。不仅如此，它还提供测试数据和环境配置数据的导入导出，付费的Post Cloud用户还能够创建自己的 Team Library用来团队协作式的测试，并能够将自己的测试收藏夹和用例数据分享给团队。</p>
<h2 id="SoapUI"><a href="#SoapUI" class="headerlink" title="SoapUI"></a>SoapUI</h2><p>接口测试</p>
<p>SoapUI是一个非常流行的用于SOAP和REST的开源API测试自动化框架。它还支持功能测试、性能测试、数据驱动测试和测试报告。</p>
<h2 id="Monkey"><a href="#Monkey" class="headerlink" title="Monkey"></a>Monkey</h2><p>稳定性测试</p>
<p>软件附带在sdk中，适用于android和ios，通过adb shell，生成用户或系统的伪随机事件。</p>
<p>压力测试结果：崩溃crash，无响应anr，</p>
<p>基本命令：adb shell monkey 1000。</p>
<h2 id="Robot-Framework"><a href="#Robot-Framework" class="headerlink" title="Robot Framework"></a>Robot Framework</h2><p>WebUI自动化测试，接口测试</p>
<p>Robot Framework是一个开源自动化框架，它实现了用于验收测试和验收测试驱动开发（ATDD）的关键字驱动方法。Robot Framework为不同的测试自动化需求提供框架。但是，通过使用Python和Java实现其他测试库，可以进一步扩展其测试功能。Selenium WebDriver是Robot Framework中常用的外部库。</p>
<p>测试工程师可以利用Robot Framework作为自动化框架，不仅可以进行Web测试，还可以用于Android和iOS测试自动化。对于熟悉关键字驱动测试的测试人员，可以轻松学习Robot Framework。</p>
<h2 id="QTP"><a href="#QTP" class="headerlink" title="QTP"></a>QTP</h2><p>WebUI自动化测试</p>
<p>QTP是一种自动测试工具。使用 QTP 的目的是想用它来执行重复的手动测试，主要是用于回归测试和测试同一软件的新版本。因此你在测试前要考虑好如何对应用程序进行测试，例如要测试那些功能、操作步骤、输入数据和期望的输出数据等。</p>
<p>QTP针对的是GUI应用程序，包括传统的Windows应用程序，以及现在越来越流行的Web应用。它可以覆盖绝大多数的软件开发技术，简单高效，并具备测试用例可重用的特点。其中包括：创建测试、插入检查点、检验数据、增强测试、运行测试、分析结果和维护测试等方面。</p>
<h2 id="LoadRunner"><a href="#LoadRunner" class="headerlink" title="LoadRunner"></a>LoadRunner</h2><p>性能测试</p>
<p>LoadRunner，是一种预测系统行为和性能的负载测试工具。通过以模拟上千万用户实施并发负载及实时性能监测的方式来确认和查找问题，LoadRunner能够对整个企业架构进行测试。</p>
<p>企业使用LoadRunner能最大限度地缩短测试时间，优化性能和加速应用系统的发布周期。LoadRunner可适用于各种体系架构的自动负载测试，能预测系统行为并评估系统性能。</p>
<h2 id="Jenkins"><a href="#Jenkins" class="headerlink" title="Jenkins"></a>Jenkins</h2><p>持续集成</p>
<p>自动化构建编译，部署，任务执行，测试报告，邮件通知等。</p>
]]></content>
      <categories>
        <category>测试</category>
      </categories>
      <tags>
        <tag>自动化测试</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习+深度学习+人工智能之间的关系</title>
    <url>/2018/08/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B3%E7%B3%BB/</url>
    <content><![CDATA[<h2 id="机器学习-深度学习-人工智能之间的关系"><a href="#机器学习-深度学习-人工智能之间的关系" class="headerlink" title="机器学习+深度学习+人工智能之间的关系"></a>机器学习+深度学习+人工智能之间的关系</h2><p><img src="https://lixinx11.github.io/medias/bigdata/2.png" alt="机器学习+深度学习+人工智能之间的关系"></p>
]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习知识点</title>
    <url>/2020/09/07/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E7%82%B9/</url>
    <content><![CDATA[<h2 id="Python——用于训练机器学习算法的编程语言。"><a href="#Python——用于训练机器学习算法的编程语言。" class="headerlink" title="Python——用于训练机器学习算法的编程语言。"></a>Python——用于训练机器学习算法的编程语言。</h2><p>确保你知道这门语言提供了哪些功能。除了 Python，我还建议你学习另外一门语言。如果要使用嵌入式平台，请选择 C++。如果要在企业环境中使用机器学习模型，请选择 Java。如果你想进行数据分析，请学习 R 语言。最后，如果你喜欢经典的 AI 算法和自然语言处理，请学习 Lisp。</p>
<h2 id="TensorFlow-Pytorch——深度学习正在蓬勃发展。"><a href="#TensorFlow-Pytorch——深度学习正在蓬勃发展。" class="headerlink" title="TensorFlow/Pytorch——深度学习正在蓬勃发展。"></a>TensorFlow/Pytorch——深度学习正在蓬勃发展。</h2><p>市场上有两个深度学习框架，但哪些项目应该使用哪个框架，它们之前的区别是非常不一样的。首先，需要注意的是，TensorFlow 通常在部署环境中更易于使用，而 Pytorch 在实验环境中更易于使用。最近，TensorFlow 试图让实验变得更容易，而 Pytorch 则致力于实现更容易的部署（即使在嵌入式硬件上）。如果你想要担当更多研究角色，我会推荐 Pytorch。如果你想要在一家主要在生产环境中更新模型的公司工作，我会推荐学习 TensorFlow。总体上讲，全面学习一个框架要比半途学习两个框架要好，尤其要考虑它们演化的速度。</p>
<h2 id="Scikit-learn——scikit-learn"><a href="#Scikit-learn——scikit-learn" class="headerlink" title="Scikit-learn——scikit-learn"></a>Scikit-learn——scikit-learn</h2><p>包含了大多数经典的机器学习算法。掌握它可以让你快速解决很多小的数据问题。如果你知道这个库的算法原理，那么在技术面试过程中就有领先优势。</p>
<h2 id="NumPy-和-Pandas"><a href="#NumPy-和-Pandas" class="headerlink" title="NumPy 和 Pandas"></a>NumPy 和 Pandas</h2><p> ——在使用 Python 处理数据时，有效且准确地选择数据是非常重要的。大多数机器学习工程师每天都使用 NumPy 进行基本的数据处理。如果你有更高级的选择标准，可以考虑 Pandas！只需要用几行代码（并且没有那些令人讨厌的 for 慢循环）选择特定的数据样本就可以给未来的同事留下深刻的印象。</p>
<h2 id="Apache-Spark"><a href="#Apache-Spark" class="headerlink" title="Apache Spark"></a>Apache Spark</h2><p>——拥有大量数据的公司将从机器学习中受益。处理大数据非常重要，Spark 将大大加快你的开发工作。请注意，在处理大数据时，了解 Hadoop 可能也很有帮助。</p>
<h2 id="OpenCV"><a href="#OpenCV" class="headerlink" title="OpenCV"></a>OpenCV</h2><p>——如果你想要使用计算机视觉学习，掌握 OpenCV 就至关重要。它提供了很多图像处理功能，可用于快速组建原型，或以更好的方式预处理图像。它还提供了很多识别、检测或定位物体的功能。</p>
]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>机器学习知识点</tag>
      </tags>
  </entry>
  <entry>
    <title>算法</title>
    <url>/2020/08/17/%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<h2 id="一亿数据获取前1000个最大值"><a href="#一亿数据获取前1000个最大值" class="headerlink" title="一亿数据获取前1000个最大值"></a>一亿数据获取前1000个最大值</h2><p> ###算法原理：</p>
<p>把一亿个数字的前100个 首先放入数组。 然后把最小值放在ary[0]。</p>
<p>然后再循环100到一亿之间的。 每次循环判断当前数字是否大于ary[0]</p>
<p>当大于时，当前数字放入ary[0] 并再次重构数组最小值进入ary[0]  以此类推 。</p>
<p>当循环完这一亿个数字后。 最大的前100个数字就出来了。</p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>自反性</title>
    <url>/2020/10/03/%E8%87%AA%E5%8F%8D%E6%80%A7/</url>
    <content><![CDATA[<h1 id="设A-1，2，3，4-，下列几个是A-上的二元关系。"><a href="#设A-1，2，3，4-，下列几个是A-上的二元关系。" class="headerlink" title="设A={1，2，3，4}，下列几个是A 上的二元关系。"></a>设A={1，2，3，4}，下列几个是A 上的二元关系。</h1><p>R1={&lt;1，1&gt;，&lt;1，2&gt;，&lt;2，1&gt;，&lt;2，2&gt;，&lt;3，4&gt;，&lt;4，1&gt;，&lt;4，4&gt;}；<br>R2={&lt;1，1&gt;，&lt;1，2&gt;，&lt;2，1&gt;}；<br>R3={&lt;1，1&gt;，&lt;1，2&gt;，&lt;1，4&gt;，&lt;2，1&gt;，&lt;2，2&gt;，&lt;3，3&gt;，&lt;4，1&gt;，&lt;4，4&gt;}；<br>R4={&lt;2，1&gt;，&lt;3，1&gt;，&lt;3，2&gt;，&lt;4，1&gt;，&lt;4，2&gt;，&lt;4，3&gt;}；<br>R5=(&lt;1，1&gt;，&lt;1，2&gt;，&lt;1，3&gt;，&lt;1，4&gt;，&lt;2，2&gt;，&lt;2，3&gt;，&lt;2，4&gt;，&lt;3，3&gt;，&lt;3，4&gt;，&lt;4，4&gt;}；<br>R6={&lt;3，4&gt;}。<br>其中，哪些是自反关系? 哪些是反自反关系?<br>解: 关系R3，R5是自反的，因为它包括所有形如&lt;a，a&gt;的序对。关系R4，R6是反自反的，因为它不包括任何形如&lt;a，a&gt;的序对。而关系R1，R2既不是自反的，也不是反自反的。<br>因为R1中包含&lt;1，1&gt;，&lt;2，2&gt;，&lt;4，4&gt;，但不包含&lt;3，3&gt;；R2中包含&lt;1，1&gt;.但不包含&lt;2，2&gt;，&lt;3，3&gt;，&lt;4，4&gt;。<br>自反性和反自反性可以在关系图和关系矩阵上非常直观地反映出来。</p>
]]></content>
      <categories>
        <category>数学算法</category>
      </categories>
      <tags>
        <tag>数学算法</tag>
      </tags>
  </entry>
  <entry>
    <title>如何设计一个分布式系统</title>
    <url>/2020/08/24/%E8%AE%BE%E8%AE%A1%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/</url>
    <content><![CDATA[<pre><code> ##  分布式系统
 　分布式系统从当初的CORBA 到EJB，Web和SOA，从集群到现在的NoSQL 云计算和大数据Hadoop等分布式系统，横向水平扩展Scala out/in是分布式系统设计的一个特点，可靠性 容错性是两个质量指标。</code></pre>
<h3 id="什么是分布式系统？"><a href="#什么是分布式系统？" class="headerlink" title="　　    什么是分布式系统？"></a>　　    什么是分布式系统？</h3><p>　　一大批服务器组成一个集合，对于用户来说仍然是一个整体连贯系统。</p>
<p>　　A. Tanenbaum定义：分布式网络的计算机中的组件之间协调动作是通过消息进行通讯。</p>
<p>　　G. Coulouris定义：当你知道有一台电脑崩溃，但是你的软件运行从来不会停止。</p>
<p>　　Leslie Lamport定义：分布式系统是这样系统：旨在支持应用程序和服务的开发，可以利用物理架构 由多个自治的处理元素，不共享主内存，但通过网络发送异步消息合作。</p>
<p>　　与分层应用区别：分层的应用程序（例如，3层）是 划分应用程序逻辑，是一种逻辑分层，而不是物理，而分布式系统DS是物理分层，和实际部署有关。</p>
<h3 id="与传统集中式系统相比："><a href="#与传统集中式系统相比：" class="headerlink" title="与传统集中式系统相比："></a>与传统集中式系统相比：</h3><p>　　集中式系统是一种Scale out/in，纵向扩展，要么向上升级服务器到中大型机，要么升级多核，增加CPU核数，集中式纵向扩展适合计算聚合度比较高的数据，而分布式适合计算松散数据，非结构化或半结构化数据。无论采取哪种扩展伸缩方案，需要根据业务数据特点而定。</p>
<p>　　任何分布式系统总是需要完成两个任务：计算和存储。计算和存储分离是分布式系统的重要特征。而通常在集中式或单机系统中，这两者是可能结合在一起，比如通过一个SQL语句实现查询后排序，查询是从存储中获得数据，排序是属于计算，因此这个SQL语句实际是将计算和存储耦合在一起。在应对大数据或大并发的情况下，这种方便的捆绑带来性能问题，而分布式计算和分布式存储虽然带来复杂性，但是也为系统的处理能力打开了上升拓展的空间。<br>###　分布式系统特点：<br>并发性：共享资源，采取ACID或Base原则，见：CAP定理。<br>分布式系统设计遵循CAP定理， CAP是：Consistency(一致性), Availability(可用性), 和 Partition tolerance(分区容错性) 可靠性 简称，CAP定理认为，CAP三种之中，只能同时满足其中两种。</p>
<p>可扩展性Scalable是重要特点，通过扩展能够获得高性能 高吞吐量 低延迟Latency。</p>
<p>可靠性/可用性:故障发现和处理以及恢复 容错处理。在一个正常运作系统中存在一个时间比例的条件。 如果一个用户不能访问系统比例增大，它被认为是不可用。可用性公式：<br>Availability = uptime / (uptime + downtime)<br>容错failover是指一个系统在错误发生的情况下，仍然一切运行正常。表示这个系统是宽容错误的。</p>
<p>消息处理: 具体产品有：RabbitMQ ZeroMQ Netty等等。</p>
<p>异构性： 不同操作系统 硬件 程序语言 开发者，中间件是一种解决方案。</p>
<p>.安全性：授权认证 SSO单点登录 Oauth等等。</p>
<p>定位命令：<br>标识资源 URLs<br>命名服务Naming services<br>定位寻找Lookup<br>主要见SOA中的服务查找。如Zookeeper实现服务查找。</p>
<p>.透明性：<br>访问透明度： 使用相同的操作本地和远程资源<br>位置透明：访问资源无需知道其物理或网络位置<br>并发透明度：多个流程可以同时运行访问使用共享资源，当不能干扰堵塞 它们的处理流程<br>复制透明性： 资源的多个实例可以被用来复制以提高可靠性和性能，但无需由用户编制专门的应用程序来实现。<br>故障透明度：出现软件硬件故障时，使用户和应用方案能继续完成他们的任务不受影响。<br>移动透明度：允许在 系统存在移动的资源和客户。<br>性能透明度：允许系统重新配置以 提高性能负荷变化<br>缩放透明度：在应用程序结构没有变化的情况下能够在规模上扩展或伸缩系统，以提高吞吐量处理能力。　　</p>
<h3 id="分布式系统的挑战"><a href="#分布式系统的挑战" class="headerlink" title="分布式系统的挑战"></a>分布式系统的挑战</h3><p>　　分布式系统是难于理解、设计、构建 和管理的，他们将比单个机器成倍还要多的变量引入到设计中，使应用程序的根源问题更难发现。SLA(服务水平协议)是衡量停机和/或性能下降的标准，大多数现代应用程序有一个期望的弹性SLA水平，通常按”9”的数量增加(如,每月99.9或99.99%可用性)。每个额外的9变得越来越难实现。</p>
<p>　　让事情更加复杂的是，我们越来越常见地看到：分布式系统的故障表现为间歇性错误或性能下降(俗称的限电)。这些失败模式耗费更多时间来诊断。例如，Joyent经营一些分布式系统作为其云计算基础设施的一部分。在这样一个系统中，包括高可用性、分布式的键/值存储，Joyent最近经历了瞬态应用程序超时。对于大多数用户系统运行正常，其反应延迟也是在SLA范围内。然而，有百分之5 - 10的请求超出了一个预定义的程序超时。这样的失败问题并没有重现在开发或测试环境中，他们经常会”消失”几分钟到几小时。排除这个故障的根本是需要大量数据存储的系统分析。</p>
<p>　　这些系统包括：数据存储API(node . js)，RDBMS(关系数据库管理系统)和由系统内部使用(PostgreSQL)以及操作系统和终端用户应用程序依赖于的键/值系统。最终，导致过度的根本问题是在应用程序语义锁定，但确定之前需要相当大的数据收集和相关性工作，包括工程师耗费大量工作时间以及学习不同领域的专业知识。</p>
<p>　　分布式系统由两个物理因素的限制：</p>
<p>节点的数量（能够增加所需的存储和计算能力）<br>节点之间的距离（信息的传送距离，最好以光速）<br>　　这两个约束导致下面值得挑战的情况发生：</p>
<p>独立节点随着数目的增加发生故障的概率增加（减少可用的和管理成本增加）<br>独立节点随着数目增加可能会增加节点之间的通信的消耗（随着规模的增大性能降低）<br>地理距离的增加提高遥远的节点之间的通信延迟（减少某些操作的性能）</p>
<h3 id="如何架构分布式系统"><a href="#如何架构分布式系统" class="headerlink" title="如何架构分布式系统"></a>如何架构分布式系统</h3><p>　　适用于分布式系统架构的最常见的一个术语是SOA(面向服务架构)。SOA可以避免不愉快的CORBA(公共对象请求代理体系结构)，通过WS - *标准，一套松散耦合的Web服务完成独立的小功能，并且彼此独立，他们是一个有弹性的分布式系统的基础。对比上一代，服务是新流程，他们是正确的抽象层次系统中的离散功能。</p>
<p>　　构建面向服务架构的第一步是确定每个函数功能如何构成整体业务目标，将这些业务映射到离散的服务，且具有独立的断层边界、扩展性和数据负载量。确定为每个服务时，您必须考虑下列事项：</p>
<p>地理. 系统是全球还是地区单独运行？<br>数据隔离. 这个系统提供一个单个或多租户模型？<br>SLAs. 可用性 延迟 吞吐量 一致性和冗余性都必须定义。<br>安全. IAAA (身份identity, 验证authentication, 授权authorization, 和 审核audit), 数据的保密性和隐私性都必须考虑<br>可用性跟踪. 了解系统的使用是每天系统的日常运作，如容量规划。也可能用于执行计费系统的使用和/或治理(配额/速度限制)。<br>部署和配置管理. 系统是如何部署更新?</p>
<p>分布式系统的模型抽象<br>系统模型（异步/同步）<br>失效模型（崩溃故障，分区）<br>一致性模型（强，最终）<br>　　通常，我们最熟悉的模式（例如，一个分布式系统上实现共享内存抽象）是太昂贵了。一个分布式系统越弱势越能保证其中元素有更大的行动自由，从而焕发潜在的更大的性能- 但它也可能导致很难管理。这就需要我们有极大智慧，不能以牺牲性能换来管理的方便性。因此，试图将分布式系统看成一个统一的单一系统的思维会阻碍分布式系统的扩展。</p>
<p>　　分布式系统遵循CAP定律，在高一致性 高可用性和分区容错性之间三选二<br>CA (consistency高一致性 + availability高可用性). 使用2pc 两阶段事务提交来保证。其缺点无法实现分区容错性，一旦某个操作失败，整个系统就出错，无法容忍(水至清则无鱼)。<br>CP (consistency高一致性 + partition tolerance分区容错性). 使用Paxos来保证，可用性降低。<br>AP (availability高可用性 + partition tolerance分区容错性). 使用Gossip等实现最终一致性，如Dynamo.<br>　###  如何正确理解CAP理论？</p>
<h3 id="分布式系统的设计技巧：分区和复制"><a href="#分布式系统的设计技巧：分区和复制" class="headerlink" title="分布式系统的设计技巧：分区和复制"></a>分布式系统的设计技巧：分区和复制</h3><p>　　对于一个数据集有两种设计方式：</p>
<p>分区：它可以被分割在多个节点，以允许更多的并行处理。有更好的性能，但是容错能力低。<br>复制：它也可以被复制或缓存在不同的节点上，以减少在客户端和服务器之间的距离，更强的容错能力，但是复制消耗性能。关键是复制数据之间的一致性。弱一致性提供更低的延迟和更高的可用性。<br>分布式系统的设计技巧：时钟和顺序<br>　　分布式系统针对计算和存储的策略是不同的，对于数据的存储主要是分区和复制，而对于计算主要是保证事件的顺序，因为分布式计算任务是由事件驱动的，比如Storm等等。那么事件的顺序代表了业务逻辑的顺序，事件有时是树形嵌套事件，可靠性就是必须保证一个树形集合所有事件都得到网站执行是一个事务原子的。参考流式大数据处理模式。</p>
]]></content>
      <categories>
        <category>分布式系统</category>
      </categories>
      <tags>
        <tag>分布式系统</tag>
      </tags>
  </entry>
  <entry>
    <title>领域驱动设计</title>
    <url>/2019/11/21/%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1/</url>
    <content><![CDATA[<h2 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h2><p>第一步，统一语言：</p>
<p>开发人员应该使用基于模型的语言来描述系统中的工件、任务和功能。</p>
<p>领域专家应该抵制不合适或无法充分表达领域理解的术语或结构，开发人员应该密切关注那些将会妨碍设计的有歧义和不一致的地方。</p>
<p>有些人天生是视觉动物，图可以帮助人们掌握某些类型的信息。</p>
<h2 id="分层模式：-Layered-Architecture"><a href="#分层模式：-Layered-Architecture" class="headerlink" title="分层模式： Layered Architecture"></a>分层模式： Layered Architecture</h2><p> <img src="https://lixinx11.github.io/medias/bigdata/6.png" alt="图1"><br> <img src="https://lixinx11.github.io/medias/bigdata/7.png" alt="图2"><br>分层模式</p>
<p>分层模式例子</p>
<p>如果一个经验并不丰富的项目团队要完成一个简单的项目，却决定使用MODELDRIVENDESIGN以及LAYEREDARCHITECTURE，那么这个项目组将会经历一个艰难的学习过程。团队成员不得不去掌握复杂的新技术，艰难地学习对象建模。</p>
<p>entity模式</p>
<p>领域对象生命周期<br> <img src="https://lixinx11.github.io/medias/bigdata/8.png" alt="图3"><br> <img src="https://lixinx11.github.io/medias/bigdata/9.png" alt="图4"></p>
]]></content>
      <categories>
        <category>领域驱动设计</category>
      </categories>
      <tags>
        <tag>领域驱动设计：软件核心复杂性应对之道</tag>
      </tags>
  </entry>
  <entry>
    <title>高并发设计</title>
    <url>/2017/03/12/%E9%AB%98%E5%B9%B6%E5%8F%91%E8%AE%BE%E8%AE%A1/</url>
    <content><![CDATA[<h2 id="系统性能两大核心点"><a href="#系统性能两大核心点" class="headerlink" title="系统性能两大核心点"></a>系统性能两大核心点</h2><p>吞吐量（Throughput）<br>响应延迟（Response Delay）<br>优化目标<br>缩短响应时间<br>提供并发数<br>让系统处于合理状态<br>Number of Concurrent Users<br>上图是高并发软件性能模型。图中三条曲线，分别表示：</p>
<p>资源的利用情况（Utilization，包括硬件资源和软件资源）<br>吞吐量（Throughput，这里是指每秒事务数）<br>响应时间（Response Time）。<br>坐标轴的横轴从左到右表现了并发用户数（Number of Concurrent Users）的不断增长。</p>
<p>随着并发用户数的增长，资源占用率和吞吐量会相应的增长，但是响应时间的变化不大；不过当并发用户数增长到一定程度后，资源占用达到饱和，吞吐量增长明显放缓甚至停止增长，而响应时间却进一步延长。如果并发用户数继续增长，你会发现软硬件资源占用继续维持在饱和状态，但是吞吐量开始下降，响应时间明显的超出了用户可接受的范围，并且最终导致用户放弃了这次请求甚至离开。</p>
<p>根据这种性能表现，图中划分了三个区域，分别是</p>
<p>Light Load（较轻的压力）<br>Heavy Load（较重的压力）<br>Buckle Zone（用户无法忍受并放弃请求）。<br>在Light Load和Heavy Load两个区域交界处的并发用户数，我们称为“最佳并发用户数（The Optimum Number of Concurrent Users）”，而Heavy Load和Buckle Zone两个区域交界处的并发用户数则称为“最大并发用户数（The Maximum Number of Concurrent Users）”。 当系统的负载等于最佳并发用户数时，系统的整体效率最高，没有资源被浪费，用户也不需要等待；当系统负载处于最佳并发用户数和最大并发用户数之间时，系统可以继续工作，但是用户的等待时间延长，满意度开始降低，并且如果负载一直持续，将最终会导致有些用户无法忍受而放弃；而当系统负载大于最大并发用户数时，将注定会导致某些用户无法忍受超长的响应时间而放弃。</p>
<p>所以我们性能优化的目标就是让系统保持在Heavy Load（较重的压力） 区域。</p>
<h2 id="优化手段"><a href="#优化手段" class="headerlink" title="优化手段"></a>优化手段</h2><h3 id="1-空间换时间"><a href="#1-空间换时间" class="headerlink" title="1. 空间换时间"></a>1. 空间换时间</h3><p>系统时间是瓶颈。</p>
<p>这种情况是CPU处理时间很当，但是空间费用我们能接受，所以我们解决的问题的方法就是用空间来换时间。</p>
<p>例如：缓存复用计算结果，降低时间开销，因为CPU时间较内存容量更昂贵</p>
<h3 id="2-时间换空间"><a href="#2-时间换空间" class="headerlink" title="2. 时间换空间"></a>2. 时间换空间</h3><p>数据大小是瓶颈。</p>
<p>这种情况是空间占用很大，处理时间能接受，所以我们解决问题的方法就是用时间换空间。</p>
<p>例如1：网络传输是瓶颈，使用系统时间换取传输的空间，使用HTTP的gzip压缩算法。解压缩的时候会消耗CPU处理时间。<br>例如2：APP的请求分类接口，使用版本号判断哪些数据更新，只下载更新的数据。比如一些商品分类类目、城市列表等，一般很少会更新，可以缓存到本地，不能每次登录的时候都去拉取，所以针对这些数据我们可以做一个版本号，如果发现更新了就去拉取数据更新。再比如一些IM社交软件的用户列表，每次登录的时候都去拉一次，其实大家想想每次录的时候都是拉一次挺消耗网络流量的。而这个时候往往你的QQ好友列表变化并不是特别频繁，这个时候怎么办呢？我们会在这个QQ好友的列表有一个时间戳作为版本号，这个版本号在server端存一份，client端存一份，在每次登录的时候会先去判断一下这个版本号是否一致，如果不一致再做更新。</p>
<h3 id="3-找到系统瓶颈"><a href="#3-找到系统瓶颈" class="headerlink" title="3. 找到系统瓶颈"></a>3. 找到系统瓶颈</h3><p>分析系统业务流程，找到关键路径并分解优化。</p>
<p>一个服务集群4W的QPS，调用量前5的接口贡献了3.5W的QPS<br>对关键路径的代码优化收益最大，当然系统剩下的部分收益也不能忽视，比如剩下5k QPS接口若性能有问题也可能把整体服务性能拖垮。<br>所以我们需要抓主要矛盾。大概解决思路总结如下：</p>
<p>整个请求服务调了多少RPC接口；<br>载入多少数据；<br>使用什么算法；<br>非核心流程能否异步化；<br>没有数据依赖的逻辑能否并行执行<br>优化层次<br>从整体到细节，从全局角度到局部视角</p>
<h4 id="1-架构设计层次"><a href="#1-架构设计层次" class="headerlink" title="1. 架构设计层次"></a>1. 架构设计层次</h4><p>关注系统控制、数据流程<br>如何拆分系统，如何使各部分系统整体负载更加均衡，充分发挥硬件设施性能优势，减少系统内部开销等。<br>架构设计层次实现手段：</p>
<p>分布式系统微服务化<br>分库分表，读写分离，数据分片<br>无状态化设计，动态水平弹性扩展<br>调用连路梳理，热点数据尽量靠近用户<br>分布式Cache、多级多类型缓存<br>容量规划<br>提前拒绝，保证柔性可用</p>
<h4 id="2-算法逻辑层次"><a href="#2-算法逻辑层次" class="headerlink" title="2. 算法逻辑层次"></a>2. 算法逻辑层次</h4><p>算法选择是否高效，是否使时间优先级的还是空间优先级，算法逻辑优化，空间时间优化任务并行处理，使用无锁数据结构等。<br>空间换时间<br>ThreadLocal<br>时间换空间<br>采用压缩算法压缩数据，更复杂的逻辑减少数据传输</p>
<h2 id="2-1-算法逻辑优化层次实现细节"><a href="#2-1-算法逻辑优化层次实现细节" class="headerlink" title="2.1 算法逻辑优化层次实现细节"></a>2.1 算法逻辑优化层次实现细节</h2><p>用更高效的算法替换现有算法，而不改变其接口</p>
<p>增量式算法、复用之前的计算结果，比如一个报表服务，要从全量数据中生成报表数据量很大，但是每次增量的数据较少，则可以考虑只计算增量数据和之前计算结果合并。这样处理的数据量就小很多。</p>
<p>并发和锁的优化，读多写少的业务场景下，基于CAS的LockFree比Mutex性能更好</p>
<p>当系统时间是瓶颈，采取空间换时间逻辑算法，分配更多空间节省系统时间</p>
<p>缓存复用计算结果，降低时间开销，CPU时间较内存容量更加昂贵</p>
<p>当系统空间容量是瓶颈的时候，采用时间换空间算法策略</p>
<p>网络传输是瓶颈，使用系统时间换取空间的压缩，HTTP的gzip的压缩算法</p>
<p>APP的请求分类接口，使用版本号判断那些数据更新，只下载更新的数据，使用更多的代码逻辑处理更细颗粒度的数据</p>
<p>并行执行，比如一段逻辑调用了多个RPC接口，而这些接口之间并没有数据依赖，则可以考虑并行调用，降低响应时间。</p>
<p>异步执行，分析业务流程中的主次流程，把次要流程拆分出来异步执行，更进一步可以拆分到单独的模块去执行，比如使用消息队列，彻底和核心流程解耦，提高核心流程的稳定性以及降低响应是时间。</p>
<ol start="3">
<li>代码优化层次<br>关注代码细节优化，代码实现是否合理，是否创建了过多的对象，循环遍历是否高效，cache使用的是否合理，是否重用计算结果等。<h2 id="3-1-代码优化层次实现细节"><a href="#3-1-代码优化层次实现细节" class="headerlink" title="3.1 代码优化层次实现细节"></a>3.1 代码优化层次实现细节</h2>循环遍历是否合理高效，不要在循环里调用RPC接口、查询分布式缓存、执行SQL等<br>先调批量接口组装好数据、再循环处理<br>代码逻辑避免生成过多对象和无效对象<br>输出log时候的log级别判断，避免new无效对象<br>ArrayList、HashMap初始容量设置是否合理<br>扩容代价<br>对数据对象是否合理重用，比如通过RPC查到的数据能复用则必须复用<br>根据数据访问特性选择合适数据结构，比如读多写少，考虑CopyOnWriteArrayList(写时Copy副本)<br>拼接字符串的时候是使用String相加还是使用StringBuilder进行append(在StringBuilder的容量预分配的情况下StringBuilder的性能比String相加性能高15倍左右)<br>是否正确初始化数据。有些全局共享的数据，饿汉式模式，在用户访问之前先初始化好<h2 id="3-2-数据库代码优化层次实现细节"><a href="#3-2-数据库代码优化层次实现细节" class="headerlink" title="3.2 数据库代码优化层次实现细节"></a>3.2 数据库代码优化层次实现细节</h2>数据库建表语句使用尽量小的数据结构<br>表示状态的字段，如果状态值在255以内使用unsigned tinyint，IP使用int而非varchar<br>使用enum的场景使用tinyint替代，enum扩展需要该表<br>避免使用select * 查询语句，只查询需要的字段，避免浪费数据IO、内存、CPU、网络传输<br>分析查询场景经理合适的索引，分析字段的可选择性，索引长度，对长的varchar使用前缀索引<br>字段尽量为Not NULL类型，MySQL手册说吗允许NULL的字段需要额外的存储空间去处理NULL ，并且很难查询优化<br>以上优化的目的为了降低服务器CPU使用率、IO流量、内存占用、网络消耗、降低响应时间</li>
</ol>
<p>在做查询时，可以通过代码逻辑，加一下查询条件，利用索引来提升查询速度。</p>
<h2 id="3-3-局部优化层次实现细节"><a href="#3-3-局部优化层次实现细节" class="headerlink" title="3.3 局部优化层次实现细节"></a>3.3 局部优化层次实现细节</h2><p>以下两段代码哪个执行速度快？</p>
<p>long[][] a = new long[10000][10000];<br>    for(int i=0;i&lt;a.length;i++){<br>        for(int j =0;j&lt;a[i].length;j++){<br>            a[i][j]=j;<br>        }<br>    }<br>复制代码<br>long[][] a = new long[10000][10000];<br>    for(int i=0;i&lt;a.length;i++){<br>        for(int j =0;j&lt;a[i].length;j++){<br>            a[j][j]=j;<br>        }<br>    }<br>复制代码<br>这两段代码，唯一的区别在于填充方式，第一种方式是按行填充，第二种方式是按列进行填充。显然是第一种方式更快一些。 虽然是二维数组，但是在内存堆列中还一维数组进行存储的。大家可以在试一下，第一种运行速度比第二种方式快20倍。</p>
<p>那深层次原因是什么呢？</p>
<p>我们知道在计算机体系中，除了有内存来做缓存，在CPU层面也有cache结构。而越靠近CPU读取速度越快。如下图：</p>
<p>缓存的结构大概时这样的，从1级到3级速度越来越慢，最后通过总线与内存连接。 本质上内存是一个大的一维数组，二维数组在内存中按行排列，现存放a[0]行，再存放a[1]行，第一种遍历方式，是行遍历，先遍历完一行再遍历第二行，符合局部性原理，Cache Hit(缓存命中率高)，第二行遍历方式，是列遍历，遍历完第一列遍历第二列，由于下一列和上一列的数组元素在内存中并不是连续的，很可能导致Cache Miss（缓存未命中），CPU需要去内存载入数据，速度较CPU L1 Cache的速度降低了很多（主存100ns,L1cache 0.5ns）</p>
<p>扩大到一般场景，业务系统使用缓存降低响应时间提高性能，必须提高缓存命中率。很聚焦的高频访问，时效性要求不高很适合缓存提升性能，很聚焦的高频访问业务如banner，广告位，时效性要求不是特别高，比如更新了可以不用实时体现，很适合使用缓存提升性能。</p>
<p>如果对数据实时性要求很高，比如严格的时效性，需要慎重考虑更新缓存带来一致性问题。</p>
<p>时效性和缓存的冲突，比如商品服务对商品进行了缓存，由于更新缓存和更新商品不是同一个事务，则对数据时效性要求高的如交易，就只能直接从数据库查商品信息。</p>
]]></content>
      <categories>
        <category>高并发</category>
      </categories>
      <tags>
        <tag>java高并发</tag>
      </tags>
  </entry>
  <entry>
    <title>java多线程</title>
    <url>/2015/04/12/java%E5%A4%9A%E7%BA%BF%E7%A8%8B/</url>
    <content><![CDATA[<h2 id="1-创建线程"><a href="#1-创建线程" class="headerlink" title="1.创建线程"></a>1.创建线程</h2><p>在Java中创建线程有两种方法：使用Thread类和使用Runnable接口。在使用Runnable接口时需要建立一个Thread实例。因此，无论是通过Thread类还是Runnable接口建立线程，都必须建立Thread类或它的子类的实例。Thread构造函数：</p>
<p>public Thread( );<br>public Thread(Runnable target);<br>public Thread(String name);<br>public Thread(Runnable target, String name);<br>public Thread(ThreadGroup group, Runnable target);<br>public Thread(ThreadGroup group, String name);<br>public Thread(ThreadGroup group, Runnable target, String name);<br>public Thread(ThreadGroup group, Runnable target, String name, long stackSize);<br> ###方法一：继承Thread类覆盖run方法</p>
<p>public class ThreadDemo1 {<br>     public static void main(String[] args){<br>         Demo d = new Demo();<br>         d.start();<br>         for(int i=0;i&lt;60;i++){<br>             System.out.println(Thread.currentThread().getName()+i);<br>         }</p>
<pre><code> &#125;</code></pre>
<p> }<br> class Demo extends Thread{<br>     public void run(){<br>         for(int i=0;i&lt;60;i++){<br>             System.out.println(Thread.currentThread().getName()+i);<br>         }<br>     }<br> }</p>
<h3 id="方法二："><a href="#方法二：" class="headerlink" title="方法二："></a>方法二：</h3><p>public class ThreadDemo2 {<br>    public static void main(String[] args){<br>        Demo2 d =new Demo2();<br>        Thread t = new Thread(d);<br>        t.start();<br>        for(int x=0;x&lt;60;x++){<br>            System.out.println(Thread.currentThread().getName()+x);<br>        }<br>    }<br>}<br>class Demo2 implements Runnable{<br>    public void run(){<br>        for(int x=0;x&lt;60;x++){<br>            System.out.println(Thread.currentThread().getName()+x);<br>        }<br>    }<br>}</p>
<h2 id="2-线程的生命周期"><a href="#2-线程的生命周期" class="headerlink" title="2.线程的生命周期"></a>2.线程的生命周期</h2><p>与人有生老病死一样，线程也同样要经历开始（等待）、运行、挂起和停止四种不同的状态。这四种状态都可以通过Thread类中的方法进行控制。下面给出了Thread类中和这四种状态相关的方法。</p>
<p>// 开始线程<br>publicvoid start( );<br>publicvoid run( );<br>// 挂起和唤醒线程<br>publicvoid resume( ); // 不建议使用<br>publicvoid suspend( ); // 不建议使用<br>publicstaticvoid sleep(long millis);<br>publicstaticvoid sleep(long millis, int nanos);<br>// 终止线程<br>publicvoid stop( ); // 不建议使用<br>publicvoid interrupt( );<br>// 得到线程状态<br>publicboolean isAlive( );<br>publicboolean isInterrupted( );<br>publicstaticboolean interrupted( );<br>// join方法<br>publicvoid join( ) throws InterruptedException;<br>线程在建立后并不马上执行run方法中的代码，而是处于等待状态。线程处于等待状态时，可以通过Thread类的方法来设置线程不各种属性，如线程的优先级（setPriority）、线程名(setName)和线程的类型（setDaemon）等。</p>
<p>当调用start方法后，线程开始执行run方法中的代码。线程进入运行状态。可以通过Thread类的isAlive方法来判断线程是否处于运行状态。当线程处于运行状态时，isAlive返回true，当isAlive返回false时，可能线程处于等待状态，也可能处于停止状态。下面的代码演示了线程的创建、运行和停止三个状态之间的切换，并输出了相应的isAlive返回值。</p>
<p>一但线程开始执行run方法，就会一直到这个run方法执行完成这个线程才退出。但在线程执行的过程中，可以通过两个方法使线程暂时停止执行。这两个方法是suspend和sleep。在使用suspend挂起线程后，可以通过resume方法唤醒线程。而使用sleep使线程休眠后，只能在设定的时间后使线程处于就绪状态（在线程休眠结束后，线程不一定会马上执行，只是进入了就绪状态，等待着系统进行调度）。</p>
<p>在使用sleep方法时有两点需要注意：</p>
<h3 id="1-sleep方法有两个重载形式，其中一个重载形式不仅可以设毫秒，而且还可以设纳秒-1-000-000纳秒等于1毫秒-。但大多数操作系统平台上的Java虚拟机都无法精确到纳秒，因此，如果对sleep设置了纳秒，Java虚拟机将取最接近这个值的毫秒。"><a href="#1-sleep方法有两个重载形式，其中一个重载形式不仅可以设毫秒，而且还可以设纳秒-1-000-000纳秒等于1毫秒-。但大多数操作系统平台上的Java虚拟机都无法精确到纳秒，因此，如果对sleep设置了纳秒，Java虚拟机将取最接近这个值的毫秒。" class="headerlink" title="1. sleep方法有两个重载形式，其中一个重载形式不仅可以设毫秒，而且还可以设纳秒(1,000,000纳秒等于1毫秒)。但大多数操作系统平台上的Java虚拟机都无法精确到纳秒，因此，如果对sleep设置了纳秒，Java虚拟机将取最接近这个值的毫秒。"></a>1. sleep方法有两个重载形式，其中一个重载形式不仅可以设毫秒，而且还可以设纳秒(1,000,000纳秒等于1毫秒)。但大多数操作系统平台上的Java虚拟机都无法精确到纳秒，因此，如果对sleep设置了纳秒，Java虚拟机将取最接近这个值的毫秒。</h3><h3 id="2-在使用sleep方法时必须使用throws或try-…-catch-…-。因为run方法无法使用throws，所以只能使用try-…-catch-…-。当在线程休眠的过程中，使用interrupt方法中断线程时sleep会抛出一个InterruptedException异常。sleep方法的定义如下："><a href="#2-在使用sleep方法时必须使用throws或try-…-catch-…-。因为run方法无法使用throws，所以只能使用try-…-catch-…-。当在线程休眠的过程中，使用interrupt方法中断线程时sleep会抛出一个InterruptedException异常。sleep方法的定义如下：" class="headerlink" title="2. 在使用sleep方法时必须使用throws或try{…}catch{…}。因为run方法无法使用throws，所以只能使用try{…}catch{…}。当在线程休眠的过程中，使用interrupt方法中断线程时sleep会抛出一个InterruptedException异常。sleep方法的定义如下："></a>2. 在使用sleep方法时必须使用throws或try{…}catch{…}。因为run方法无法使用throws，所以只能使用try{…}catch{…}。当在线程休眠的过程中，使用interrupt方法中断线程时sleep会抛出一个InterruptedException异常。sleep方法的定义如下：</h3><p>publicstaticvoid sleep(long millis) throws InterruptedException<br>publicstaticvoid sleep(long millis, int nanos) throws InterruptedException<br>有三种方法可以使终止线程。</p>
<ol>
<li><p>使用退出标志，使线程正常退出，也就是当run方法完成后线程终止。</p>
</li>
<li><p>使用stop方法强行终止线程（这个方法不推荐使用，因为stop和suspend、resume一样，也可能发生不可预料的结果）。</p>
</li>
<li><p>使用interrupt方法中断线程。</p>
</li>
<li><p>使用退出标志终止线程</p>
</li>
</ol>
<p>当run方法执行完后，线程就会退出。但有时run方法是永远不会结束的。如在服务端程序中使用线程进行监听客户端请求，或是其他的需要循环处理的任务。在这种情况下，一般是将这些任务放在一个循环中，如while循环。如果想让循环永远运行下去，可以使用while(true){…}来处理。但要想使while循环在某一特定条件下退出，最直接的方法就是设一个boolean类型的标志，并通过设置这个标志为true或false来控制while循环是否退出。下面给出了一个利用退出标志终止线程的例子。</p>
<p>join方法的功能就是使异步执行的线程变成同步执行。也就是说，当调用线程实例的start方法后，这个方法会立即返回，如果在调用start方法后后需要使用一个由这个线程计算得到的值，就必须使用join方法。如果不使用join方法，就不能保证当执行到start方法后面的某条语句时，这个线程一定会执行完。而使用join方法后，直到这个线程退出，程序才会往下执行。下面的代码演示了join的用法。</p>
<h2 id="3-多线程安全问题"><a href="#3-多线程安全问题" class="headerlink" title="3.多线程安全问题"></a>3.多线程安全问题</h2><p>问题原因：当多条语句在操作同一个线程共享数据时，一个线程对多条语句只执行了一部分，还没执行完，另一个线程参与进来执行，导致共享数据的错误。</p>
<p>解决办法：对多条操作共享数据的语句，只能让一个线程都执行完，在执行过程中，其他线程不执行。</p>
<h4 id="同步代码块："><a href="#同步代码块：" class="headerlink" title="同步代码块："></a>同步代码块：</h4><p>public class ThreadDemo3 {<br>    public static void main(String[] args){<br>        Ticket t =new Ticket();<br>        Thread t1 = new Thread(t,”窗口一”);<br>        Thread t2 = new Thread(t,”窗口二”);<br>        Thread t3 = new Thread(t,”窗口三”);<br>        Thread t4 = new Thread(t,”窗口四”);<br>        t1.start();<br>        t2.start();<br>        t3.start();<br>        t4.start();<br>    }<br>}<br>class Ticket implements Runnable{<br>    private int ticket =400;<br>    public void run(){<br>        while(true){<br>            synchronized (new Object()) {<br>                try {<br>                    Thread.sleep(1);<br>                } catch (InterruptedException e) {<br>                    // TODO Auto-generated catch block<br>                    e.printStackTrace();<br>                }<br>                if(ticket&lt;=0)<br>                    break;<br>                System.out.println(Thread.currentThread().getName()+”—卖出”+ticket–);<br>            }<br>        }<br>    }<br>}<br>同步函数</p>
<p>public class ThreadDemo3 {<br>    public static void main(String[] args){<br>        Ticket t =new Ticket();<br>        Thread t1 = new Thread(t,”窗口一”);<br>        Thread t2 = new Thread(t,”窗口二”);<br>        Thread t3 = new Thread(t,”窗口三”);<br>        Thread t4 = new Thread(t,”窗口四”);<br>        t1.start();<br>        t2.start();<br>        t3.start();<br>        t4.start();<br>    }<br>}<br>class Ticket implements Runnable{<br>    private int ticket = 4000;<br>    public synchronized void  saleTicket(){<br>        if(ticket&gt;0)<br>            System.out.println(Thread.currentThread().getName()+”卖出了”+ticket–);</p>
<pre><code>&#125;
public void run()&#123;
    while(true)&#123;
        saleTicket();
    &#125;
&#125;</code></pre>
<p>}<br>同步函数锁是this 静态同步函数锁是class</p>
<h4 id="线程间的通信"><a href="#线程间的通信" class="headerlink" title="线程间的通信"></a>线程间的通信</h4><p>public class ThreadDemo3 {<br>    public static void main(String[] args){<br>        class Person{<br>            public String name;<br>            private String gender;<br>            public void set(String name,String gender){<br>                this.name =name;<br>                this.gender =gender;<br>            }<br>            public void get(){<br>                System.out.println(this.name+”….”+this.gender);<br>            }<br>        }<br>        final Person p =new Person();<br>        new Thread(new Runnable(){<br>            public void run(){<br>                int x=0;<br>                while(true){<br>                    if(x==0){<br>                        p.set(“张三”, “男”);<br>                    }else{<br>                        p.set(“lili”, “nv”);<br>                    }<br>                    x=(x+1)%2;<br>                }<br>            }<br>        }).start();<br>        new Thread(new Runnable(){<br>            public void run(){<br>                while(true){<br>                    p.get();<br>                }<br>            }<br>        }).start();<br>    }<br>}<br>/*<br>张三….男<br>张三….男<br>lili….nv<br>lili….男<br>张三….nv<br>lili….男<br>*/<br>修改上面代码</p>
<p>public class ThreadDemo3 {<br>     public static void main(String[] args){<br>         class Person{<br>             public String name;<br>             private String gender;<br>             public void set(String name,String gender){<br>                 this.name =name;<br>                 this.gender =gender;<br>             }<br>             public void get(){<br>                 System.out.println(this.name+”….”+this.gender);<br>             }<br>         }<br>         final Person p =new Person();<br>         new Thread(new Runnable(){<br>             public void run(){<br>                 int x=0;<br>                 while(true){<br>                     synchronized (p) {<br>                         if(x==0){<br>                             p.set(“张三”, “男”);<br>                         }else{<br>                             p.set(“lili”, “nv”);<br>                         }<br>                         x=(x+1)%2;<br>                     }</p>
<pre><code>             &#125;
         &#125;
     &#125;).start();
     new Thread(new Runnable()&#123;
         public void run()&#123;
             while(true)&#123;
                 synchronized (p) &#123;
                     p.get();
                 &#125;
             &#125;
         &#125;
     &#125;).start();
 &#125;</code></pre>
<p> }<br> /*<br> lili….nv<br> lili….nv<br> lili….nv<br> lili….nv<br> lili….nv<br> lili….nv<br> 张三….男<br> 张三….男<br> 张三….男<br> 张三….男<br> */</p>
<h4 id="等待唤醒机制"><a href="#等待唤醒机制" class="headerlink" title="等待唤醒机制"></a>等待唤醒机制</h4><p>/*<br> *线程等待唤醒机制<br> *等待和唤醒必须是同一把锁<br> */<br>public class ThreadDemo3 {<br>    private static boolean flags =false;<br>    public static void main(String[] args){<br>        class Person{<br>            public String name;<br>            private String gender;<br>            public void set(String name,String gender){<br>                this.name =name;<br>                this.gender =gender;<br>            }<br>            public void get(){<br>                System.out.println(this.name+”….”+this.gender);<br>            }<br>        }<br>        final Person p =new Person();<br>        new Thread(new Runnable(){<br>            public void run(){<br>                int x=0;<br>                while(true){<br>                    synchronized (p) {<br>                        if(flags)<br>                            try {<br>                                p.wait();<br>                            } catch (InterruptedException e) {<br>                                // TODO Auto-generated catch block<br>                                e.printStackTrace();<br>                            };<br>                        if(x==0){<br>                            p.set(“张三”, “男”);<br>                        }else{<br>                            p.set(“lili”, “nv”);<br>                        }<br>                        x=(x+1)%2;<br>                        flags =true;<br>                        p.notifyAll();<br>                    }<br>                }<br>            }<br>        }).start();<br>        new Thread(new Runnable(){<br>            public void run(){<br>                while(true){<br>                    synchronized (p) {<br>                        if(!flags)<br>                            try {<br>                                p.wait();<br>                            } catch (InterruptedException e) {<br>                                // TODO Auto-generated catch block<br>                                e.printStackTrace();<br>                            };<br>                        p.get();<br>                        flags =false;<br>                        p.notifyAll();<br>                        }<br>                }<br>            }<br>        }).start();<br>    }<br>}</p>
<h4 id="生产消费机制一"><a href="#生产消费机制一" class="headerlink" title="生产消费机制一"></a>生产消费机制一</h4><p>public class ThreadDemo4 {<br>    private static boolean flags =false;<br>    public static void main(String[] args){<br>        class Goods{<br>            private String name;<br>            private int num;<br>            public synchronized void produce(String name){<br>                if(flags)<br>                    try {<br>                        wait();<br>                    } catch (InterruptedException e) {<br>                        // TODO Auto-generated catch block<br>                        e.printStackTrace();<br>                    }<br>                this.name =name+”编号：”+num++;<br>                System.out.println(“生产了….”+this.name);<br>                flags =true;<br>                notifyAll();<br>            }<br>            public synchronized void consume(){<br>                if(!flags)<br>                    try {<br>                        wait();<br>                    } catch (InterruptedException e) {<br>                        // TODO Auto-generated catch block<br>                        e.printStackTrace();<br>                    }<br>                System.out.println(“消费了******”+name);<br>                flags =false;<br>                notifyAll();<br>            }</p>
<pre><code>    &#125;
    final Goods g =new Goods();
    new Thread(new Runnable()&#123;
        public void run()&#123;
            while(true)&#123;
                g.produce(&quot;商品&quot;);
            &#125;
        &#125;
    &#125;).start();
    new Thread(new Runnable()&#123;
        public void run()&#123;
            while(true)&#123;
                g.consume();
            &#125;
        &#125;
    &#125;).start();
&#125;</code></pre>
<p>}</p>
<h4 id="生产消费机制2"><a href="#生产消费机制2" class="headerlink" title="生产消费机制2"></a>生产消费机制2</h4><p>public class ThreadDemo4 {<br>    private static boolean flags =false;<br>    public static void main(String[] args){<br>        class Goods{<br>            private String name;<br>            private int num;<br>            public synchronized void produce(String name){<br>                while(flags)<br>                    try {<br>                        wait();<br>                    } catch (InterruptedException e) {<br>                        // TODO Auto-generated catch block<br>                        e.printStackTrace();<br>                    }<br>                this.name =name+”编号：”+num++;<br>                System.out.println(Thread.currentThread().getName()+”生产了….”+this.name);<br>                flags =true;<br>                notifyAll();<br>            }<br>            public synchronized void consume(){<br>                while(!flags)<br>                    try {<br>                        wait();<br>                    } catch (InterruptedException e) {<br>                        // TODO Auto-generated catch block<br>                        e.printStackTrace();<br>                    }<br>                System.out.println(Thread.currentThread().getName()+”消费了******”+name);<br>                flags =false;<br>                notifyAll();<br>            }</p>
<pre><code>    &#125;
    final Goods g =new Goods();
    new Thread(new Runnable()&#123;
        public void run()&#123;
            while(true)&#123;
                g.produce(&quot;商品&quot;);
            &#125;
        &#125;
    &#125;,&quot;生产者一号&quot;).start();
    new Thread(new Runnable()&#123;
        public void run()&#123;
            while(true)&#123;
                g.produce(&quot;商品&quot;);
            &#125;
        &#125;
    &#125;,&quot;生产者二号&quot;).start();
    new Thread(new Runnable()&#123;
        public void run()&#123;
            while(true)&#123;
                g.consume();
            &#125;
        &#125;
    &#125;,&quot;消费者一号&quot;).start();
    new Thread(new Runnable()&#123;
        public void run()&#123;
            while(true)&#123;
                g.consume();
            &#125;
        &#125;
    &#125;,&quot;消费者二号&quot;).start();
&#125;</code></pre>
<p>}<br>/*<br>消费者二号消费了**<strong><strong>商品编号：48049<br>生产者一号生产了….商品编号：48050<br>消费者一号消费了**</strong></strong>商品编号：48050<br>生产者一号生产了….商品编号：48051<br>消费者二号消费了**<strong><strong>商品编号：48051<br>生产者二号生产了….商品编号：48052<br>消费者二号消费了**</strong></strong>商品编号：48052<br>生产者一号生产了….商品编号：48053<br>消费者一号消费了**<strong><strong>商品编号：48053<br>生产者一号生产了….商品编号：48054<br>消费者二号消费了**</strong></strong>商品编号：48054<br>生产者二号生产了….商品编号：48055<br>消费者二号消费了******商品编号：48055<br>*/</p>
]]></content>
      <categories>
        <category>java多线程</category>
      </categories>
      <tags>
        <tag>java多线程</tag>
      </tags>
  </entry>
  <entry>
    <title>领域驱动设计中的一些基本概念</title>
    <url>/2020/12/06/%E9%A2%86%E5%9F%9F%E8%AE%BE%E8%AE%A1/</url>
    <content><![CDATA[<h2 id="1．实体-entity-："><a href="#1．实体-entity-：" class="headerlink" title="1．实体(entity)："></a>1．实体(entity)：</h2><pre><code>    根据eric evans的定义，”一个由它的标识定义的对象叫做实体”。通常实体具备唯一id，能够被持久化，具有业务逻辑，对应现实世界业务对象。

     实体一般和主要的业务/领域对象有一个直接的关系。一个实体的基本概念是一个持续抽象的生命，可以变化不同的状态和情形，但总是有相同的标识。</code></pre>
<p>需要注意的是：</p>
<pre><code>     一些开发人员将实体当成了orm意义上的实体，而不是业务所有和业务定义的领域对象。在一些实现中采用了transaction script风格的架构，使用贫血的领域模型。这种认识上的混乱，在领域驱动架构中，不愿意在领域对象中加入业务逻辑而导致贫血的领域模型，同时还可能使混乱的服务对象激增。</code></pre>
<h2 id="2．值对象-value-object"><a href="#2．值对象-value-object" class="headerlink" title="2．值对象(value object)"></a>2．值对象(value object)</h2><pre><code>    值对象的定义是：描述事物的对象；更准确的说，一个没有概念上标识符描述一个领域方面的对象。这些对象是用来表示临时的事物，或者可以认为值对象是实体的属性，这些属性没有特性标识但同时表达了领域中某类含义的概念。

    通常值对象不具有唯一id，由对象的属性描述，可以用来传递参数或对实体进行补充描述。

    作为实体属性的描述时，值对象也会被存储。在uml的类图上显现为一对多或一对一的关系。在orm映射关系上需要采用较复杂的一对多或一对一关系映射。

    关于实体与值对象的一个例子：比如员工信息的属性，如住址，电话号码都可以改变；然而，同一个员工的实体的标识将保持不变。因此，一个实体的基本概念是一个持续抽象的生命，可以变化不同的状态和情形，但总是有相同的标识。</code></pre>
<p>实体与值对象的区别</p>
<pre><code>     实体具有唯一标识，而值对象没有唯一标识，这是实体和值对象间的最大不同。

    实体就是领域中需要唯一标识的领域概念。有两个实体，如果唯一标识不一样，那么即便实体的其他所有属性都一样，也认为是两个不同的实体；一个实体的基本概念是一个持续抽象的生命，可以变化不同的状态和情形，但总是有相同的标识。

    不应该给实体定义太多的属性或行为，而应该寻找关联，发现其他一些实体或值对象，将属性或行为转移到其他关联的实体或值对象上。

    如果两个对象的所有的属性的值都相同，我们会认为它们是同一个对象的话，那么我们就可以把这种对象设计为值对象。值对象在判断是否是同一个对象时是通过它们的所有属性是否相同，如果相同则认为是同一个值对象；而实体是否为同一个实体的区分，只是看实体的唯一标识是否相同，而不管实体的属性是否相同。

    值对象另外一个明显的特征是不可变，即所有属性都是只读的。因为属性是只读的，所以可以被安全的共享；当共享值对象时，一般有复制和共享两种做法，具体采用哪种做法还要根据实际情况而定。

    箴言：如果值对象时可共享的，它们应该是不可变的。（值对象应该保持尽量的简单）

     值对象的设计应尽量简单，不要让它引用很多其他的对象，因为本质上讲值对象只是代表一个值。</code></pre>
<h2 id="3．聚合及聚合根-aggregate、aggregate-root-："><a href="#3．聚合及聚合根-aggregate、aggregate-root-：" class="headerlink" title="3．聚合及聚合根(aggregate、aggregate root)："></a>3．聚合及聚合根(aggregate、aggregate root)：</h2><pre><code>    聚合是用来定义领域对象所有权和边界的领域模式。聚合的作用是帮助简化模型对象间的关系。聚合，它通过定义对象之间清晰的所属关系和边界来实现领域模型的内聚，并避免了错综复杂的难以维护的对象关系网的形成。聚合定义了一组具有内聚关系的相关对象的集合，我们把聚合看作是一个修改数据的单元。

    划分aggregation是对领域模型的进一步深化，aggregation能阐释领域模型内部对象之间的深层关联．对aggregation的划分会直接映射到程序结构上．比如：ｄｄｄ推荐按aggregation设计model的子包．每个aggregation配备一个repository.aggregation内部的非root对象是通过导航获得的．        

    一个聚合是一组相关的被视为整体的对象。每个聚合都有一个根对象（聚合根实体），从外部访问只能通过这个对象。根实体对象有组成聚合所有对象的引用，但是外部对象只能引用根对象实体。

     只有聚合根才能使用仓储库直接查询，其它的只能通过相关的聚合访问。如果根实体被删除，聚合内部的其它对象也将被删除。

     通常，我们把聚合组织到一个文件夹或一个包中。每一个聚集对应一个包，并且每个聚集成员包括实体、值对象，domain事件，仓储接口和其它工厂对象。</code></pre>
<p>聚合有以下一些特点：</p>
<p>　　1. 每个聚合有一个根和一个边界，边界定义了一个聚合内部有哪些实体或值对象，根是聚合内的某个实体；</p>
<p>　　2. 聚合内部的对象之间可以相互引用，但是聚合外部如果要访问聚合内部的对象时，必须通过聚合根开始导航，绝对不能绕过聚合根直接访问聚合内的对象，也就是说聚合根是外部可以保持对它的引用的唯一元素；</p>
<p>　　3. 聚合内除根以外的其他实体的唯一标识都是本地标识，也就是只要在聚合内部保持唯一即可，因为它们总是从属于这个聚合的；</p>
<p>　　4. 聚合根负责与外部其他对象打交道并维护自己内部的业务规则；</p>
<p>　　5. 基于聚合的以上概念，我们可以推论出从数据库查询时的单元也是以聚合为一个单元，也就是说我们不能直接查询聚合内部的某个非根的对象；</p>
<p>　　6. 聚合内部的对象可以保持对其他聚合根的引用；</p>
<p>　　7. 删除一个聚合根时必须同时删除该聚合内的所有相关对象，因为他们都同属于一个聚合，是一个完整的概念。</p>
<p>如何识别聚合？</p>
<pre><code>    聚合中的对象关系是内聚的，即这些对象之间必须保持一个固定规则，固定规则是指在数据变化时必须保持不变的一致性规则。

    当我们在修改一个聚合时，我们必须在事务级别确保整个聚合内的所有对象满足这个固定规则。

    作为一条建议，聚合尽量不要太大，否则即便能够做到在事务级别保持聚合的业务规则完整性，也可能会带来一定的性能问题。

    有分析报告显示，通常在大部分领域模型中，有70%的聚合通常只有一个实体，即聚合根，该实体内部没有包含其他实体，只包含一些值对象；另外30%的聚合中，基本上也只包含两到三个实体。这意味着大部分的聚合都只是一个实体，该实体同时也是聚合根。</code></pre>
<p>如何识别聚合根？</p>
<p>　　如果一个聚合只有一个实体，那么这个实体就是聚合根；如果有多个实体，可以思考聚合内哪个对象有独立存在的意义并且可以和外部直接进行交互。</p>
<pre><code>   并不是所有的实体都是聚集根，但只有实体才能成为聚集根。</code></pre>
<h2 id="4．工厂-factories-："><a href="#4．工厂-factories-：" class="headerlink" title="4．工厂(factories)："></a>4．工厂(factories)：</h2><pre><code>   工厂用来封装创建一个复杂对象尤其是聚合时所需的知识，作用是将创建对象的细节隐藏起来。客户传递给工厂一些简单的参数，然后工厂可以在内部创建出一个复杂的领域对象然后返回给客户。当创建 实体和值对象复杂时建议使用工厂模式。

   不意味着我们一定要使用工厂模式。如果创建对象很简单，使用构造器或者控制反转/依赖注入容器足够创建对象的依赖。此时，我们就不需要通用工厂模式来创建实体或值对象。

   良好工厂的要求：

   每个创建方法都是原子的。一个工厂应该只能生产透明状态的对象。对于实体，意味着创建整个聚合时满足所有的不变量。

  一个单独的工厂通常生产整个聚合，传出一个根实体的引用，确保聚合的不变量都有。如果对象的内部聚合需要工厂，通常工厂方法的逻辑放在在聚合根上。这样对外部隐藏了聚合内聚的实现，同时赋予了根确保聚合完整的职责。如果聚合根不是子实体工厂的合适的家，那么继续创建一个单独的工厂。</code></pre>
<h2 id="5．仓储（repositories）："><a href="#5．仓储（repositories）：" class="headerlink" title="5．仓储（repositories）："></a>5．仓储（repositories）：</h2><pre><code>    仓储是用来管理实体的集合。

     仓储里面存放的对象一定是聚合，原因是domain是以聚合的概念来划分边界的；聚合作为一个整体概念，要么一起被取出来，要么一起被删除。外部访问不会单独对某个聚合内的子对象进行单独操作。因此，我们只对聚合设计仓储。

     仓储还有一个重要的特征就是分为仓储定义部分和仓储实现部分，我们在领域模型中定义仓储的接口，而在基础设施层实现具体的仓储。也符合按照接口分离模式在领域层定义仓储库接口的原则。

    注意：repositories本身是一种领域组件，但repositories的实现却不是领域层中的。</code></pre>
<p>respositories和dao：<br>         dao和repository在领域驱动设计中都很重要。dao是面向数据访问的，是关系型数据库和应用之间的契约。</p>
<pre><code>    repository：位于领域层，面向aggregation root。repository是一个独立的抽象，使用领域的通用语言，它与dao进行交互，并使用领域理解的语言提供对领域模型的数据访问服务的“业务接口”。</code></pre>
<p>　　dao方法是细粒度的，更接近数据库，而repository方法的粒度粗一些，而且更接近领域。领域对象应该只依赖于repository接口。客户端应该始终调用领域对象，领域对象再调用dao将数据持久化到数据 存储中。</p>
<p>　　处理领域对象之间的依赖关系（比如实体及其repository之间的依赖关系）是开发人员经常遇到的典型问题。解决这个问题通 常的设计方案是让服务类或外观类直接调用repository，在调用repository的时候返回实体对象给客户端。</p>
<h2 id="6．服务（services）："><a href="#6．服务（services）：" class="headerlink" title="6．服务（services）："></a>6．服务（services）：</h2><pre><code>     服务这个词在服务模式中是这么定义的：服务提供的操作是它提供给使用它的客户端，并突出领域对象的关系。

     所有的service只负责协调并委派业务逻辑给领域对象进行处理，其本身并真正实现业务逻辑，绝大部分的业务逻辑都由领域对象承载和实现了。

     service可与多种组件进行交互，这些组件包括：其他的service、领域对象和repository 或 dao。

     通常，应用中一般包括：domain模型服务和应用层服务：

    *  domain services encapsulate domain concepts that just are not naturally modeled as things.

    *  application services constitute the application, or service, layer.

    当一个领域操作被视为一个重要的领域概念，一般就应该作为领域服务。 服务应该是无状态的。

    设计实现领域服务来协调业务逻辑，只在领域服务中实现领域逻辑的调用。

    领域服务逻辑须以非常干净简洁的代码实现。因此，我们必须实现对领域低层组件的调用。通常应用的调用，例如仓储库的调用，创建事务等，不应该在这里实现。这些操作应该在应用层实现。

      通常服务对象名称中都应包含一个动词。 service接口的传入传出参数也都应该是dto，可能包含的工作有领域对象和dto的互转换以及事务。

  服务的3个特征：</code></pre>
<p>　　a. 服务执行的操作涉及一个领域概念，这个领域概念通常不属于一个实体或者值对象</p>
<p>　　b. 被执行的操作涉及到领域中其它的对象</p>
<p>　　c. 操作时无状态的</p>
<p>推荐：最好显式声明服务，因为它创建了领域中一个清晰的特性，封装了一个概念领域层服务和基础设施层服务：均建立在领域实体和值对象的上层，以便直接为这些相关的对象提供所需的服务；</p>
<p>领域服务与domain对象的区别</p>
<pre><code>    一般的领域对象都是有状态和行为的，而领域服务没有状态只有行为。需要强调的是领域服务是无状态的，它存在的意义就是协调领域对象共同完成某个操作，所有的状态还是都保存在相应的领域对象中。

    通常，对开发人员来说创建不应该存在的服务相当容易；要么在服务中包含了本应存在于领域对象中的领域逻辑，要么扮演了缺失的领域对象角色，而这些领域对象并没有作为模型的一部分去创建。</code></pre>
<h2 id="7．domain事件"><a href="#7．domain事件" class="headerlink" title="7．domain事件"></a>7．domain事件</h2><pre><code>    domain event模式最初由udi dahan提出，发表在自己的博客上：http://www.udidahan.com/2009/06/14/domain-events-salvation/

    企业级应用程序事件大致可以分为三类：系统事件、应用事件和领域事件。领域事件的触发点在领域模型（domain model）中。它的作用是将领域对象从对repository或service的依赖中解脱出来，避免让领域对象对这些设施产生直接依赖。它的做法就是当领域对象的业务方法需要依赖到这些对象时就发出一个事件，这个事件会被相应的对象监听到并做出处理。

    通过使用领域事件，我们可以实现领域模型对象状态的异步更新、外部系统接口的委托调用，以及通过事件派发机制实现系统集成。另外，领域事件本身具有自描述性。它不仅能够表述系统发生了什么事情，而且还能够描述发生事件的动机。

     domain事件也用表进行存储。</code></pre>
<h2 id="8．DTO"><a href="#8．DTO" class="headerlink" title="8．DTO"></a>8．DTO</h2><pre><code>   dto- datatransfer object（数据传输对象）：dto在设计之初的主要考量是以粗粒度的数据结构减少网络通信并简化调用接口。</code></pre>
<p>领域驱动架构与n层架构设计<br>领域驱动架构<br>        eric  evans的“领域驱动设计- 应对软件的复杂性“一书中描述和解释了建议的n层架构高层次的图：</p>
<p>user interface：</p>
<pre><code>    该层包含与其他系统/客户进行交互的接口与通信设施，在多数应用里，该层可能提供包括web services、rmi或rest等在内的一种或多种通信接口。该层主要由facade、dto和assembler三类组件构成，三类组件均是典型的j2ee模式。

    dto的作用最初主要是以粗粒度的数据结构减少网络通信并简化调用接口。在领域驱动设计中，采用dto模型，可以起到隐藏领域细节，帮助实现独立封闭的领域模型的作用。

    dto与领域对象之间的相互转换工作多由assembler承担，也有一些系统使用反射机制自动实现dto与领域对象之间的相互转换，如apache common beanutils。

    facade的用意在于为远程客户端提供粗粒度的调用接口。facade本身不处理任何的业务逻辑，它的主要工作就是将一个用户请求委派给一个或多个service进行处理，同时借助assembler将service传入或传出的领域对象转化为dto进行传输。</code></pre>
<p>application：</p>
<pre><code>     application层中主要组件就是service。这里需要注意的是，service的组织粒度和接口设计依据与传统transaction script风格的service是一致的，但是两者的实现却有质的区别。</code></pre>
<p>　　transaction script(事务脚本)的核心是过程，通过过程的调用来组织业务逻辑，业务逻辑在服务（service）层进行处理。大部分业务应用都可以被看成一系列事务。</p>
<pre><code>     transaction script的特点是简单容易理解，面向过程设计。  如果应用相对简单，在应用的生命周期里不会有基础设施技术的改变，尤其是业务逻辑很少会变动，采用transaction script风格简单自然，性能良好，容易理解。

    transaction script的缺点在于，对于复杂的业务逻辑难以保持良好的设计，事务之间的冗余代码不断增多。应用架构容易出现“胖服务层”和“贫血的领域模型”。同时，service层积聚越来越多的业务逻辑，导致可维护性和扩展性变差</code></pre>
<p>　　领域模型属于面向对象设计，领域模型具备自己的属性行为和状态，领域对象元素之间通过聚合配合解决实际业务应用。可复用，可维护，易扩展，可以采用合适的设计模型进行详细设计。缺点是相对复杂，要求设计人员有良好的抽象能力。</p>
<pre><code>    transactionscript风格业务逻辑主要在service中实现，而在领域驱动设计的架构里，service只负责协调并委派业务逻辑给领域对象进行处理。因此，我们可以考察这一点来识别系统是transaction script架构还是domain model架构。在实践中，设计良好的领域设计架构在开发过程中也容易向transaction script架构演变。</code></pre>
<p>domain：</p>
<pre><code>    domain层是整个系统的核心层，该层维护一个使用面向对象技术实现的领域模型，几乎全部的业务逻辑会在该层实现。domain层包含entity（实体）、valueobject(值对象)、domain event（领域事件）和repository（仓储）等多种重要的领域组件。</code></pre>
<p>infrastructure：</p>
<pre><code>    infrastructure（基础设施层）为interfaces、application和domain三层提供支撑。所有与具体平台、框架相关的实现会在infrastructure中提供，避免三层特别是domain层掺杂进这些实现，从而“污染”领域模型。infrastructure中最常见的一类设施是对象持久化的具体实现。</code></pre>
]]></content>
      <categories>
        <category>领域驱动设计中的一些基本概念</category>
      </categories>
  </entry>
  <entry>
    <title>领域层/模型层Biz</title>
    <url>/2020/12/06/%E9%A2%86%E5%9F%9FBIZ/</url>
    <content><![CDATA[<h2 id="领域层主要负责表达业务概念，业务状态信息和业务规则。"><a href="#领域层主要负责表达业务概念，业务状态信息和业务规则。" class="headerlink" title="领域层主要负责表达业务概念，业务状态信息和业务规则。"></a>领域层主要负责表达业务概念，业务状态信息和业务规则。</h2><p>Domain层是整个系统的核心层，几乎全部的业务逻辑会在该层实现。</p>
<p>领域模型层主要包含以下的内容：</p>
<p>实体(Entities):具有唯一标识的对象</p>
<p>值对象(Value Objects): 无需唯一标识。</p>
<p>领域服务(Domain): 与业务逻辑相关的，具有属性和行为的对象。</p>
<p>聚合/聚合根(Aggregates &amp; Aggregate Roots): 聚合是指一组具有内聚关系的相关对象的集合。</p>
<p>工厂(Factories): 创建复杂对象，隐藏创建细节。</p>
<p>仓储(Repository): 提供查找和持久化对象的方法。</p>
<p>领域层biz目录：</p>
<h2 id="（1）domain"><a href="#（1）domain" class="headerlink" title="（1）domain"></a>（1）domain</h2><p>存放Domain类，Domain负责业务逻辑，调用Repository对象来执行数据库操作。Domain没有直接访问数据库的代码，具体的数据库操作是通过调用Repository对象完成的。</p>
<p>注意，除了CQRS模式外，Repository都应该是由Domain调用的，而不是由Service调用。</p>
<h2 id="（2）repository"><a href="#（2）repository" class="headerlink" title="（2）repository"></a>（2）repository</h2><p>存放Repository类，调用Dao或者Mapper对象类执行数据库操作。</p>
<h2 id="（3）factory"><a href="#（3）factory" class="headerlink" title="（3）factory"></a>（3）factory</h2><p>存放Factory类，负责Domain和实体Entity的转换。</p>
]]></content>
      <categories>
        <category>领域层/模型层Biz</category>
      </categories>
      <tags>
        <tag>领域层/模型层Biz</tag>
      </tags>
  </entry>
  <entry>
    <title>架构设计原则</title>
    <url>/2020/12/06/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99/</url>
    <content><![CDATA[<p><img src="https://lixinx11.github.io/medias/bigdata/6%E5%A4%A7%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99.png" alt="大数据技术栈"></p>
]]></content>
      <categories>
        <category>架构设计原则</category>
      </categories>
      <tags>
        <tag>架构设计原则</tag>
      </tags>
  </entry>
</search>
